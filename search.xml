<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ECharts前端可视化</title>
    <url>/2020/05/19/frontEnd/ECharts%E5%89%8D%E7%AB%AF%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%84%E4%BB%B6/</url>
    <content><![CDATA[<h1 id="大致框架"><a href="#大致框架" class="headerlink" title="大致框架"></a>大致框架</h1><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>ECharts 关系图<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"js/jquery-3.2.1.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"js/echarts.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"main"</span> <span class="attr">style</span>=<span class="string">"width:1000px;height:800px"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> myChart = echarts.init(<span class="built_in">document</span>.getElementById(<span class="string">'main'</span>));</span></span><br><span class="line"><span class="actionscript">        <span class="keyword">var</span> categories = [];</span></span><br><span class="line"><span class="actionscript">        <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span></span><br><span class="line">            categories[i] = &#123;</span><br><span class="line"><span class="actionscript">                name: <span class="string">'类目'</span> + i</span></span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;</span><br><span class="line">        option = &#123;</span><br><span class="line"><span class="actionscript">            <span class="comment">// 图的标题</span></span></span><br><span class="line">            title: &#123;</span><br><span class="line"><span class="actionscript">                text: <span class="string">'ECharts 关系图'</span></span></span><br><span class="line">            &#125;,</span><br><span class="line"><span class="actionscript">            <span class="comment">// 提示框的配置</span></span></span><br><span class="line">            tooltip: &#123;</span><br><span class="line"><span class="actionscript">                formatter: <span class="function"><span class="keyword">function</span> <span class="params">(x)</span> </span>&#123;</span></span><br><span class="line"><span class="actionscript">                    <span class="keyword">return</span> x.data.des;</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line"><span class="actionscript">            <span class="comment">// 工具箱</span></span></span><br><span class="line">            toolbox: &#123;</span><br><span class="line"><span class="actionscript">                <span class="comment">// 显示工具箱</span></span></span><br><span class="line"><span class="actionscript">                show: <span class="literal">true</span>,</span></span><br><span class="line">                feature: &#123;</span><br><span class="line">                    mark: &#123;</span><br><span class="line"><span class="actionscript">                        show: <span class="literal">true</span></span></span><br><span class="line">                    &#125;,</span><br><span class="line"><span class="actionscript">                    <span class="comment">// 还原</span></span></span><br><span class="line">                    restore: &#123;</span><br><span class="line"><span class="actionscript">                        show: <span class="literal">true</span></span></span><br><span class="line">                    &#125;,</span><br><span class="line"><span class="actionscript">                    <span class="comment">// 保存为图片</span></span></span><br><span class="line">                    saveAsImage: &#123;</span><br><span class="line"><span class="actionscript">                        show: <span class="literal">true</span></span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            legend: [&#123;</span><br><span class="line"><span class="actionscript">                <span class="comment">// selectedMode: 'single',</span></span></span><br><span class="line"><span class="actionscript">                data: categories.map(<span class="function"><span class="keyword">function</span> <span class="params">(a)</span> </span>&#123;</span></span><br><span class="line"><span class="actionscript">                    <span class="keyword">return</span> a.name;</span></span><br><span class="line">                &#125;)</span><br><span class="line">            &#125;],</span><br><span class="line">            series: [&#123;</span><br><span class="line"><span class="actionscript">                type: <span class="string">'graph'</span>, <span class="comment">// 类型:关系图</span></span></span><br><span class="line"><span class="actionscript">                layout: <span class="string">'force'</span>, <span class="comment">//图的布局，类型为力导图</span></span></span><br><span class="line"><span class="actionscript">                symbolSize: <span class="number">40</span>, <span class="comment">// 调整节点的大小</span></span></span><br><span class="line"><span class="actionscript">                roam: <span class="literal">true</span>, <span class="comment">// 是否开启鼠标缩放和平移漫游。默认不开启。如果只想要开启缩放或者平移,可以设置成 'scale' 或者 'move'。设置成 true 为都开启</span></span></span><br><span class="line"><span class="actionscript">                edgeSymbol: [<span class="string">'circle'</span>, <span class="string">'arrow'</span>],</span></span><br><span class="line">                edgeSymbolSize: [2, 10],</span><br><span class="line">                edgeLabel: &#123;</span><br><span class="line">                    normal: &#123;</span><br><span class="line">                        textStyle: &#123;</span><br><span class="line">                            fontSize: 20</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                force: &#123;</span><br><span class="line">                    repulsion: 2500,</span><br><span class="line">                    edgeLength: [10, 50]</span><br><span class="line">                &#125;,</span><br><span class="line"><span class="actionscript">                draggable: <span class="literal">true</span>,</span></span><br><span class="line">                lineStyle: &#123;</span><br><span class="line">                    normal: &#123;</span><br><span class="line">                        width: 2,</span><br><span class="line"><span class="actionscript">                        color: <span class="string">'#4b565b'</span>,</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                edgeLabel: &#123;</span><br><span class="line">                    normal: &#123;</span><br><span class="line"><span class="actionscript">                        show: <span class="literal">true</span>,</span></span><br><span class="line"><span class="actionscript">                        formatter: <span class="function"><span class="keyword">function</span> <span class="params">(x)</span> </span>&#123;</span></span><br><span class="line"><span class="actionscript">                            <span class="keyword">return</span> x.data.name;</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                label: &#123;</span><br><span class="line">                    normal: &#123;</span><br><span class="line"><span class="actionscript">                        show: <span class="literal">true</span>,</span></span><br><span class="line">                        textStyle: &#123;&#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line"></span><br><span class="line"><span class="actionscript">                <span class="comment">// 数据</span></span></span><br><span class="line">                data: [&#123;</span><br><span class="line"><span class="actionscript">                    name: <span class="string">'node01'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'nodedes01'</span>,</span></span><br><span class="line">                    symbolSize: 70,</span><br><span class="line">                    category: 0,</span><br><span class="line">                &#125;, &#123;</span><br><span class="line"><span class="actionscript">                    name: <span class="string">'node02'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'nodedes02'</span>,</span></span><br><span class="line">                    symbolSize: 50,</span><br><span class="line">                    category: 1,</span><br><span class="line">                &#125;, &#123;</span><br><span class="line"><span class="actionscript">                    name: <span class="string">'node03'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'nodedes3'</span>,</span></span><br><span class="line">                    symbolSize: 50,</span><br><span class="line">                    category: 1,</span><br><span class="line">                &#125;, &#123;</span><br><span class="line"><span class="actionscript">                    name: <span class="string">'node04'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'nodedes04'</span>,</span></span><br><span class="line">                    symbolSize: 50,</span><br><span class="line">                    category: 1,</span><br><span class="line">                &#125;, &#123;</span><br><span class="line"><span class="actionscript">                    name: <span class="string">'node05'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'nodedes05'</span>,</span></span><br><span class="line">                    symbolSize: 50,</span><br><span class="line">                    category: 1,</span><br><span class="line">                &#125;],</span><br><span class="line">                links: [&#123;</span><br><span class="line"><span class="actionscript">                    source: <span class="string">'node01'</span>,</span></span><br><span class="line"><span class="actionscript">                    target: <span class="string">'node02'</span>,</span></span><br><span class="line"><span class="actionscript">                    name: <span class="string">'link01'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'link01des'</span></span></span><br><span class="line">                &#125;, &#123;</span><br><span class="line"><span class="actionscript">                    source: <span class="string">'node01'</span>,</span></span><br><span class="line"><span class="actionscript">                    target: <span class="string">'node03'</span>,</span></span><br><span class="line"><span class="actionscript">                    name: <span class="string">'link02'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'link02des'</span></span></span><br><span class="line">                &#125;, &#123;</span><br><span class="line"><span class="actionscript">                    source: <span class="string">'node01'</span>,</span></span><br><span class="line"><span class="actionscript">                    target: <span class="string">'node04'</span>,</span></span><br><span class="line"><span class="actionscript">                    name: <span class="string">'link03'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'link03des'</span></span></span><br><span class="line">                &#125;, &#123;</span><br><span class="line"><span class="actionscript">                    source: <span class="string">'node01'</span>,</span></span><br><span class="line"><span class="actionscript">                    target: <span class="string">'node05'</span>,</span></span><br><span class="line"><span class="actionscript">                    name: <span class="string">'link04'</span>,</span></span><br><span class="line"><span class="actionscript">                    des: <span class="string">'link05des'</span></span></span><br><span class="line">                &#125;],</span><br><span class="line">                categories: categories,</span><br><span class="line">            &#125;]</span><br><span class="line">        &#125;;</span><br><span class="line">        myChart.setOption(option);</span><br><span class="line">    <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="Series里的参数表"><a href="#Series里的参数表" class="headerlink" title="Series里的参数表"></a>Series里的参数表</h1><div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>介绍</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>edgeSymbol</td>
<td>使得图是有箭头的</td>
<td>edgeSymbol: [‘circle’, ‘arrow’]</td>
</tr>
<tr>
<td>force</td>
<td>力导向图中的点之间动态距离的设置，</td>
<td>force: {                // gravity: 0  //引力              <br />                                 edgeLength: 5, //默认距离    <br />                                repulsion: 20 //斥力          <br />  },</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1].重要的参考<a href="https://echarts.apache.org/examples/zh/index.html#chart-type-graphGL" target="_blank" rel="noopener">https://echarts.apache.org/examples/zh/index.html#chart-type-graphGL</a></p>
<p>[2].ECharts详细说明<a href="https://www.it610.com/article/3564022.htm" target="_blank" rel="noopener">https://www.it610.com/article/3564022.htm</a></p>
<p>[3].非常详细的介绍<a href="https://blog.csdn.net/qq_40576686/article/details/78711191" target="_blank" rel="noopener">https://blog.csdn.net/qq_40576686/article/details/78711191</a></p>
]]></content>
      <categories>
        <category>frontEnd</category>
      </categories>
  </entry>
  <entry>
    <title>html的form表单</title>
    <url>/2020/05/22/frontEnd/html%E7%9A%84form%E8%A1%A8%E5%8D%95/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>\<form>标签用于为用户输入创建HTML表单。</p>
<p>表单包含：input元素（文本字段，复选框，单选框，提交按钮等），menus、textarea、fieldset、legend、label元素</p>
<p>举例如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">""</span> <span class="attr">method</span>=<span class="string">""</span>&gt;</span></span><br><span class="line">    用户名：<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"username"</span> <span class="attr">value</span>=<span class="string">"用户名"</span> &gt;</span></span><br><span class="line">    密码：<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">"密码"</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"提交"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>表单用于向服务器传输数据</strong></p>
<h3 id="2-传递数据原理过程method"><a href="#2-传递数据原理过程method" class="headerlink" title="2 传递数据原理过程method="></a>2 传递数据原理过程method=</h3><p><strong>使用POST方法：</strong></p>
<p>浏览器按照这两个步骤来发送数据：</p>
<p>1.浏览器将与action属性中指定的表单处理服务器建立联系，</p>
<p>2.一旦建立连接，浏览器就按分段传输的方法将数据发送给服务器。</p>
<p><strong>使用GET方法：</strong></p>
<p>浏览器与表单处理服务器建立连接，然后直接在一个传输步骤中发送所有的表单数据：浏览器会将数据直接附在表单的action URL之后。这两者之间用问号分隔，从服务器获取数据，不更改服务器的状态和数据。</p>
<p>因此，调用含义get方法的表单时，要在url的页面后面加上要传入的值，如：http:127.0.0.1/entity/?user_text=”杨幂”或者<a href="http://www.example.com/example/program?x=28&amp;y=66" target="_blank" rel="noopener">http://www.example.com/example/program?x=28&amp;y=66</a></p>
<p><strong>用post还是get：</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>get优点</th>
<th>post优点</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.最佳表单传输性能+发送只有少数简短字段的小表单<br />2.get不需要在读取和解码方法做些额外的工作</td>
<td>1.有许多字段或是很长文本域的表单<br />2.涉及到安全性问题，不能让外人看到传输的数据时</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-表单的属性参数"><a href="#3-表单的属性参数" class="headerlink" title="3 表单的属性参数"></a>3 表单的属性参数</h3><p>参考<a href="https://www.w3school.com.cn/tags/tag_form.asp" target="_blank" rel="noopener">https://www.w3school.com.cn/tags/tag_form.asp</a></p>
<p>form的method参数用于设置</p>
<p>几个重要的属性：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>可能取值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>action</td>
<td>URL<br />比如：action=”form_action.asp”</td>
<td>用于设置表单的提交url，若不写或者保持空字符串，则将使用当前的URL。</td>
</tr>
<tr>
<td>menthod</td>
<td>menthod=”get”或者menthod=”post”</td>
<td>规定用与发送form-data的HTTP的方法；设置表单的提交方式，为空的话，默认使用POST。</td>
</tr>
<tr>
<td>name</td>
<td>str型，</td>
<td>规定表单的名称，提供了一种在脚本中引用form表单的方法</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><strong>对于action中的url地址而言：</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">action="<span class="tag">&lt;<span class="name">%=request.getContextPath()</span> %&gt;</span>/html/index.html"</span><br><span class="line"><span class="comment">&lt;!--这里&lt;%=request.getContextPath() %&gt;表示回到应用的根目录下，再加上相对路径--&gt;</span></span><br><span class="line">    </span><br><span class="line">action="/html/index.html"</span><br><span class="line"><span class="comment">&lt;!--表示在服务器的根目录下搜索html/index.html  /表示web根目录</span></span><br><span class="line"><span class="comment">	提交表单之后，是(正常调用IP:/html/index.html)</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line">action="index.html"</span><br><span class="line"><span class="comment">&lt;!--不以"/"开头的表示的是相对地址，即相对于当前这个页面的地址。</span></span><br><span class="line"><span class="comment">	提交表单之后，则是(调用IP:当前url/index.html)</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line">    </span><br><span class="line">action="http://localhost:8080/PracticeLogin/html/index.html"</span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">	这个是绝对路径，直接就是将路径显示出来。</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">&lt;!--表示在服务器的 &gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="四-例子"><a href="#四-例子" class="headerlink" title="四.例子"></a>四.例子</h3><h4 id="menthod-”get”的例子"><a href="#menthod-”get”的例子" class="headerlink" title="menthod=”get”的例子"></a>menthod=”get”的例子</h4><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"form_action.asp"</span> <span class="attr">method</span>=<span class="string">"get"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span>First name: <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"fname"</span> /&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span>Last name: <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"lname"</span> /&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"Submit"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="menthod-”post”的例子"><a href="#menthod-”post”的例子" class="headerlink" title="menthod=”post”的例子"></a>menthod=”post”的例子</h4><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1].使用form表单实现Django数据传输的一个实例<a href="https://blog.csdn.net/a877415861/article/details/77989811?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase" target="_blank" rel="noopener">https://blog.csdn.net/a877415861/article/details/77989811?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase</a></p>
]]></content>
      <categories>
        <category>frontEnd</category>
      </categories>
  </entry>
  <entry>
    <title>html的简单介绍</title>
    <url>/2020/05/15/frontEnd/html%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">content= $(<span class="string">'#liang'</span>).val()</span><br></pre></td></tr></table></figure>
<p>这句话的含义就是，选取前面定义过的id=’liang’的标签，并取值赋给content</p>
<p>$其实就是copy函数名，在传统的编程语言中，$不能用在函数名中知，但是javascript中可以，这个$函数的作用就是通过ID获取Element。跟你直道接调用getElementById()效果是一样的。</p>
<h3 id="Js弹出对话框的三种形式："><a href="#Js弹出对话框的三种形式：" class="headerlink" title="Js弹出对话框的三种形式："></a>Js弹出对话框的三种形式：</h3><p>alert(str);    弹出的框中只有确认按钮</p>
<p>confirm(str);     弹出的框中既有确认按钮，也有取消按钮，并且有返回值，可以被调用。</p>
<p>prompt(str);       弹出提示对话框，使用户输入有关信息，并接受返回值，</p>
<p>将js代码放入body里面的最底部，这样方便先加载静态显示的内容，再加载js动态效果</p>
<h3 id="style-’text-javascript’"><a href="#style-’text-javascript’" class="headerlink" title="style=’text/javascript’"></a>style=’text/javascript’</h3><p>type=”text/javascript”是说明这一段脚本语言是javascript。告诉浏览来器这一段要按照javascript来解释执行。</p>
<h3 id="html的文件路径问题"><a href="#html的文件路径问题" class="headerlink" title="html的文件路径问题"></a>html的文件路径问题</h3><p>没有在页面引入Qjuery，引用路径：可以是绝对路径引用（以根目录为基准），也可以是相对路径引用(以网页文件当前所在文档为基准开始向下找，当前所在文档为基准，用两个点”..”表示上一级文件夹同级寻找。)</p>
<p><a href="https://blog.csdn.net/wildand/article/details/89501599" target="_blank" rel="noopener">https://blog.csdn.net/wildand/article/details/89501599</a></p>
]]></content>
      <categories>
        <category>frontEnd</category>
      </categories>
  </entry>
  <entry>
    <title>C++的一些概念</title>
    <url>/2020/04/18/C++/C++%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p><strong>多态的概念</strong></p>
<p><a href="https://www.cnblogs.com/dishengAndziyu/p/10915253.html" target="_blank" rel="noopener">https://www.cnblogs.com/dishengAndziyu/p/10915253.html</a></p>
<p>相同的行为方式产生不同的行为结果</p>
<p>同样的调用语句在实际运行中有不同的表现形式</p>
<p><strong>C++的线程的锁</strong></p>
<p>互斥锁，自旋锁，读写锁，条件锁。</p>
<p><a href="https://blog.csdn.net/Allen_Walker_QAQ/article/details/80637010" target="_blank" rel="noopener">https://blog.csdn.net/Allen_Walker_QAQ/article/details/80637010</a></p>
<p><strong>C++中基本数据类型所占的字节数</strong></p>
<p>   char ：1个字节</p>
<p>  char* (指针变量)：8个字节</p>
<p>  short int :2个字节 </p>
<p> int :4字节</p>
<p> unsigned int :4字节</p>
<p> float :4字节</p>
<p>double,long,long long :8字节</p>
<p>对于定义的类而言：1.等于非静态成员变量的总和；</p>
<p>   2.编译器为了CPU的计算，做了数据对齐处理。（有char和int时，char作为4字节处理）</p>
<p><strong>C++的STL的使用</strong></p>
<p><a href="https://www.cnblogs.com/pullself/p/10049657.html" target="_blank" rel="noopener">https://www.cnblogs.com/pullself/p/10049657.html</a></p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>C++的Vector操作</title>
    <url>/2020/04/18/C++/C++%E7%9A%84Vector%E7%9A%84%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="一-头文件"><a href="#一-头文件" class="headerlink" title="一.头文件"></a>一.头文件</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;vector&gt;</span></span></span><br></pre></td></tr></table></figure>
<h3 id="二-vector申明及初始化"><a href="#二-vector申明及初始化" class="headerlink" title="二.vector申明及初始化"></a>二.vector申明及初始化</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;   <span class="comment">//</span></span><br><span class="line"></span><br><span class="line">vector&lt;int&gt; vec(5)；//申明一个初始大小为5的int型向量</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">vect</span><span class="params">(<span class="number">10</span>,<span class="number">1</span>)</span></span>; <span class="comment">//申明一个初始大小为10，且值都为1的向量</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">vec</span><span class="params">(num,num+<span class="number">5</span>)</span></span>;<span class="comment">// 将num数组的元素用于初始化vec向量(数组首地址，数组尾地址)</span></span><br></pre></td></tr></table></figure>
<h3 id="三-vector的基本操作"><a href="#三-vector的基本操作" class="headerlink" title="三.vector的基本操作"></a>三.vector的基本操作</h3><h4 id="1-容量的访问"><a href="#1-容量的访问" class="headerlink" title="1.容量的访问"></a>1.容量的访问</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">a.向量大小：len=vec.<span class="built_in">size</span>()</span><br><span class="line">b.向量最大容量：(<span class="keyword">int</span>)vec.max_size();</span><br><span class="line">c.更改向量大小：vec.resize(num);   </span><br><span class="line">d.向量真实大小：<span class="keyword">int</span> len=vec.capacity()</span><br><span class="line">e.向量判空：vec.empty();   </span><br><span class="line">f.减少向量大小到满足元素所占存储空间的大小：vec.shrink_to_fit();</span><br></pre></td></tr></table></figure>
<h4 id="2-修改"><a href="#2-修改" class="headerlink" title="2.修改"></a>2.修改</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">a.末尾添加元素：vec.push_back(要添加的元素）</span><br><span class="line">b.末尾删除元素：vec.pop_back(空)；</span><br><span class="line">                       </span><br><span class="line">c.任意位置插入元素：vec.insert();</span><br><span class="line">iterator insert( iterator loc, <span class="keyword">const</span> TYPE &amp;val ); <span class="comment">//在指定位置loc前插入值为val的元素,返回指向这个元素的迭代器,</span></span><br><span class="line"><span class="keyword">void</span> insert( iterator loc, size_type num, <span class="keyword">const</span> TYPE &amp;val ); <span class="comment">//在指定位置loc前插入num个值为val的元素</span></span><br><span class="line"><span class="keyword">void</span> insert( iterator loc, input_iterator start, input_iterator <span class="built_in">end</span> );<span class="comment">//在指定位置loc前插入区间[start, end)的所有元素 </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">d.任意位置删除元素：vec.erase();</span><br><span class="line">vec.erase(pos)，删除pos位置的数据</span><br><span class="line">vec.erase(beg，<span class="built_in">end</span>); 删除[beg，<span class="built_in">end</span>]区间的数据</span><br><span class="line"></span><br><span class="line">e.交换两个向量的元素：vec.swap();</span><br><span class="line"></span><br><span class="line">f.清空向量元素:vec.<span class="built_in">clear</span>();</span><br></pre></td></tr></table></figure>
<h4 id="3-元素的访问"><a href="#3-元素的访问" class="headerlink" title="3.元素的访问"></a>3.元素的访问</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">下标访问法：vec[<span class="number">1</span>]；<span class="comment">//并不会检查是否越界</span></span><br><span class="line">at访问法：vec.at(<span class="number">1</span>);<span class="comment">//at会检查是否越界，是则抛出out of range的异常</span></span><br><span class="line">访问第一个元素：vec.front();</span><br><span class="line">访问最后一个元素：vec.back();</span><br><span class="line">返回一个指针：<span class="keyword">int</span>*p=vec.data(); <span class="comment">//可以返回一个指针指向这个数组，</span></span><br></pre></td></tr></table></figure>
<h4 id="4-迭代器"><a href="#4-迭代器" class="headerlink" title="4.迭代器"></a>4.迭代器</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">开始指针：vec.<span class="built_in">begin</span>();</span><br><span class="line">末尾指针：vec.<span class="built_in">end</span>();  <span class="comment">//指向最后一个元素的下一个位置</span></span><br><span class="line"><span class="comment">//对于iterator,有vector&lt;char&gt;::iterator theIterator = vec.begin();</span></span><br></pre></td></tr></table></figure>
<h4 id="5-有用的封装函数"><a href="#5-有用的封装函数" class="headerlink" title="5.有用的封装函数"></a>5.有用的封装函数</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">a.元素翻转：</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line">reverse(vec.<span class="built_in">begin</span>(),vec.<span class="built_in">end</span>());</span><br><span class="line"></span><br><span class="line">b.元素排序</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line">sort(vec.<span class="built_in">begin</span>(),vec.<span class="built_in">end</span>());<span class="comment">//从小到大排序</span></span><br><span class="line"></span><br><span class="line">c.元素求和</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;numeric&gt;</span></span></span><br><span class="line">accumulate(要累加的头迭代指标，要累加的尾迭代指标，累加的值)</span><br><span class="line">例：sum=accumulate(vec.<span class="built_in">begin</span>()，vec.<span class="built_in">end</span>(),<span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<p>-———————————————————-</p>
<h3 id="注意点："><a href="#注意点：" class="headerlink" title="注意点："></a>注意点：</h3><p>1.在定义动态，没有规定大小的vector型数组时，向数组中添加元素不能用下标访问法，只能用str.push_back()往容器里面加入元素，等加入了元素后，才可以用下标访问法</p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
  </entry>
  <entry>
    <title>什么是基于Web框架开发</title>
    <url>/2020/05/25/frontEnd/%E4%BB%80%E4%B9%88%E6%98%AF%E5%9F%BA%E4%BA%8EWeb%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<p>基于Web开发又称为B/S架构开发。</p>
<p>B/S模式是百指在TCP/IP的支持下，以HTTP为传输协议，客户端通过Browser访问Web服务器以及与之相连的后台数据库的技术及体系结构。它由浏览器、Web服务器、应用服务器和数据库服务器组成。客户端的浏览器通过URL访问Web服务器，度Web服务器请求数据库服务器，并将获得的结果以HTML形式返回客户端浏览器。</p>
]]></content>
      <categories>
        <category>frontEnd</category>
      </categories>
  </entry>
  <entry>
    <title>知识图谱的基本概念</title>
    <url>/2020/05/30/knowledge%20graph/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/</url>
    <content><![CDATA[<h3 id="1-起源发展"><a href="#1-起源发展" class="headerlink" title="1 起源发展"></a>1 起源发展</h3><p>于2012年5月17日由[Google]正式提出，其初衷是为了提高搜索引擎的能力，改善用户的搜索质量以及搜索体验。随着人工智能的技术发展和应用，知识图谱逐渐成为关键技术之一，现已被广泛应用于智能搜索、智能问答、个性化推荐、内容分发等领域。知识图谱的大致介绍如下图所示：</p>
<p><img src ="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/什么是知识图谱.png" width="550"/></p>
<h3 id="2-知识图谱的架构"><a href="#2-知识图谱的架构" class="headerlink" title="2 知识图谱的架构"></a>2 知识图谱的架构</h3><p>包括自身的逻辑架构以及构建知识图谱所采用的技术（体系）架构。 </p>
<p><strong>逻辑层面架构：</strong></p>
<p>分为数据层和模式层：数据层是由一系列的事实组成，知识将以事实为单位进行存储，用三元组来表达事实，可以用图数据库存储。模式层构建在数据层之上，是知识图谱的核心，通常采用本体库来管理知识图谱的模式层。 </p>
<p><strong>技术层面的架构：</strong></p>
<p><img src ="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/知识图谱技术架构.jpeg" width="500"/></p>
<p> <strong>知识图谱的构建方式：</strong></p>
<p>1).自顶向下：先为知识图谱定义好本体与数据模式，再将实体加入到知识库中。 </p>
<p>2).自底向上：从一些开放链接数据中提取实体，选择其中置信度较高的加入到知识库中，再构建顶层的本体模式。（大多数）</p>
<p><strong>典型的知识图谱案例：</strong><a href="https://www.cnblogs.com/timssd/p/8437077.html" target="_blank" rel="noopener">https://www.cnblogs.com/timssd/p/8437077.html</a></p>
<h3 id="3-知识表示"><a href="#3-知识表示" class="headerlink" title="3 知识表示"></a>3 知识表示</h3><p><strong>早期知识表示方法：</strong></p>
<ul>
<li>一阶谓词逻辑（First-Order Logic）</li>
<li>产生式规则（Production Rule）</li>
<li>框架（Framework）</li>
<li>语义网络（Semantic Network）</li>
</ul>
<p><strong>基于语义网的知识表示框架：</strong></p>
<ul>
<li>RDF和RDFS</li>
<li>OWL和OWL2 Fragments</li>
<li>SPARQL查询语言</li>
<li>Json-LD、RDFa、HTML5 、MicroData等新型知识表示</li>
</ul>
<h3 id="知识存储"><a href="#知识存储" class="headerlink" title="知识存储"></a>知识存储</h3><p><strong>关系数据库和图数据库：</strong></p>
<p><a href="https://www.cnblogs.com/jpfss/p/11280880.html" target="_blank" rel="noopener">https://www.cnblogs.com/jpfss/p/11280880.html</a></p>
<h3 id="知识推理"><a href="#知识推理" class="headerlink" title="知识推理"></a>知识推理</h3><p><strong>关系推理分类：</strong></p>
<p><img src ="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/关系推理分类.jpg" width="400" /></p>
<p><strong>基于知识图谱的关系推演：</strong></p>
<p><a href="https://zhuanlan.zhihu.com/p/42340077" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/42340077</a></p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>[1].知识图谱中的关系推理 <a href="https://blog.csdn.net/u010159842/article/details/80492069" target="_blank" rel="noopener">https://blog.csdn.net/u010159842/article/details/80492069</a></p>
<p>[2].本体、实体的概念区别：<a href="https://blog.csdn.net/Solitarily/article/details/78768139" target="_blank" rel="noopener">https://blog.csdn.net/Solitarily/article/details/78768139</a></p>
]]></content>
      <categories>
        <category>knowledge graph</category>
      </categories>
  </entry>
  <entry>
    <title>java下载过程中遇到的问题</title>
    <url>/2020/05/10/java/java%E4%B8%8B%E8%BD%BD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>在下载Neo4j时，要先下载Java，在访问官网时，得到了如下的两类</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/插入.png" alt="插入"></p>
<p>不知道该下载哪一种</p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>一般都是下载.exe，是直接帮安装的。而.zip则是由源码的</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title>Hierarchical softmax</title>
    <url>/2020/06/11/machine%20learning/Hierarchical%20softmax/</url>
    <content><![CDATA[<p>构造一棵树，依据训练样本数据中的单词出现的频率，构建起来的一棵Huffman tree，频率越高，节点越短。得到构造的二叉树的结构：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/分层softmax.png" alt="分层softmax"></p>
<p>对于每一个节点，都是一个二分类[0,1]，可以用sigmod去处理节点信息。sigmod函数如下：</p>
<script type="math/tex; mode=display">
\sigma (x)=\frac{1}{1+exp(-x)}</script><p>此时，当我们知道了目标单词x,我们只需要计算root节点到该词的路径乘积即可，不需去遍历所有的节点信息，时间复杂度变成O($\log_2$(v))</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/softmax2.png" alt="softmax2"></p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>RNN(循环神经网络)</title>
    <url>/2020/06/20/machine%20learning/RNN(%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)/</url>
    <content><![CDATA[<h3 id="RNN-Recurrent-Neural-Network-问题引入"><a href="#RNN-Recurrent-Neural-Network-问题引入" class="headerlink" title="RNN(Recurrent Neural Network) 问题引入"></a>RNN(Recurrent Neural Network) 问题引入</h3><p>之前研究的是一个个的输入，前一个输入和后一个输入并没有关系，但是任务需要能够更好的处理序列的信息，也即后一个输入的处理结果与前一个输入有着一定的关系。</p>
<p>比如”我吃苹果”中，在确定”吃”这个输入的词性是动词之后，下一个输入”苹果”是名词的可能性很大，即相互关联关系。</p>
<h3 id="RNN结构"><a href="#RNN结构" class="headerlink" title="RNN结构"></a>RNN结构</h3><p>先看一个简单的RNN结构</p>
<p><img src ="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/简单RNN结构图.jpg" width="200" height="150"/></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x是一个向量，表示输入层的值。</span><br><span class="line">u是输入层到隐藏层的权重矩阵。</span><br><span class="line">s是一个向量,表示隐藏层的值(这一层有多个节点，节点数与向量s的维度相同)。</span><br><span class="line">权重矩阵w就是隐藏层上一次的值作为这一次的输入的权重。</span><br><span class="line">v是隐藏层到输出层的权重矩阵。</span><br></pre></td></tr></table></figure>
<p>具体的RNN的结构图</p>
<p><img src ="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/具体RNN的图.jpg" width="550"/></p>
<blockquote id="fn_？">
<sup>？</sup>. 这里的g和f是什么？<a href="#reffn_？" title="Jump back to footnote [？] in the text."> &#8617;</a>
</blockquote>
<p>之后，将其按照时间线进行展开，得到如下图所示：</p>
<p><img src ="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/展开后的RNN.jpg" width="500" /></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>循环神经网络<a href="https://zybuluo.com/hanbingtao/note/541458" target="_blank" rel="noopener">https://zybuluo.com/hanbingtao/note/541458</a></p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>Sigmoid函数介绍</title>
    <url>/2020/07/20/machine%20learning/Sigmoid%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h3 id="Sigmoid函数形式"><a href="#Sigmoid函数形式" class="headerlink" title="Sigmoid函数形式"></a>Sigmoid函数形式</h3><script type="math/tex; mode=display">
\sigma(x)=\frac{1}{1+e^{-x}}</script><p>其导数形式：$\sigma’(x)=\frac{e^{-x}}{(1+e^{-x})^2}=\sigma(x)[1-\sigma(x)]$</p>
<p>并且由此可以得到</p>
<p>$[log~\sigma(x)]’=1-\sigma(x)$</p>
<p>$[log(1-\sigma(x))]’=-\sigma(x)$</p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>前馈神经网络</title>
    <url>/2020/06/11/machine%20learning/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p>前馈神经网络的结构以下几个特点：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">*每层神经元与下一层神经元之间完全互连</span><br><span class="line">*神经元之间不存在同层连接</span><br><span class="line">*神经元之间不存在跨层连接</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/前馈神经网络.png" alt="前馈神经网络"></p>
<p>由此可以得知：”前馈“指的是网络拓扑结构中不存在环或回路，</p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>softmax简要介绍</title>
    <url>/2020/07/13/machine%20learning/softmax%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>应用于多分类的场景中。</p>
<p>把一些输入映射为0-1之间的实数，并且归一化保证和为1.</p>
<p>max是分类，非黑即白，非大即小。而所希望的是取到某个分类的概率，因此加上soft。最后的输出是每个分类被取到的概率。</p>
<h3 id="什么是Softmax公式"><a href="#什么是Softmax公式" class="headerlink" title="什么是Softmax公式"></a>什么是Softmax公式</h3><p>首先上图：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/softmax图片.jpg" alt="softmax图片" style="zoom:80%;" /></p>
<p><strong>softmax公式：</strong></p>
<p>若有一个数组V，$V_i$表示V中的第i个元素，则这个元素的softmax的值为：</p>
<script type="math/tex; mode=display">
S_i=\frac{e^i}{\sum_je^j}</script><p>该元素的指数值除以所有元素指数和的比值。</p>
<h3 id="softmax-和k个二元分类器的区别："><a href="#softmax-和k个二元分类器的区别：" class="headerlink" title="softmax 和k个二元分类器的区别："></a>softmax 和k个二元分类器的区别：</h3><p>若分类的类别是互相排斥的，则可以使用Softmax更为方便；</p>
<p>若分类的类别并不是互相排斥的，则建立k个独立的logistic回归分类器更合适。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1].softmax简要介绍</p>
<p><a href="https://blog.csdn.net/bitcarmanlee/article/details/82320853" target="_blank" rel="noopener">https://blog.csdn.net/bitcarmanlee/article/details/82320853</a></p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>李航-《统计学习方法》</title>
    <url>/2020/06/23/machine%20learning/%E6%9D%8E%E8%88%AA-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/</url>
    <content><![CDATA[<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1].代码实现<a href="https://github.com/fengdu78/lihang-code" target="_blank" rel="noopener">https://github.com/fengdu78/lihang-code</a></p>
<p>[2].统计学习方法最全资源汇总<a href="https://mp.weixin.qq.com/s/XXldfRkELDs931YoOzXXlA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/XXldfRkELDs931YoOzXXlA</a></p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>图嵌入</title>
    <url>/2020/07/17/machine%20learning/%E5%9B%BE%E5%B5%8C%E5%85%A5%20/</url>
    <content><![CDATA[<h3 id="1-什么是图嵌入"><a href="#1-什么是图嵌入" class="headerlink" title="1 什么是图嵌入"></a>1 什么是图嵌入</h3><p>将图数据(通常为高维稠密的矩阵)映射为低维稠密向量的过程。</p>
<p>图嵌入要捕捉图的拓扑结构，顶点与顶点的关系，以及其他的信息(如子图、连边等)。如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/图嵌入.jpg" alt="图嵌入" style="zoom:30%;" /></p>
<h3 id="2-图嵌入技术分类："><a href="#2-图嵌入技术分类：" class="headerlink" title="2 图嵌入技术分类："></a>2 图嵌入技术分类：</h3><p><strong>节点嵌入：</strong></p>
<p>需要对节点进行分类、节点相似度预测、节点分布可视化时一般采用节点的嵌入。</p>
<p><strong>图嵌入：</strong></p>
<p>需要在图级别上预测或者整个图结构决策，需要将整个图表示为一个向量进行嵌入表示。</p>
<h3 id="3-使用图嵌入的原因："><a href="#3-使用图嵌入的原因：" class="headerlink" title="3 使用图嵌入的原因："></a>3 使用图嵌入的原因：</h3><p><strong>1). 在graph上直接进行机器学习有一定局限性。</strong></p>
<p>图是由节点和边构成，图中的向量关系只能用数学、统计或者特定的子集进行表示，但在嵌入之后的向量空间具有更加灵活和丰富的计算方式。</p>
<p><strong>2).图嵌入能够压缩数据。</strong></p>
<p>原来的图是用邻接矩阵描述图中节点之间的连接。图嵌入之后是降维作用，压缩数据。</p>
<p><strong>3).向量计算比直接在图上操作更加简单。</strong></p>
<h3 id="4-图嵌入满足的条件："><a href="#4-图嵌入满足的条件：" class="headerlink" title="4 图嵌入满足的条件："></a>4 图嵌入满足的条件：</h3><p>​    <strong>1).属性选择</strong></p>
<p>确保嵌入能够很好地描述图的属性，即需要表示图拓扑，节点连接和节点邻域</p>
<p>​    <strong>2).可扩展性</strong></p>
<p>好的嵌入方法在小图上高效嵌入，在大图上也能高效嵌入。</p>
<p>​    <strong>3).嵌入的维度</strong></p>
<p>需要一个合适的维度。</p>
<h3 id="5-图嵌入方法"><a href="#5-图嵌入方法" class="headerlink" title="5 图嵌入方法"></a>5 图嵌入方法</h3><h4 id="节点嵌入："><a href="#节点嵌入：" class="headerlink" title="节点嵌入："></a>节点嵌入：</h4><p>DeepWalk，Node2vec，SDNE</p>
<h4 id="图嵌入"><a href="#图嵌入" class="headerlink" title="图嵌入"></a>图嵌入</h4><p>graph2vec</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1].<a href="https://zhuanlan.zhihu.com/p/87572912" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/87572912</a></p>
<p>[2].图嵌入和知识图谱嵌入<a href="https://zhuanlan.zhihu.com/p/94201377" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/94201377</a></p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>梯度下降法</title>
    <url>/2020/07/27/machine%20learning/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</url>
    <content><![CDATA[<p>数据样本如下：(样本来自于)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>4</td>
<td>19</td>
</tr>
<tr>
<td>2</td>
<td>5</td>
<td>26</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>19</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
<td>29</td>
</tr>
</tbody>
</table>
</div>
<p>这里$x_1$和$x_2$是样本值，y是预测目标，我们假设以一条直线来拟合上面的数据，设待拟合的函数如下：</p>
<p>$h(\theta)=\theta_1 x_1+\theta_2 x_2\tag{1}$</p>
<p>我们的目标是求出$\theta_1$和$\theta_2$的值，让$h(\theta)$尽量逼近目标值y。</p>
<p>对于这个线性回归问题，采用最小二乘法和梯度下降就可以求出两个参数。下面的损失函数等借用最小二乘法的概念解释。</p>
<h3 id="梯度下降法原理："><a href="#梯度下降法原理：" class="headerlink" title="梯度下降法原理："></a>梯度下降法原理：</h3><p><strong>损失函数</strong>如下：</p>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{2m}\sum_{i=1}^m[h_{\theta}(x^i)-y^i]^2\tag{2}</script><p>这里m代表每次取多少样本进行训练，若采用SGD训练，则每次随机取一组样本，m=1;若是批处理，则m等于每次抽取作为训练样本的数量。$\theta$是参数，其对应于（1）式中的$\theta_1,\theta_2$。</p>
<p><strong>训练目标如下：</strong></p>
<p>让损失函数$J(\theta)$的值最小，则由梯度下降法，先对$J(\theta)$求偏导：</p>
<script type="math/tex; mode=display">
\frac{ \part }{\part\theta_j}J(\theta)=2\frac{1}{2m}\sum_{i=1}^m[h_{\theta}(x^i)-y^i](\frac{\part}{\part\theta_j}h_{\theta}(x^i))\\=\frac{1}{m}\sum_{i=1}^m[h_{\theta}(x^i)-y^i]x^i_j\tag{3}</script><p>由于是要最小化损失函数，故参数$\theta$的更新是按其负梯度方向的：</p>
<script type="math/tex; mode=display">
\theta_j:=\theta_j-\alpha\frac{\part}{\part\theta_j}J(\theta)\\=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m[h_{\theta}(x^i)-y^i]x^i_j\tag{4}</script><blockquote>
<p>每次向山下走时，都以下降最多的路线。</p>
<p>从二维角度考虑，则利用函数$y=x^2+1$，若要使得函数达到最小值，则对x求导，得到$y’=\frac{1}{2}x$，再利用梯度下降的方式，使得$x \rarr 0$</p>
</blockquote>
<h3 id="批量梯度下降法-Batch-gradient-descent"><a href="#批量梯度下降法-Batch-gradient-descent" class="headerlink" title="批量梯度下降法(Batch gradient descent)"></a>批量梯度下降法(Batch gradient descent)</h3><p>每次迭代使用所有的样本。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment">#用y = Θ1*x1 + Θ2*x2来拟合下面的输入和输出</span></span><br><span class="line"><span class="comment">#input1  1   2   5   4</span></span><br><span class="line"><span class="comment">#input2  4   5   1   2</span></span><br><span class="line"><span class="comment">#output  19  26  19  20</span></span><br><span class="line">input_x = [[<span class="number">1</span>,<span class="number">4</span>], [<span class="number">2</span>,<span class="number">5</span>], [<span class="number">5</span>,<span class="number">1</span>], [<span class="number">4</span>,<span class="number">2</span>]]  <span class="comment">#输入</span></span><br><span class="line">y = [<span class="number">19</span>,<span class="number">26</span>,<span class="number">19</span>,<span class="number">20</span>]   <span class="comment">#输出</span></span><br><span class="line">theta = [<span class="number">1</span>,<span class="number">1</span>]       <span class="comment">#θ参数初始化</span></span><br><span class="line">loss = <span class="number">10</span>           <span class="comment">#loss先定义一个数，为了进入循环迭代</span></span><br><span class="line">step_size = <span class="number">0.01</span>    <span class="comment">#步长</span></span><br><span class="line">eps =<span class="number">0.0001</span>         <span class="comment">#精度要求</span></span><br><span class="line">max_iters = <span class="number">10000</span>   <span class="comment">#最大迭代次数</span></span><br><span class="line">error =<span class="number">0</span>            <span class="comment">#损失值</span></span><br><span class="line">iter_count = <span class="number">0</span>      <span class="comment">#当前迭代次数</span></span><br><span class="line"> </span><br><span class="line">err1=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]      <span class="comment">#求Θ1梯度的中间变量1</span></span><br><span class="line">err2=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]      <span class="comment">#求Θ2梯度的中间变量2</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">while</span>( loss &gt; eps <span class="keyword">and</span> iter_count &lt; max_iters):   <span class="comment">#迭代条件,使得损失值小于某一个固定的值，就行</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    err1sum = <span class="number">0</span></span><br><span class="line">    err2sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range (<span class="number">4</span>):     <span class="comment">#每次迭代所有的样本都进行训练</span></span><br><span class="line">        pred_y = theta[<span class="number">0</span>]*input_x[i][<span class="number">0</span>]+theta[<span class="number">1</span>]*input_x[i][<span class="number">1</span>]  <span class="comment">#预测值</span></span><br><span class="line">        err1[i]=(pred_y-y[i])*input_x[i][<span class="number">0</span>] <span class="comment">#这个式子是J(\theta)对\theta_1求偏导后得到的式子，然后将样本点代入</span></span><br><span class="line">        err1sum=err1sum+err1[i]                 <span class="comment">#这个是求和</span></span><br><span class="line">        err2[i]=(pred_y-y[i])*input_x[i][<span class="number">1</span>]</span><br><span class="line">        err2sum=err2sum+err2[i]</span><br><span class="line">    theta[<span class="number">0</span>] = theta[<span class="number">0</span>] - step_size * err1sum/<span class="number">4</span>  <span class="comment">#对应(4)式</span></span><br><span class="line">    theta[<span class="number">1</span>] = theta[<span class="number">1</span>] - step_size * err2sum/<span class="number">4</span>  <span class="comment">#对应(4)式</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range (<span class="number">4</span>):</span><br><span class="line">        pred_y = theta[<span class="number">0</span>]*input_x[i][<span class="number">0</span>]+theta[<span class="number">1</span>]*input_x[i][<span class="number">1</span>]   <span class="comment">#预测值</span></span><br><span class="line">        error = (<span class="number">1</span>/(<span class="number">2</span>*<span class="number">4</span>))*(pred_y - y[i])**<span class="number">2</span>  <span class="comment">#损失值</span></span><br><span class="line">        loss = loss + error  <span class="comment">#总损失值</span></span><br><span class="line">    iter_count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"iters_count"</span>, iter_count)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'theta: '</span>,theta )</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'final loss: '</span>, loss)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'iters: '</span>, iter_count)</span><br></pre></td></tr></table></figure>
<p>最后的输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">theta:  [3.0044552563214433, 3.9955447274498894]</span><br><span class="line">final loss:  9.428456066652548e-05</span><br><span class="line">iters:  9</span><br></pre></td></tr></table></figure>
<h3 id="随机梯度下降法-Stochastic-gradientdescent-SGD"><a href="#随机梯度下降法-Stochastic-gradientdescent-SGD" class="headerlink" title="随机梯度下降法(Stochastic gradientdescent):SGD"></a>随机梯度下降法(Stochastic gradientdescent):SGD</h3><p>针对BGD算法训练速度过慢的缺点，提出了SGD算法，普通的BGD算法是每次迭代把所有样本都过一遍，每训练一组样本就把梯度更新一次。而SGD算法是从样本中随机抽出一组，训练后按梯度更新一次，然后再抽取一组，再更新一次，在样本量及其大的情况下，可能不用训练完所有的样本就可以获得一个损失值在可接受范围之内的模型了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment">#用y = Θ1*x1 + Θ2*x2来拟合下面的输入和输出</span></span><br><span class="line"><span class="comment">#input1  1   2   5   4</span></span><br><span class="line"><span class="comment">#input2  4   5   1   2</span></span><br><span class="line"><span class="comment">#output  19  26  19  20</span></span><br><span class="line">input_x = [[<span class="number">1</span>,<span class="number">4</span>], [<span class="number">2</span>,<span class="number">5</span>], [<span class="number">5</span>,<span class="number">1</span>], [<span class="number">4</span>,<span class="number">2</span>]]  <span class="comment">#输入</span></span><br><span class="line">y = [<span class="number">19</span>,<span class="number">26</span>,<span class="number">19</span>,<span class="number">20</span>]   <span class="comment">#输出</span></span><br><span class="line">theta = [<span class="number">1</span>,<span class="number">1</span>]       <span class="comment">#θ参数初始化</span></span><br><span class="line">loss = <span class="number">10</span>           <span class="comment">#loss先定义一个数，为了进入循环迭代</span></span><br><span class="line">step_size = <span class="number">0.01</span>    <span class="comment">#步长</span></span><br><span class="line">eps =<span class="number">0.0001</span>         <span class="comment">#精度要求</span></span><br><span class="line">max_iters = <span class="number">10000</span>   <span class="comment">#最大迭代次数</span></span><br><span class="line">error =<span class="number">0</span>            <span class="comment">#损失值</span></span><br><span class="line">iter_count = <span class="number">0</span>      <span class="comment">#当前迭代次数</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">while</span>( loss &gt; eps <span class="keyword">and</span> iter_count &lt; max_iters):    <span class="comment">#迭代条件</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    i = random.randint(<span class="number">0</span>,<span class="number">3</span>)  <span class="comment">#每次迭代在input_x中随机选取一组样本进行权重的更新</span></span><br><span class="line">    pred_y = theta[<span class="number">0</span>]*input_x[i][<span class="number">0</span>]+theta[<span class="number">1</span>]*input_x[i][<span class="number">1</span>] <span class="comment">#预测值</span></span><br><span class="line">    theta[<span class="number">0</span>] = theta[<span class="number">0</span>] - step_size * (pred_y - y[i]) * input_x[i][<span class="number">0</span>]</span><br><span class="line">    theta[<span class="number">1</span>] = theta[<span class="number">1</span>] - step_size * (pred_y - y[i]) * input_x[i][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range (<span class="number">3</span>):</span><br><span class="line">        pred_y = theta[<span class="number">0</span>]*input_x[i][<span class="number">0</span>]+theta[<span class="number">1</span>]*input_x[i][<span class="number">1</span>] <span class="comment">#预测值</span></span><br><span class="line">        error = <span class="number">0.5</span>*(pred_y - y[i])**<span class="number">2</span></span><br><span class="line">        loss = loss + error</span><br><span class="line">    iter_count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'iters_count'</span>, iter_count)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'theta: '</span>,theta )</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'final loss: '</span>, loss)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'iters: '</span>, iter_count)</span><br></pre></td></tr></table></figure>
<h3 id="小批量梯度下降-Mini-batch-gradient-descent-：MBGD"><a href="#小批量梯度下降-Mini-batch-gradient-descent-：MBGD" class="headerlink" title="小批量梯度下降(Mini-batch gradient descent)：MBGD"></a>小批量梯度下降(Mini-batch gradient descent)：MBGD</h3><p>SGD相对来说要快很多，但是也有存在问题，由于单个样本的训练可能会带来很多噪声，使得SGD并不是每次迭代都向着整体最优化方向，因此在刚开始训练时可能收敛得很快，但是训练一段时间后就会变得很慢。在此基础上又提出了小批量梯度下降法，它是每次从样本中随机抽取一小批进行训练，而不是一组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment">#用y = Θ1*x1 + Θ2*x2来拟合下面的输入和输出</span></span><br><span class="line"><span class="comment">#input1  1   2   5   4</span></span><br><span class="line"><span class="comment">#input2  4   5   1   2</span></span><br><span class="line"><span class="comment">#output  19  26  19  20</span></span><br><span class="line">input_x = [[<span class="number">1</span>,<span class="number">4</span>], [<span class="number">2</span>,<span class="number">5</span>], [<span class="number">5</span>,<span class="number">1</span>], [<span class="number">4</span>,<span class="number">2</span>]]  <span class="comment">#输入</span></span><br><span class="line">y = [<span class="number">19</span>,<span class="number">26</span>,<span class="number">19</span>,<span class="number">20</span>]       <span class="comment">#输出</span></span><br><span class="line">theta = [<span class="number">1</span>,<span class="number">1</span>]           <span class="comment">#θ参数初始化</span></span><br><span class="line">loss = <span class="number">10</span>               <span class="comment">#loss先定义一个数，为了进入循环迭代</span></span><br><span class="line">step_size = <span class="number">0.01</span>        <span class="comment">#步长</span></span><br><span class="line">eps =<span class="number">0.0001</span>             <span class="comment">#精度要求</span></span><br><span class="line">max_iters = <span class="number">10000</span>       <span class="comment">#最大迭代次数</span></span><br><span class="line">error =<span class="number">0</span>                <span class="comment">#损失值</span></span><br><span class="line">iter_count = <span class="number">0</span>          <span class="comment">#当前迭代次数</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">while</span>( loss &gt; eps <span class="keyword">and</span> iter_count &lt; max_iters):  <span class="comment">#迭代条件</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="comment">#这里每次批量选取的是2组样本进行更新，另一个点是随机点+1的相邻点</span></span><br><span class="line">    i = random.randint(<span class="number">0</span>,<span class="number">3</span>)     <span class="comment">#随机抽取一组样本</span></span><br><span class="line">    j = (i+<span class="number">1</span>)%<span class="number">4</span>                 <span class="comment">#抽取另一组样本，j=i+1</span></span><br><span class="line">    pred_y0 = theta[<span class="number">0</span>]*input_x[i][<span class="number">0</span>]+theta[<span class="number">1</span>]*input_x[i][<span class="number">1</span>]  <span class="comment">#预测值1</span></span><br><span class="line">    pred_y1 = theta[<span class="number">0</span>]*input_x[j][<span class="number">0</span>]+theta[<span class="number">1</span>]*input_x[j][<span class="number">1</span>]  <span class="comment">#预测值2</span></span><br><span class="line">    theta[<span class="number">0</span>] = theta[<span class="number">0</span>] - step_size * (<span class="number">1</span>/<span class="number">2</span>) * ((pred_y0 - y[i]) * input_x[i][<span class="number">0</span>]+(pred_y1 - y[j]) * input_x[j][<span class="number">0</span>])  <span class="comment">#对应(4)式</span></span><br><span class="line">    theta[<span class="number">1</span>] = theta[<span class="number">1</span>] - step_size * (<span class="number">1</span>/<span class="number">2</span>) * ((pred_y0 - y[i]) * input_x[i][<span class="number">1</span>]+(pred_y1 - y[j]) * input_x[j][<span class="number">1</span>])  <span class="comment">#对应(4)式</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range (<span class="number">3</span>):</span><br><span class="line">        pred_y = theta[<span class="number">0</span>]*input_x[i][<span class="number">0</span>]+theta[<span class="number">1</span>]*input_x[i][<span class="number">1</span>]     <span class="comment">#总预测值</span></span><br><span class="line">        error = (<span class="number">1</span>/(<span class="number">2</span>*<span class="number">2</span>))*(pred_y - y[i])**<span class="number">2</span>                    <span class="comment">#损失值</span></span><br><span class="line">        loss = loss + error       <span class="comment">#总损失值</span></span><br><span class="line">    iter_count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'iters_count'</span>, iter_count)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> (<span class="string">'theta: '</span>,theta )</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'final loss: '</span>, loss)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'iters: '</span>, iter_count)</span><br></pre></td></tr></table></figure>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1].例子<a href="https://blog.csdn.net/Softdiamonds/article/details/80339083#" target="_blank" rel="noopener">https://blog.csdn.net/Softdiamonds/article/details/80339083#</a></p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>目标函数和损失函数</title>
    <url>/2020/07/25/machine%20learning/%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E5%92%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>度量的是预测值和真实值之间的差异。损失函数通常写成$L(\hat{y},y)$，这里$\hat{y}$表示预测值，$y$表示真实值。比如平方差损失函数$L(\hat{y},y)=(\hat{y}-y)^2$。</p>
<h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>更为宽泛的概念。</p>
<p>目标函数是优化问题中的概念。</p>
<details>   
    <summary>优化问题包括</summary>
    (1).目标函数，最终是要最大化或者最小化的函数；</br>
    (2).约束条件：约束条件是可选的，如x<0，
     </details>

<h3 id="区分两者的例子"><a href="#区分两者的例子" class="headerlink" title="区分两者的例子"></a>区分两者的例子</h3><h4 id="既是损失函数又是目标函数的例子"><a href="#既是损失函数又是目标函数的例子" class="headerlink" title="既是损失函数又是目标函数的例子"></a>既是损失函数又是目标函数的例子</h4><p><strong>最小二乘的拟合函数：</strong></p>
<p>给定一组的样本点$\{(x_1,y_1),…,(x_n,y_n)\}$,我们要求用一条直线去拟合这些样本点。假设求出的模型形式为$y=\beta^Tx$。然后最小化下面的方程：</p>
<script type="math/tex; mode=display">
arg~\underset{\beta}{min}\{\sum_{i=0}^n(\beta^Tx_i-y_i)^2\}</script><p>这里这个式子既是损失函数，也是目标函数。</p>
<h4 id="是目标函数但大于损失函数"><a href="#是目标函数但大于损失函数" class="headerlink" title="是目标函数但大于损失函数"></a>是目标函数但大于损失函数</h4><p><strong>脊回归(Ridge regression)：</strong></p>
<p>需要对$\beta$做正则化处理。需要优化的函数变成：</p>
<script type="math/tex; mode=display">
arg~\underset{\beta}{min}\{\sum_{i=0}^n(\beta^Tx_i-y_i)^2+\lambda\beta^T\beta\}</script><p>上式可以称作目标函数，但却不是损失函数。损失函数仅仅是其中的一部分</p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>(DeepWalk)online Learning of Social Representation</title>
    <url>/2020/04/17/paper/(DeepWalk)online%20Learning%20of%20Social%20Representation/</url>
    <content><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>构建分层softmax有什么用？？</p>
<p>独立性假设？？？</p>
<p>标签应该用什么向量来表示？？？？？？</p>
<p>这里为什么可以用独立性假设</p>
<p>这里的J是不是有问题？不应该是连乘式嘛？</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/clipboard.png" alt="img"></p>
<h1 id="0-简介"><a href="#0-简介" class="headerlink" title="0 简介"></a>0 简介</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">论文英文：online Learning of Social Representation.</span><br><span class="line">论文中文：社交表征的在线学习</span><br><span class="line">发表期刊：2014的KDD会议上</span><br><span class="line">作者：</span><br><span class="line">Bryan Perozzi, Stony Brook University, Stony Brook, NY, USA</span><br><span class="line">Rami Al-Rfou, Stony Brook University, Stony Brook, NY, USA</span><br><span class="line">Steven Skiena, Stony Brook University, Stony Brook, NY, USA</span><br></pre></td></tr></table></figure>
<p><strong>嵌入、词嵌入、网络嵌入</strong></p>
<p><strong>DeepWalk：</strong>DeepWalk把一个图或网络作为输入，输出为网络中顶点的向量表示。通过截断随机游走（truncated random walk）学习出一个网络的社会表示（social representation）(中心思想)，所谓的社会表示就是原来图中邻居的相似性、社区关系等特征表示。对这种关系编码得到低维的、有丰富含义的顶点向量表示。</p>
<p>deepwalk是将截断随机游走和神经语言模型结合形成的网络表示。</p>
<p><strong>映射函数$\Phi$：</strong>实现将网络中的节点映射成向量，便于计算。</p>
<h1 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1 背景介绍"></a>1 背景介绍</h1><pre><code>  1.使用机器学习的算法解决问题需要大量的信息，而现实生活中的网络信息较少。为了将机器学习的算法应用在现实网络中，要对信息较少的网络（稀疏性网络，社交网络）进行处理。
</code></pre><p><strong>DeepWalk</strong>通过构建的short random walk流学习Graph中顶点的social representation。Social representations是关于顶点的邻居相似性、社区关系的一种隐含的特征表示，通过对上述关系的编码得到一种低维的、具有丰富含义的向量表示，也即embedding vector。</p>
<h1 id="2-问题描述-相关概念"><a href="#2-问题描述-相关概念" class="headerlink" title="2 问题描述+相关概念"></a>2 问题描述+相关概念</h1><p><strong>普通图的表示：</strong></p>
<p>令G =(V,E)，其中V表示网络的节点，E是网络中的连接，$E\subseteq(V\times V)$。</p>
<p><strong>标注图的表示（labeled social network）:</strong></p>
<p>G的基础上加上所有顶点的向量表示的矩阵X和所有顶点所属的标签构成的矩阵Y</p>
<blockquote>
<p>网络节点分类问题中每个顶点都有一个类别，所属的类别即为该顶点的标注</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online.png" alt="DW-online" style="zoom:50%;" /></p>
<p>​       X是将每个顶点的向量结合在一起形成的矩阵</p>
<p>​        Y是每个顶点的标签构成的集合</p>
<p><strong>学习网络表示注意的几个性质：</strong></p>
<p>适用性（Adaptability）:网络要适应网络的变化，对于新的节点和边添加可以处理，正常演化</p>
<p>同节点类似表示性(Community aware):网络中结构相似的点表示成的向量也相似</p>
<p>低维性(Low dimensional): 代表每个顶点的向量维数不能过高，过高会过拟合。</p>
<p>连续性(Continuous):低维的向量应当连续。</p>
<p><strong>网络嵌入和词嵌入：(word embedding and network embedding)</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>网络嵌入</th>
<th>词嵌入</th>
</tr>
</thead>
<tbody>
<tr>
<td>可用向量表示单元&amp;&amp;基本处理单元</td>
<td>网络节点</td>
<td>单词</td>
</tr>
<tr>
<td>分析</td>
<td>对节点的表示中节点构成的随机游走序列进行分析</td>
<td>对构成一个句子的单词序列进行分析</td>
</tr>
</tbody>
</table>
</div>
<p><strong>嵌入的理解：（Embedding）</strong></p>
<p>词嵌入，网络嵌入中的嵌入是<font color='blue'>学习这些内容的本质特征和内在含义的意思</font></p>
<p>网络嵌入：将节点转化为向量，挖掘节点的本质特征（语义，属性等性质上的相似性转化为向量空间上的相似性）</p>
<p>网络嵌入是将节点表示成低微向量，用向量的余弦距离表示节点的相连关系，余弦距离越近，表示有相连关系。</p>
<p><strong>随机游走（random walk）:</strong></p>
<p>网络上不断重复地随机选择游走路径，最终形成一条贯穿网络的路径；</p>
<p>从某个特定的端点开始，游走的每一步都从与当前节点相连的边中随机选择一条，沿着选定的边移动到下一个顶点，不断重复这个过程。</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online3.png" alt="DW-online3" style="zoom:50%;" /></p>
<p>截断随机游走==长度固定的随机游走。</p>
<p><strong>随机游走的两个好处：</strong></p>
<ul>
<li>并行性：随机游走是局部的，可以多个顶点同时开始一定长度的随机游走。减少采样的时间。</li>
<li>适应性：适应网络局部的变化，网络演化是局部的点和边的变化，这样的变化只对部分随机游走路径产生影响。</li>
</ul>
<h1 id="3-语言建模扩展到网络节点表示"><a href="#3-语言建模扩展到网络节点表示" class="headerlink" title="3 语言建模扩展到网络节点表示"></a>3 语言建模扩展到网络节点表示</h1><p><a href="https://zhuanlan.zhihu.com/p/45167021（推理部分）" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/45167021（推理部分）</a></p>
<p><strong>类比过程：</strong></p>
<p>语言建模的目标是估计出现在语料库中的特定序列的可能性。即，给定$W_n=(w_0,w_1,…,w_n)$的序列，其中$w_i\in V$（V是词汇表），我们想最大化$P_r(w_n|w_0,w_1,..w_{n-1})$。在最近的工作中，语言建模扩展到使用概率神经网络来构建词语的一般表示。</p>
<p>随机游走得到的序列可以被认为是一种特殊语言的短句，类比语言建模可以得到：在随机游走中给定迄今为止访问的所有先前顶点$(v_1,v_2,…,v_{i-1})$的情况下，下一个顶点是$v_i$的可能性可以表示为：</p>
<script type="math/tex; mode=display">
P_r(v_i|(v_1,v_2,...,v_{i-1}))\tag{1}</script><p><strong>引入”节点—向量的映射“：</strong></p>
<p>对于(1)而言，顶点是没办法计算的，因此要引入<font color='red'>映射函数</font>$\Phi:v\in V \rarr R^{|V|\times d}$。将网络中的每一个节点映射成d维向量，得到一个矩阵，共有|V|xd个参数，这些参数需要学习。</p>
<p>则原先(1)的<font color='red'>优化目标</font>就可以写成：</p>
<script type="math/tex; mode=display">
P_r(v_i|(\Phi(v_0),\Phi(v_1),...,\Phi(v_{i-1})))\tag{2}</script><p><strong>引入”松弛（relaxation）假设“：</strong></p>
<p>​    但是随着walk的增长，$(\Phi(v_0),\Phi(v_1),…,\Phi(v_{i-1}))$这一部分太难计算。因此，借用词向量中的skip-gram模型，引入松弛假设：</p>
<ul>
<li><p>不是通过上下文预测缺失词(missing word)，而是使用缺失词来预测上下文。因此，只需要计算一个$\Phi(v_k)$就可以，其中$v_k$是缺失词。</p>
</li>
<li><p>同时考虑左边窗口和右边窗口。如下图橘黄色部分，$v_4$同时考虑左边和右边的2个窗口内的节点：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/deepwalk-窗口.jpg" alt="deepwalk-窗口" style="zoom:40%;" /></p>
</li>
<li><p>不考虑顺序，只要是窗口中出现的词都算进来，而不管它具体出现在窗口的哪个位置。即无序性。</p>
</li>
</ul>
<p><strong>得到：最终优化目标函数：</strong></p>
<script type="math/tex; mode=display">
\underset{\Phi}{minimize}~-log[P_r(\{v_{i-w},...,v_{i-1},v_{i+1},...,v_{i+w}\}|\Phi(v_i))]</script><blockquote>
<p>这里概率部分的意思是：在一个随机游走中，当给定一个顶点$v_i$时，出现在它的w窗口范围内顶点的概率。</p>
<p>忽视顶点的顺序更好地体现了在随机游走中顶点的邻近关系，真正需要计算的是一个顶点$v_i$的向量</p>
</blockquote>
<h1 id="4-算法"><a href="#4-算法" class="headerlink" title="4 算法"></a>4 算法</h1><p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online8.png" alt="DW-online8"></p>
<p><em>图3.DeepWalk算法框架</em></p>
<p>DeepWalk的算法包含两个部分，一个部分是随机游走的生成，另一部分是参数的更新</p>
<p><strong>1.主体部分：</strong></p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online9.png" alt="DW-online9"></p>
<p>其中第2步是构建Hierarchical Softmax，第3步对每个节点做γ次随机游走，第4步打乱网络中的节点，第5步以每个节点为根节点生成长度为t的随机游走，第7步根据生成的随机游走使用skip-gram模型利用梯度的方法对参数进行更新。</p>
<p><strong>2.参数更新部分：</strong></p>
<p>skip-gram是一个语言模型，用于最大化句子中出现在窗口w内的单词之间的共现概率。用独立性假设，将等式3中的条件概率近似为</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online10.png" alt="DW-online10"></p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online11.png" alt="DW-online11"></p>
<p>对随机游走序列中的每个顶点，先把它映射到它的当前表示向量Φ(vj)（参见图3(b)）；然后通过随机梯度下降算法，最大化出现在上下文中的所有单词的概率，以此更新向量表示。</p>
<p><strong>3.Hierarchical Softmax</strong></p>
<p>给定uk∈V，直接计算第3行的Pr(uk|Φ(vj))是不可行的，我们将使用Hierarchical Softmax来分解条件概率。</p>
<p>我们将网络中的顶点分配为二叉树的叶子节点，将问题转化为最大化层级中特定路径的概率（参见图3(c)）。如果顶点uk的路径由一系列树节点(b0，b1，…，b[log |V|])来标识，其中，b0=vj，b[log |V|]= uk，那么</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online12.png" alt="DW-online12"></p>
<p>Pr(bl|Φ(vj))可以通过对bl的父节点建模一个二元分类器实现，计算公式为：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online13.png" alt="DW-online13"></p>
<p>(这里的公式二元分类器)</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online14.png" alt="DW-online14"></p>
<h1 id="八-实验"><a href="#八-实验" class="headerlink" title="八.实验"></a>八.实验</h1><p><a href="https://www.jianshu.com/p/5adcc3d94159" target="_blank" rel="noopener">https://www.jianshu.com/p/5adcc3d94159</a>  参照实验部分</p>
<p><strong>1.数据集：</strong></p>
<ul>
<li>BlogCatalog是博客作者的社交关系网络。标签代表作者提供的主题类别。</li>
<li>Flickr是照片分享网站用户之间的联系网络。标签代表用户的兴趣组。</li>
<li>YouTube是流行的视频分享网站用户之间的社交网络。标签代表喜欢不同类视频的观众群体。</li>
</ul>
<p><strong>2.对比算法</strong></p>
<ul>
<li>SpectralClustering</li>
<li>Modularity</li>
<li>EdgeCluster</li>
<li>wvRN</li>
<li>Majority</li>
</ul>
<p><strong>3.实验设计</strong></p>
<h1 id="九-总结"><a href="#九-总结" class="headerlink" title="九.总结"></a>九.总结</h1><p>学习顶点潜在表示的新方法，对语言建模算法的一般化。DeepWalk可扩展，可为大规模、稀疏的图创建有意义的表示。</p>
<h1 id="十-参考文献"><a href="#十-参考文献" class="headerlink" title="十.参考文献"></a>十.参考文献</h1><p>[1].deepwalk理解：<a href="https://zhuanlan.zhihu.com/p/45167021" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/45167021</a></p>
<p>[2].论文参考翻译：<a href="https://www.jianshu.com/p/5adcc3d94159" target="_blank" rel="noopener">https://www.jianshu.com/p/5adcc3d94159</a></p>
<p>[3].工具：<a href="https://github.com/phanein/deepwalk" target="_blank" rel="noopener">https://github.com/phanein/deepwalk</a></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>deepwalk</tag>
      </tags>
  </entry>
  <entry>
    <title>(Trans系列)</title>
    <url>/2020/04/18/paper/(Trans%E7%B3%BB%E5%88%97)/</url>
    <content><![CDATA[<p><strong>论文情况</strong></p>
<p>目前基于翻译模型（Trans系列）的知识表示学习的研究情况</p>
<p>TransE, NIPS2013, Translating embeddings for modeling multi-relational data</p>
<p>TransH, AAAI2014, Knowledge graph embedding by translating on hyperplanes</p>
<p>TransR, AAAI2015, Learning Entity and Relation Embeddings for Knowledge Graph Completion</p>
<p>TransD, ACL2015, Knowledge graph embedding via dynamic mapping matrix</p>
<p>TransA, arXiv2015, An adaptive approach for knowledge graph embedding</p>
<p>TranSparse, AAAI2016, Knowledge graph completion with adaptive sparse transfer matrix</p>
<p>TransG, arXiv2015, A Generative Mixture Model for Knowledge Graph Embedding</p>
<p>KG2E, CIKM2015, Learning to represent knowledge graphs with gaussian embedding</p>
<hr>
<h1 id="Mean-rank，Hit-10的理解"><a href="#Mean-rank，Hit-10的理解" class="headerlink" title="Mean rank，Hit@10的理解"></a>Mean rank，Hit@10的理解</h1><h3 id="1-Mean-rank"><a href="#1-Mean-rank" class="headerlink" title="1.Mean rank:"></a>1.Mean rank:</h3><p>对于每个testing triple，以预测tail entity为例，将(h,r,t)中的t用知识图谱中的每个实体代替，通过fr(h,t)函数计算分数，得到的一系列分数升序排列，f函数值越小越好-排的越靠前越好。然后去看每个testing triple中正确答案也即真实的t在序列中排多少位，比如t1排100位，t2排200，t3排60，然后对这些排名求平均,Mean rank即可以得到。</p>
<h3 id="2-Hit10"><a href="#2-Hit10" class="headerlink" title="2.Hit10:"></a>2.Hit10:</h3><p>按照上述进行f函数值排列，然后去看每个testing triple的正确答案是否排在序列的前十，如果在的话就计数+1,然后，最终排在前十的个数/总个数 ，就是Hit@10.</p>
<h1 id="参考的"><a href="#参考的" class="headerlink" title="参考的"></a>参考的</h1><p><a href="https://blog.csdn.net/wp_csdn/article/details/79607727" target="_blank" rel="noopener">https://blog.csdn.net/wp_csdn/article/details/79607727</a></p>
<p><a href="https://www.jianshu.com/p/f1ba68064343" target="_blank" rel="noopener">https://www.jianshu.com/p/f1ba68064343</a></p>
<p>书籍-《知识图谱》 -第九章的第四节</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>表示学习与深度学习</title>
    <url>/2020/05/26/machine%20learning/%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="My"><a href="#My" class="headerlink" title="My"></a>My</h3><p>表示学习就是将原始数据转换成计算机能有效识别的特征，又分为局部表示和分布式表示。局部表示是用某一维来表示原始数据的某一实体，而分布式表示则是用向量整体来表示，是低维稠密向量。</p>
<p>嵌入则是将局部表示转换成分布式表示。</p>
<p>深度学习则是如何有效表示学习+实现这种表示学习的算法。最终目标是提高模型的准确性。</p>
<h3 id="1-表示学习"><a href="#1-表示学习" class="headerlink" title="1 表示学习"></a>1 表示学习</h3><blockquote>
<p>定义：<strong>为了提高机器学习系统的准确率，我们就需要将输入信息转换为有效的特征，或者更一般性称为表示（Representation）。如果有一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就是可以叫做表示学习（Representation Learning）</strong>。</p>
</blockquote>
<p><strong>关键：</strong>解决语义鸿沟问题。(输入数据的底层特征和高层语义信息之间的不一致和差异性)，比较好的是在高层语义信息上进行预测模型建模。</p>
<p><strong>核心问题：</strong>1.“什么是一个好的表示”；2.“如何学习到好的表示”。</p>
<p><strong>好的表示学习的优点：</strong>1.较强的表示能力；2.包含更高层的语义信息，使得后续的学习任务变得简单；3.具有一般性，任务或领域独立。</p>
<p><strong>两种表示学习方式：</strong>1.局部表示(Local Representation)；2.分布式表示(Distributed Representation).</p>
<p><strong>表示学习的关键：</strong>构建具有一定深度的多层次特征表示。</p>
<h4 id="1-1-局部表示"><a href="#1-1-局部表示" class="headerlink" title="1.1 局部表示"></a>1.1 局部表示</h4><p>一般表示为向量的形式。“one-hot”局部表示，以不同的名字来命名不同的颜色，相当于给颜色取了一个代号，比如(0,0,0,1,0)表示红色，(1,0,0,0)表示绿色，也称作离散表示或符号表示。</p>
<p><strong>局部表示的两个不足之处：</strong>1.one-hot向量的维数很高，不能扩展。若有一种新的颜色出现，则需要增加一维，所对应的神经网络改动会很大。2.不能很好地刻画不同颜色之间的相似度。</p>
<h4 id="1-2-分布式表示"><a href="#1-2-分布式表示" class="headerlink" title="1.2 分布式表示"></a>1.2 分布式表示</h4><p>可以表示为低维的稠密向量。举例：表示颜色的方法可以为RGB值，不同的颜色对应R，G，B三维空间中的一个点。如(255,255,255)表示白色，(0,0,0)表示黑色，也即相较于局部表示，分布式表示用稠密向量的整体表示某个实体，而局部表示则是用某一维来表示某个实体。</p>
<h4 id="1-3-嵌入-Embedding"><a href="#1-3-嵌入-Embedding" class="headerlink" title="1.3 嵌入(Embedding)"></a>1.3 嵌入(Embedding)</h4><p>使用神经网络将高维的局部表示空间$\R^{|v|}$,映射到一个非常低维的分布式表示空间$\R^d$中。使得特征不再是坐标轴上的点，而是分散在整个低维空间中。如下图所示</p>
<p><img src ="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/局部表示嵌入到分布式表示.png" width="300"/></p>
<p><strong>嵌入：</strong>将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的拓扑关系。</p>
<p><strong>“好的高层语义表示：”</strong>从底层特征开始，经过多步非线性转换得到。</p>
<h3 id="2-深度学习"><a href="#2-深度学习" class="headerlink" title="2.深度学习"></a>2.深度学习</h3><p>为了学习一种好的表示，构建一种有深度的模型，并通过学习算法让模型自动学习出特征表示(底层特征-&gt;中层特征-&gt;高层特征)，最终提升预测模型的准确率。</p>
<p><strong>深度：</strong>原始数据进行非线性特征转换的次数，若一个表示学习系统是一个有向图结构，则深度也是从输入节点到输出节点所经过的最长路径的长度。</p>
<p><strong>深度学习和表示学习的关系：</strong></p>
<p><img src ="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/深度学习和表示学习.png" /></p>
<p><strong>深度学习要解决的关键问题：</strong>贡献度分配问题，一个系统的不同组件或参数对于最终输出结果的贡献或影响。即模型的各个部分对于最终结果的影响程度。深度学习主要采用的模型是神经网络模型，利用神经网络的反向误差传播算法来解决各个部分贡献度分配问题。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>表示学习与深度学习<a href="https://www.jianshu.com/p/b1dcd8811326" target="_blank" rel="noopener">https://www.jianshu.com/p/b1dcd8811326</a></p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>(node2vec)Scalable Feature Learning for Networks</title>
    <url>/2020/04/17/paper/(node2vec)Scalable%20Feature%20Learning%20for%20Networks/</url>
    <content><![CDATA[<h3 id="1-问题"><a href="#1-问题" class="headerlink" title="-1 问题"></a>-1 问题</h3><p>本文最终的输出是什么？和目标函数有什么关系？</p>
<h3 id="0-简介"><a href="#0-简介" class="headerlink" title="0 简介"></a>0 简介</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">论文英文：Scalable Feature Learning for Networks</span><br><span class="line">论文中文：面向网络的可扩展特征学习</span><br><span class="line">发表期刊：KDD 2016</span><br></pre></td></tr></table></figure>
<p><strong>node2vec主要思想：</strong>生成随机游走采样得到（节点，上下文）的组合，然后用处理词向量的方法对这样的组合建模得到网络节点的表示。</p>
<p><strong>论文的创新点：</strong>在生成随机游走的过程中做了一些创新。</p>
<p>思想和DeepWalk是一样的，但是改进了DeepWalk中随机游走的生成方式，使得生成的随机游走可以反映深度游走和广度游走的特性。</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p><strong>复杂网络面对的几种任务：</strong></p>
<ul>
<li>网络节点的分类（网络中的节点进行聚类，哪些节点有类似的属性，就将其分到同一个类别中）</li>
<li>链接预测（预测网络中哪些顶点有潜在的关联）</li>
</ul>
<p><strong>本文的工作：</strong></p>
<p>设计出既能保持节点邻居信息又容易训练的模型</p>
<p><strong>网络中的结构特征（社区）：</strong></p>
<p>社区：很多节点会聚集在一起，内部的连接远比外部的连接多。</p>
<blockquote>
<p>相当于一个集群的概念</p>
</blockquote>
<p>网络中两个可能相聚很远的节点，在边的连接上有着类似的特征。</p>
<p>如下面的$u,S_1,S_2,S_3,S_4$就是一个社区，u和$S_6$在结构上有着相似的特征</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/node2vec-社区.png" alt="node2vec-社区" style="zoom:50%;" /></p>
<p><strong>网络表示学习算法要满足：</strong></p>
<ul>
<li>同一个社区内的节点表示相似</li>
<li>拥有类似结构的节点表示相似</li>
</ul>
<h1 id="2-Related-Works"><a href="#2-Related-Works" class="headerlink" title="2 Related Works"></a>2 Related Works</h1><p>之前的工作存在着的一些问题：</p>
<ul>
<li>特征需要依赖人手工定义，本身就不准确</li>
<li>一些非监督学习中的降维方法被拿来使用，但效率低，准确度不够，不能反应出网络的结构特征</li>
</ul>
<h1 id="3-模型介绍"><a href="#3-模型介绍" class="headerlink" title="3 模型介绍"></a>3 模型介绍</h1><h4 id="3-1-模型目标函数及推导："><a href="#3-1-模型目标函数及推导：" class="headerlink" title="3.1 模型目标函数及推导："></a>3.1 模型目标函数及推导：</h4><p><strong>初始目标函数（objective function）：</strong></p>
<script type="math/tex; mode=display">
\underset{f}{max}\sum_{u\in V}logPr(N_s(u)|f(u)) \tag{1}</script><p>$f(u)$是当前节点，$N_s(u)$是邻居节点。</p>
<p><font color='red'>优化目标是给定每个顶点条件下，令其邻近顶点出现的概率最大。</font>，因此是对数和的形式。</p>
<p><strong>引入的两个假设：</strong></p>
<ul>
<li><strong>条件独立性（Conditional independence）：</strong>也即采样的每个邻居是相互独立的，若要计算采样所有邻居的概率只需要将采样每个邻居的概率相乘即可，公式如下：</li>
</ul>
<script type="math/tex; mode=display">
P_r(N_s(u)|f(u))=\prod_{n_i\in N_s(u)}P_r(n_i|f(u))\tag{2}</script><ul>
<li><strong>特征空间的对称性（Symmetry in feature space）：</strong>一条边连接了a和b，则映射到特征空间时，a对b的影响和b对a的影响是一样的。一个顶点作为源顶点和作为近邻顶点时共享一套embedding向量。由一个模型表示一个（节点，邻居）对：</li>
</ul>
<script type="math/tex; mode=display">
P_r(n_i|f(u))=\frac{exp(f(n_i)\cdot f(u))}{\sum_{v\in V }exp(f(v)\cdot f(u))}\tag{3}</script><p><strong>最终的优化目标函数：</strong></p>
<p>将(1)、(2)、(3) 三个公式结合起来推导得到最终的优化结果：</p>
<script type="math/tex; mode=display">
\underset{f}{max}\sum_{u\in V}[-logZ_u+\sum_{n_i\in N_s(u)}f(n_i)\cdot f(u)]</script><p>其推导过程如下：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/node2vec的公式推导.jpg" alt="node2vec的公式推导" style="zoom:40%;" /></p>
<p>推导完后，应该有一个$|N_s(u)|$的系数，但这一部分并不出现在最终的损失函数中，是因为整个这一项$|N_s(u)|logZ_u$都是常数的原因。</p>
<p>这里注意两点：</p>
<p>​        1). $Z_u$直接计算特别费时，本文是Negative Sampling方式解决。</p>
<p>​        2).$N_s(u)$未必是u的直接邻居，只是用s方法采样得到的邻居，和具体的采样方式有关。</p>
<h4 id="3-2-随机游走采样-创新的部分"><a href="#3-2-随机游走采样-创新的部分" class="headerlink" title="3.2 随机游走采样(创新的部分)"></a>3.2 随机游走采样(创新的部分)</h4><p><strong>两种图的游走方式：</strong></p>
<p>​        深度优先游走(Depth-first Sampling,DFS)，广度优先游走(BFS)</p>
<p>​        BFS倾向于在初始节点的周围游走，反映处一个节点的邻居的微观特性；</p>
<p>​        DFS则会跑的离初始节点越来越远，反映出一个节点邻居的宏观特性。</p>
<p><strong>本文工作：改进DeepWalk中随机游走的方式，综合DFS和BFS的特性。</strong></p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/node2vec-随机游走.png" alt="node2vec-随机游走" style="zoom:40%;" /></p>
<p>对于这个随机游走，若已经采样了(t,v)，现在停留在节点v上，则下一个要采样的节点x遵循以下的概率分布：(一个节点到它不同邻居的转移概率：)</p>
<script type="math/tex; mode=display">
\alpha_{pq}(t,x)=\begin{cases}
\frac{1}{p} &if~d_{tx}=0\\
1 & if~d_{tx}=1\\
\frac{1}{q} &if~d_{tx}=2
\end{cases}</script><blockquote>
<p>若t与x相等，则采样x的概率为$\frac{1}{p}$，即往回采样，采样已经访问过的节点t</p>
<p>若t与x相连，则采样x的概率为1，这是一定采样相邻的节点$x_1$；</p>
<p>若t与x不相连，则采样x的概率为$\frac{1}{q}$，这是采样不相邻的节点$x_2,x_3$。</p>
</blockquote>
<p><strong>超参数p、q的意义：</strong></p>
<p>​    返回参数p：</p>
<p>​        若$p&gt;max(q,1)$，则采样会尽量不往回走，不太可能是上一个访问的节点t</p>
<p>​        若$p&lt;min(q,1)$，则采样更倾向于返回上一个节点，则会一直在起始点周围的某些节点来回转。</p>
<p>​    出入参数q：</p>
<p>​        q控制着游走是向外还是向内，若q&gt;1，随机游走倾向于访问和t接近的顶点（偏向于BFS）。若q&lt;1，倾向于访问远离t的顶点（偏向于DFS）</p>
<p>这里当p=1，q=1时，游走方式就等同于DeepWalk中的随机游走。</p>
<h1 id="六-算法部分"><a href="#六-算法部分" class="headerlink" title="六.算法部分"></a>六.算法部分</h1><p>按概率抽取，采用了Alias算法进行顶点采样</p>
<p><img src="D:\有道云存储\qq4EC68D37BEC205269D5190F466ABEE14\9908a908f1cf4930976bd7d526e99348\clipboard.png" alt="img"></p>
<p>算法的参数+部分：</p>
<p>图G，表示向量维度d，每个节点生成的游走个数r，游走长度I，上下文的窗口长度k，还有p,q参数。</p>
<p>1.根据p,q和之前的公式计算一个节点到它的邻居的转移概率。</p>
<p>2.将这个转移概率加到图G中形成G’。</p>
<p>3.walks用来存储随机游走，初始化为空。</p>
<p>4.外循环r次表示每个节点作为初始节点要生成r个随机游走。</p>
<p>5.对于图中的各个节点。</p>
<p>6.生成一条随机游走walk。</p>
<p>7.将walk添加到walks中保存。</p>
<p>8.用SGD的方法对walks进行训练。</p>
<p>1.将初始节点u添加进去。</p>
<p>2.walk的长度为I，由此还要再循环添加I-1个节点。</p>
<p>3.当前节点设为walk最后添加的节点。</p>
<p>4.找出当前节点的所有邻居节点。</p>
<p>5.根据转移概率采样选择某个邻居s</p>
<p>6.将该邻居添加到walk中。</p>
<p><strong>此处有不懂的地方？？？？？</strong></p>
<h1 id="七-Node2vec核心代码"><a href="#七-Node2vec核心代码" class="headerlink" title="七.Node2vec核心代码"></a>七.Node2vec核心代码</h1><p><a href="https://blog.csdn.net/u012151283/article/details/87081272" target="_blank" rel="noopener">https://blog.csdn.net/u012151283/article/details/87081272</a></p>
<h1 id="八-实验部分"><a href="#八-实验部分" class="headerlink" title="八.实验部分"></a>八.实验部分</h1><p><strong>实验部分？？？？？？？？？？</strong></p>
<p><img src="D:\有道云存储\qq4EC68D37BEC205269D5190F466ABEE14\447b2a1282f14e2eaef542a225ccc8a2\clipboard.png" alt="img"></p>
<p><img src="D:\有道云存储\qq4EC68D37BEC205269D5190F466ABEE14\15b2e0dbe7074368a67182f0103f3e5b\clipboard.png" alt="img"></p>
<h1 id="十-参考论文"><a href="#十-参考论文" class="headerlink" title="十.参考论文"></a>十.参考论文</h1><p>[1].论文翻译<a href="https://zhuanlan.zhihu.com/p/46344860" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46344860</a></p>
<p>[2].代码参考<a href="https://blog.csdn.net/u012151283/article/details/87081272" target="_blank" rel="noopener">https://blog.csdn.net/u012151283/article/details/87081272</a></p>
<p>[3].模型实现<a href="https://github.com/shenweichen/GraphEmbedding" target="_blank" rel="noopener">https://github.com/shenweichen/GraphEmbedding</a></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>node2vec</tag>
      </tags>
  </entry>
  <entry>
    <title>同构图和异构图</title>
    <url>/2020/07/18/machine%20learning/%E5%90%8C%E6%9E%84%E5%9B%BE%E5%92%8C%E5%BC%82%E6%9E%84%E5%9B%BE/</url>
    <content><![CDATA[<p>什么是同构图？什么是异构图，他们能够开展的工作有哪些？</p>
<h3 id="同构图-Homogeneous-Graph"><a href="#同构图-Homogeneous-Graph" class="headerlink" title="同构图(Homogeneous Graph)"></a>同构图(Homogeneous Graph)</h3><p>传统同构图数据中只存在一种节点和边，因此在构建图神经网络时所用节点共享同样的模型参数并且拥有同样的特征空间。</p>
<h3 id="异构图-Heterogeneous-Graph"><a href="#异构图-Heterogeneous-Graph" class="headerlink" title="异构图(Heterogeneous Graph)"></a>异构图(Heterogeneous Graph)</h3><p>可以存在不只一种节点和边，因此允许不同类型的节点拥有不同维度的特征或属性。</p>
<p>人和周围事物的关系大部分都是天然异构，如：“我看了《流浪地球》”。“我”和“《流浪地球》”的属性是不同的，需要用不同的模型或特征维度来表达。</p>
<p> <strong>基于异构图训练的神经网络比较有代表性的两个模型：</strong></p>
<p>​    1.用于节点分类和链接预测等任务的RGCN</p>
<p>​    2.用于产品推荐的GCMC。</p>
<p><strong>异构图神经网络框架DGL[1]：</strong></p>
<p> 纽约大学、亚马逊联手推出的神经网络框架DGL。</p>
<p>有各种异构图神经网络的实现方法，比如GCMC、RGCN、HAN、Metapath2vec</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1].从图到图卷积<a href="https://www.jianshu.com/p/d97afb87ef20" target="_blank" rel="noopener">https://www.jianshu.com/p/d97afb87ef20</a></p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
  </entry>
  <entry>
    <title>(word2vec第1弹)-向量空间中单词表示的有效评估</title>
    <url>/2020/04/18/paper/(word2vec)Efficient%20Estimation%20of%20Word%20Representations%20in%20Vector%20Space/</url>
    <content><![CDATA[<p>什么是N-gram模型？</p>
<p>随机梯度下降和反向传播算法。</p>
<p>RNN模型</p>
<p>题目</p>
<p>Efficient Estimation of Word Representations in Vector Space</p>
<p>背景说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.word2vec是用于词向量计算的工具</span><br><span class="line">2.该工具得到的训练结果：词向量(word embedding),度量词与词之间的相似性。</span><br><span class="line">3.word2vec算法的背后是一个浅层的神经网络</span><br><span class="line">4.word2vec算法或模型是指背后用于计算word vector的CBOW模型和Skip-gram模型。</span><br></pre></td></tr></table></figure>
<p>由google的Mikolov于2013年发表。</p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>两种新的模型体系结构，用于从非常大的数据集中计算单词的连续矢量表示。</p>
<p>准确性提高，计算成本降低很多。</p>
<p>用于句法和语义词的相似性。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h3><p>之前是将词作为原子之间的相似性的原子单位，并且在词汇表中表示为索引。典型的是N-gram模型。</p>
<p>但是这样简单的技术是有限制的，在自动语音识别（由高质量的转录语音数据大小决定）和机器翻译（现有较少的单词库）中，存储的数据是有限的。</p>
<p>引出使用单词的分布式表示，并且基于神经网络的语音模型优于N-gram模型。</p>
<h4 id="1-1-Goals-of-the-Paper"><a href="#1-1-Goals-of-the-Paper" class="headerlink" title="1.1 Goals of the Paper"></a>1.1 Goals of the Paper</h4><p><strong>主要目的</strong>：从词汇表中数十亿个单词和数以百计的单词的巨大数据集中引入可用于学习高质量单词矢量的技术。</p>
<p>单词矢量的最大维数在50~100之间。</p>
<p>所提出的技术：相似的单词趋于彼此接近，且单词可以有多个相似度。(若名词有多个单词结尾，则在原始矢量空间的子空间中搜索相似的单词，可以找到有相似结尾的单词。)</p>
<p><strong>单词表示的相似性：</strong>使用对单词向量执行简单代数运算的单词偏移技术，例如，显示出vector（“ King”）-vector（“ Man”）+ vector（“ Woman”）产生的矢量与单词Queen的矢量表示最接近 。</p>
<p><strong>本文的工作</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.开发保留词间线性规则性的新模型架构来最大化上述向量运算的准确性</span><br><span class="line">2.设计了一种新的综合测验集，用于测量句法和语义规律性，</span><br><span class="line">3.单词向量的维数和训练数据的数量对于训练时间和准确性的影响。</span><br></pre></td></tr></table></figure>
<h4 id="1-2-Previous-Work"><a href="#1-2-Previous-Work" class="headerlink" title="1.2 Previous Work"></a>1.2 Previous Work</h4><p>将单词作为连续向量的表示，典型的是<strong>NNLM模型</strong>。用于估计神经网络语言模型的模型架构。其中使用具有线性投影层和非线性隐藏层的前馈神经网络来共同学习单词向量表示和统计语言模型。</p>
<p>其中单词向量是使用带有单个隐藏层的神经网络进行精细学习的。 单词向量被训练为训练NNLM。 因此，即使不构建完整的NNLM，也可以学习单词向量。 在这项工作中，我们直接扩展了该体系结构，并重点关注了使用简单模型学习单词向量的第一步。</p>
<h3 id="2-Model-Architectures"><a href="#2-Model-Architectures" class="headerlink" title="2.Model Architectures"></a>2.Model Architectures</h3><p>评估单词的连续表示的模型有：Latent Semantic Analysis (LSA) 和 Latent Dirichlet Allocation (LDA)。本文中采用的是<strong>由神经网络学习的词的分布式表示形式</strong>，这种方式在保留词之间的线性规则上好于LSA，在大型数据集上，比LDA更为便宜。</p>
<p>对于接下来的这几个模型，模型的复杂度和下面的公式成比例：</p>
<script type="math/tex; mode=display">
O=E\times T \times Q</script><p>其中E是模型训练的Epochs的数目，T是training set中的单词的数目，Q是每个框架模型的进一步定义，一般的E=3~50，T高达十亿。下面的所有模型都采用随机梯度下降和反向传播训练。</p>
<h4 id="2-1-Feedforward-Neural-Net-Language-Model-NNLM"><a href="#2-1-Feedforward-Neural-Net-Language-Model-NNLM" class="headerlink" title="2.1 Feedforward Neural Net Language Model(NNLM)"></a>2.1 Feedforward Neural Net Language Model(NNLM)</h4><p>前馈神经网络语言模型</p>
<p>它由输入，投影，隐藏和输出层组成。 在输入层，使用1-of-V编码对N个先前的单词进行编码，其中V是词汇量。 然后，使用共享的投影矩阵将输入层投影到尺寸为N×D的投影层P上。 由于只有N个输入在给定时间处于活动状态，所以投影层的组成相对便宜。 由于投影层中的值很密集，NNLM体系结构在投影层和隐藏层之间的计算变得很复杂。 对于N = 10的常见选择，投影层（P）的大小可能为500到2000，而隐藏层的大小H通常为500到1000单位。 此外，隐藏层用于计算词汇表中所有单词的概率分布，从而导致维数为V的输出层。 因此，每个训练示例的计算复杂度为下式子(2)</p>
<script type="math/tex; mode=display">
Q=N\times D+N\times D\times H+H\times V ---(2)</script><p>其中主导项是H×V。但是，为避免这种情况提出了一些实际的解决方案。要么使用softmax的分层版本[25，23，18]，要么使用在训练过程中未标准化的模型来完全避免标准化模型[4，9]。用词汇表的二叉树表示，需要评估的输出单位数可以降低到log2（V）左右。因此，大多数复杂性是由项N×D×H引起的。在我们的模型中，我们使用层次化的软件最大值，其中词汇表示霍夫曼二叉树。这遵循先前的观察，即词频在神经网络语言模型中很容易获得类[16]。霍夫曼树将短的二进制代码分配给频繁的单词，这进一步减少了需要经过估值的输出单元的数量：而平衡二叉树需要对账本进行估值的log2（V），而基于霍夫曼树的分层软最大值仅需要log2（Unigram perplexity（V））。例如，当词汇量为一百万个单词时，这会使评估速度提高大约两倍。尽管对于N×D×H项中的计算瓶颈而言，这对于神经网络LM而言并不是至关重要的提速，但我们将提出一种建议，该结构必须具有隐藏层并且因此在很大程度上取决于softmax归一化的效率。</p>
<h3 id="2-2-Recurrent-Neural-Net-Language-Model-RNNLM"><a href="#2-2-Recurrent-Neural-Net-Language-Model-RNNLM" class="headerlink" title="2.2 Recurrent Neural Net Language Model (RNNLM)"></a>2.2 Recurrent Neural Net Language Model (RNNLM)</h3><p>递归神经网络语言模型。</p>
<p>已经提出了基于递归神经网络的语言模型来克服前馈NNLM的某些限制，例如需要指定上下文长度（模型N的顺序），并且因为理论上RNN可以比浅层神经网络更有效地表示更复杂的模式[15，2]。 RNN模型没有投影层。 仅输入，隐藏和输出层。 这种类型的模型的特殊之处在于递归矩阵，它使用延时连接将隐藏层与其自身相连。 这允许循环模型形成某种形式的短期内存，该信息是由隐藏层状态表示的过去的信息组成的，该信息根据当前输入和上一时间步中隐藏层的状态进行更新。 RNN模型的每个训练示例的复杂度为</p>
<script type="math/tex; mode=display">
Q=H\times H+H\times V---(3)</script><p>其中，单词表示D的维数与隐藏层H相同。再次，可以使用分层softmax有效地将术语H×V简化为H×log2（V）。 那么，大多数复杂度来自H×H。</p>
<h3 id="2-3-Parallel-Training-of-Neural-Networks"><a href="#2-3-Parallel-Training-of-Neural-Networks" class="headerlink" title="2.3  Parallel Training of Neural Networks"></a>2.3  Parallel Training of Neural Networks</h3><p>神经网络并行训练。</p>
<p>为了在海量数据集上训练模型，我们在称为DistBelief [6]的大规模分布式框架的基础上实现了多个模型，包括前馈NNLM和本文提出的新模型。 该框架允许我们并行运行同一模型的多个副本，并且每个副本通过保留所有参数的集中式服务器同步其梯度更新。 对于这种并行训练，我们使用称为Adagrad [7]的自适应学习速率程序进行小批量异步梯度下降。 在此框架下，通常使用一百个或多个模型副本，每个副本在数据中心的不同计算机上使用许多CPU内核。</p>
<h3 id="3-New-Log-linear-Models-对数线性模型"><a href="#3-New-Log-linear-Models-对数线性模型" class="headerlink" title="3 New Log-linear Models(对数线性模型)"></a>3 New Log-linear Models(对数线性模型)</h3><p>上面这些模型的非线性隐藏层导致了复杂性较高。新的架构直接遵循我们早期工作[13，14]中提出的架构，发现神经网络语言模型可以成功地分两个步骤进行训练：首先，使用简单模型对连续的单词向量进行学习，然后在这些单词的分布式表示之上限制N-gram NLM。 虽然后来有大量工作集中在学习单词向量上，但我们认为[13]中提出的简化简单方法的方法。 请注意，相关模型也已经提早提出[26，8]。</p>
<h4 id="3-1-Continuous-Bag-of-Words-Model-连续词袋模型"><a href="#3-1-Continuous-Bag-of-Words-Model-连续词袋模型" class="headerlink" title="3.1 Continuous Bag-of-Words Model(连续词袋模型)"></a>3.1 Continuous Bag-of-Words Model(连续词袋模型)</h4><p>所提出的第一个体系结构类似于前馈NNLM，其中去除了非线性隐藏层，并且所有单词都共享了投影层（不仅仅是投影矩阵）。因此，所有单词都投影到同一位置（对它们的向量进行平均）。我们将此架构称为“词袋模型”，因为历史中的词序不会影响投影。此外，我们也使用未来的话语。通过构建一个对数线性分类器，在输入中包含四个未来和四个历史单词，我们的训练标准是正确分类当前（中间）单词，从而在下一节介绍的任务上获得了最佳性能。那么训练的复杂度如下：</p>
<script type="math/tex; mode=display">
Q=N\times D+D\times \log_2(V)---(4)</script><p>我们将这个模型进一步称为CBOW，与标准的词袋模型不同，它使用上下文的连续分布式表示。该模型的体系结构如图1所示。请注意，输入和投影层之间的权重矩阵以与NNLM中相同的方式共享给所有单词位置。</p>
<h4 id="3-2-Continuous-Skip-gram-Model"><a href="#3-2-Continuous-Skip-gram-Model" class="headerlink" title="3.2 Continuous Skip-gram Model"></a>3.2 Continuous Skip-gram Model</h4><p>第二种结构与CBOW类似，但是它不是根据上下文来预测当前单词，而是尝试根据同一句子中的另一个单词来最大化单词的分类。更准确地说，我们将每个当前单词用作具有连续投影层的对数线性分类器的输入，并预测当前单词前后的特定范围内的单词。我们发现，增加范围可以提高所得词向量的质量，但同时也会增加计算复杂度。由于距离较远的单词通常比与距离最近的单词更不相关，因此我们在训练示例中通过从这些单词中抽取较少的采样来给予距离较远的单词较少的权重。这种架构的训练复杂度是</p>
<script type="math/tex; mode=display">
Q=C\times (D+D\times \log_2(V))---(5)</script><p>其中C是单词的最大距离。因此，如果我们选择C = 5，则对于每个训练词，我们将随机选择范围<1; C>的数字R，将历史中的R个单词和当前单词的未来中的R个单词用作正确的标签。这将要求我们对R×2个单词进行分类，将当前单词作为输入，并将每个R + R单词作为输出。在以下实验中，我们使用C = 10。</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/CBOW-SkipGram.png" alt="CBOW-SkipGram"></p>
<h3 id="4-Result"><a href="#4-Result" class="headerlink" title="4.Result"></a>4.Result</h3><h3 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6 Conclusion"></a>6 Conclusion</h3><p> 本文研究了语法模型和语义语言任务的集合中各种模型衍生的单词的矢量表示的质量。我们观察到，与流行的神经网络模型（前馈模型和递归模型）相比，可以使用非常简单的模型结构来训练高质量的单词向量。由于计算复杂度低得多，因此可以从更大的数据集中计算出非常准确的高维词向量。使用Dist Belief分布的框架，即使在具有一万亿个单词的语料库上，也应该能够训练CBOW和Skip-gram模型，从而使词汇量基本上不受限制。这比以前发布的同类最佳结果最好的数量级大几个数量级。SemEval-2012 Task 2 [11]是一个有趣的任务，其中单词向量最近被显示为明显优于以前的最新技术水平。公开使用的RNN向量与其他技术一起使用，使Spearman的排名相关性比以前的最佳结果提高了50％以上[31]。基于神经网络的词向量先前已应用于许多其他NLP任务，例如情感分析[12]和复述检测[28]。可以预期，这些应用程序可以从本文描述的模型架构中受益。我们正在进行的工作表明，单词向量可以成功地应用于知识库中事实的自动扩展，也可以用于验证现有事实的正确性。机器翻译实验的结果看起来也很有希望。将来，比较我们的技术需求潜在关系分析[30]和其他方法也将很有趣。相信我们全面的测试集将帮助研究团体改进现有的估计词向量的技术。我们还预计，高质量的字向量将成为未来NLP应用程序的重要组成部分。</p>
<p>[1].翻译参考</p>
<p><a href="https://www.jianshu.com/p/4517181ca9c3" target="_blank" rel="noopener">https://www.jianshu.com/p/4517181ca9c3</a></p>
<p>[2].N-gram模型</p>
<p><a href="https://blog.csdn.net/songbinxu/article/details/80209197" target="_blank" rel="noopener">https://blog.csdn.net/songbinxu/article/details/80209197</a></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>word2vec</tag>
      </tags>
  </entry>
  <entry>
    <title>(word2vec第3弹)词和短语的分布式表示及其构成</title>
    <url>/2020/04/18/paper/(word2vec)Distributed%20Representations%20of%20Words%20and%20Phrases%20and%20their%20Compositionality/</url>
    <content><![CDATA[<p>[TOC]</p>
<h3 id="0-简介"><a href="#0-简介" class="headerlink" title="0 简介"></a>0 简介</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">论文中文：词和短语的分布式表示及其构成</span><br><span class="line">论文英文：Distributed Representations of Words and Phrases and their Compositionality.</span><br><span class="line">时间：2013年</span><br><span class="line">作者：Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff</span><br><span class="line">发表期刊：介绍性文章</span><br></pre></td></tr></table></figure>
<p>讲解Skip-gram模型的优化及其扩展。</p>
<p>本文提出了几个扩展，提高了向量的质量和训练速度，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.通过对frequent words(高频词)进行二次采样，进行训练加速，并提高了低频词的向量表示。</span><br><span class="line"></span><br><span class="line">2.学习更多的regular word representations(常规词表示)。</span><br><span class="line"></span><br><span class="line">3.提出一个分层softmax的简单替代方法-negative sampling(负采样)。</span><br><span class="line"></span><br><span class="line">4.提出一种简化的噪声对比估计(Noise Contrastive Estimation, NCE),可以更快和更好地表示频繁单词。</span><br></pre></td></tr></table></figure>
<p>词表示(word representations)的一个固有限制：</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h3><p>skip-gram模型：从大量非结构化文本数据中学习高质量向量表示的有效方法。</p>
<p>学习高质量分布式向量表示的方法。</p>
<p>词表示的一个缺陷：不关心词序，而且无法表示习惯用语。</p>
<h3 id="2-Skip-gram模型"><a href="#2-Skip-gram模型" class="headerlink" title="2 Skip-gram模型"></a>2 Skip-gram模型</h3><p><strong>模型结构：</strong></p>
<p><img src='https://raw.githubusercontent.com/liangwg/FigureBed/master/img/skip-gram模型图1.png' width='200'></p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/skip-gram模型图2.png" alt="skip-gram模型图2" style="zoom:70%;" /></p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/skip-gram模型图3.jpg" alt="skip-gram模型图3" style="zoom:80%;" /></p>
<p>输入层与隐藏层的权重矩阵：VxN，V是词库大小，N是一个词的特征表示长度，300一般</p>
<p><strong>训练目标：</strong>能够预测文本中某个词周围可能出现的词。已知中心词，预测周围词</p>
<p><strong>目标函数：</strong>若一份文档由T个词组成，$w_1,w_2,w_3,…,w_T$，模型的目标函数是最大化他们的平均对数概率：</p>
<p>​        $max~\frac{1}{T}\sum_{t=1}^{T}\sum_{-c\le j\le c,j\ne0}log[p(w_{t+j}|w_t)]$</p>
<blockquote>
<p>滑动窗口式目标函数，每个词都作为一次中心词，确定完中心词后，把以[-c,c]作为滑动窗口，计算对数概率的乘积</p>
</blockquote>
<p>c是训练上下文的大小，c较大则训练例增大，准确性更高，训练时间更长。</p>
<p><strong>基本方式计算$p(w_{t+j}|w_t)$：</strong></p>
<p>具体对(1)的推导过程参见[2]。</p>
<p>基本的Skip-gram公式使用softmax函数来定义$p(w_{t+j}|w_t)$</p>
<script type="math/tex; mode=display">
p(w_O|w_I)=\frac{exp(v'^T_{w_O}v_{w_I})}{\sum_{w=1}^Vexp(v'^T_wv_{w_I})}\tag{1}</script><blockquote>
<p>$w_I$是已知的中心词，$w_O$是周围的一个词。</p>
<p>这个公式表达的是具体去计算某一个周围词的概率。</p>
<p>公式的含义就是用隐-出矩阵的作为周围词的那一列的向量的转置，乘以入-隐矩阵的作为中心词的哪一行的行向量的转置</p>
</blockquote>
<ul>
<li><p>$v_{w_I}$是表示输入-隐藏层的权重矩阵$\bold{W}$的第I行的行向量的转置，是列向量(是Nx1)。也即one-hot编码中不为0的哪一行中的位置。$\bold{W}$是VxN的矩阵。(单词w的中心词向量)</p>
</li>
<li><p>$\bold{v}’_{w_O}$是隐藏层-输出层的权重矩阵$\bold{W}’$中的第O列，是Nx1的列向量，，这里的j是输出向量中第j位的单词。$\bold{W}’$是NxV的矩阵。(单词w的上下文词向量)</p>
</li>
<li><p>V是输入词向量的维度，模型词汇表的大小；N是隐藏层的维度。</p>
</li>
</ul>
<h3 id="3-论文的改进处"><a href="#3-论文的改进处" class="headerlink" title="3 论文的改进处"></a>3 论文的改进处</h3><h4 id="3-1-采用Hierarchical-Softmax计算-p-w-t-j-w-t"><a href="#3-1-采用Hierarchical-Softmax计算-p-w-t-j-w-t" class="headerlink" title="3.1 采用Hierarchical Softmax计算$p(w_{t+j}|w_t)$"></a>3.1 采用Hierarchical Softmax计算$p(w_{t+j}|w_t)$</h4><p>Hierarchical Softmax，意即分层softmax。结构见下图：”</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/word2vec-H-softmax.png" alt="word2vec-H-softmax" style="zoom:80%;" /></p>
<p>这里W个字作为叶子节点$w_1,w_2,w_3…$，</p>
<p><strong>计算方式：</strong></p>
<script type="math/tex; mode=display">
p(w|w_i)=\prod^{L(w)-1}_{j=1}\sigma(【n(w,j+1)=ch(n(w,j))】v'^T_{n(w,j)}v_{wI})</script><p>​    n(w,j)：从根节点到单词w的第j个中间节点；</p>
<p>​    L(w)：从根节点到单词w的路径长度；</p>
<p>​    ch(n)：是n的左孩子或者右孩子；</p>
<p>​    【x】：若x为true，则为1；反之则为-1；</p>
<p>​    $\sigma(x)=\frac{1}{1+exp(-x)}$，并且可以证明$\sum_{w=1}^Wp(w|w_I)=1$</p>
<p><strong>特点：</strong></p>
<p>​    与此同时，计算$log(p(w_O|w_I))$和$\nabla log(p(w_O|w_I))$的消耗与$L(w_O)$成正比。</p>
<p>​    不同于标准的Skip-gram，为每个单词分配两个表征$v_w与v’_w$，分层softmax为每个单词分配一个词向量$v_w$，以及为每个 内部节点分配向量表征$v’_n$。</p>
<p><strong>优势：</strong></p>
<p>​    对于Huffman树，高频词的编码较短(靠近根节点)，以此加快训练。</p>
<h4 id="3-2-负采样Negative-Sampling"><a href="#3-2-负采样Negative-Sampling" class="headerlink" title="3.2 负采样Negative Sampling"></a>3.2 负采样Negative Sampling</h4><p> <strong>随机梯度下降法存在的问题：</strong></p>
<p>1.我们每次只对窗口中出现的几个单词进行升级，但是在计算梯度的过程中，是对整个参数矩阵进行运算，但这样的参数矩阵中的大部分值都是0，见下面的</p>
<script type="math/tex; mode=display">
\nabla_{\theta}J_t(\theta)=\left[\begin{matrix}0\\\vdots\\\nabla_{v_{like}}\\\vdots\\0\\\nabla_{u_I}\\\vdots\\\nabla_{u_{learning}}\\\vdots\end{matrix}\right]\in\R^{2dV}</script><p>2.我们所使用的目标函数是softmax函数</p>
<p>$softmax(u_o^Tv_c)=p(o|c)=\hat{y}_o=\frac{e^{u^T_o}v_c}{\sum^W_{w=1}e^{u^T_w}v_c}$,由分母可以知道，分母需要把窗口所有的单词的“得分”都算出来再求和，这种方式效率较低。</p>
<p><strong>负采样的核心思想：</strong></p>
<p>计算目标单词和窗口中的单词的真实单词对“得分”，再加上一些“噪声”，即词表中的随机单词和目标单词的“得分”。</p>
<p>真实单词对“得分”和“噪声”作为代价函数。</p>
<p>每次优化参数，只关注代价函数中涉及的词向量。</p>
<p>见如下公式：</p>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{T}\sum^T_{t=1}J_t(\theta)</script><script type="math/tex; mode=display">
J_t(\theta)=log\sigma(u_o^Tv_c)+\sum^k_{j=1}\Bbb{E}_{j~P(w)}[log\sigma(-u_j^Tv_c)]</script><p>采用上述公式解决了之前说的两个问题：</p>
<ol>
<li>我们仅对K个参数进行采样</li>
<li>我们放弃softmax函数，采用sigmoid函数，这样就不存在先求一遍窗口中所有单词的‘“得分”的情况了。</li>
</ol>
<h4 id="3-3-高频词的二次取样"><a href="#3-3-高频词的二次取样" class="headerlink" title="3.3 高频词的二次取样"></a>3.3 高频词的二次取样</h4><p>高频出现的词，信息价值很少 → the经常与很多单词co-occurs → 经过长时间训练，词向量没有显著的改变 → 平衡rare and frequency words → 对每个词按概率进行discard。</p>
<p>概率计算：$P(w_i)=1-\sqrt{\frac{t}{f(w_i)}}$</p>
<p>$f(w_i)$：单词$w_i$的频率；</p>
<p>t：阀值，$10^{-5}$</p>
<p><strong>优势：</strong></p>
<p>​    1.在保留频率排序的同时，对频率大于t的词进行了启发式的子抽样</p>
<p>​    2.加快了学习速度，提高了罕见词词向量的准确性。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1]. 翻译参考</p>
<p><a href="https://blog.csdn.net/u010555997/article/details/76598666" target="_blank" rel="noopener">https://blog.csdn.net/u010555997/article/details/76598666</a> （前半部分）</p>
<p><a href="https://blog.csdn.net/qq_27859417/article/details/84929114" target="_blank" rel="noopener">https://blog.csdn.net/qq_27859417/article/details/84929114</a> (概述理解)</p>
<p>[2].分层softmax介绍</p>
<p>word2vec详解（CBOW，skip-gram，负采样，分层Softmax） - 孙孙的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/53425736" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/53425736</a></p>
<p>[3].整体阅读</p>
<p><a href="https://hiyoungai.com/posts/28911bbb.html" target="_blank" rel="noopener">https://hiyoungai.com/posts/28911bbb.html</a></p>
<p>[4].skip-gram模型的深层次解析+语言模型的一些基础知识<a href="https://blog.csdn.net/omashion/article/details/72667203" target="_blank" rel="noopener">https://blog.csdn.net/omashion/article/details/72667203</a></p>
<p>[5].负采样<a href="https://zhuanlan.zhihu.com/p/29488930" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29488930</a></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>word2vec的总结</title>
    <url>/2020/04/18/paper/word2vec/</url>
    <content><![CDATA[<p>word2vec是<strong>word embedding</strong>的一种</p>
<p>（word embedding :把人类的抽象符号转换成数值形式，或是嵌入到一个数学空间中，就是词嵌入）</p>
<p><strong>word2vec的最终目的：</strong></p>
<p>模型训练完后的副产物-模型参数</p>
<p>将参数作为输入x的某种向量化的表示，这个向量就是词向量</p>
<p><strong>word2vec的两种模型</strong></p>
<p>skip-gram 模型：用词的输入，来预测上下文</p>
<p>CBOW模型：用上下文输入，来预测词</p>
<p><strong>word2vec的精髓</strong></p>
<p>用输入的向量来训练出权重，</p>
<p><strong>word2vec的三个创新</strong></p>
<p>(1).将常见的单词组合或者词组作为单个“word”来处理</p>
<p>(2).对高频词进行抽样来减少训练样本的个数</p>
<p>(3).对优化目标采用“negative sampling”方法，这样每个训练样本的训练只会更新一小部分的模型权重，从而降低计算负担。(更新的negative words是那些频率较高的单词，这样更有可能和输入有关)</p>
<p><strong>最后的输出是：</strong></p>
<p>后验分布：在已知是这个周围词的情况下，还是输入的中心词的概率</p>
<hr>
<p>[6].word2vec详解（CBOW，skip-gram，负采样，分层Softmax） - 孙孙的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/53425736" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/53425736</a></p>
<p>[1].<strong>激活函数的介绍</strong></p>
<p>「激活函数」指的是什么？ - Lunarnai的回答 - 知乎 <a href="https://www.zhihu.com/question/304499337/answer/549345296" target="_blank" rel="noopener">https://www.zhihu.com/question/304499337/answer/549345296</a></p>
<p>[2].<strong>反向传播算法</strong> <a href="https://zhuanlan.zhihu.com/p/33411558" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33411558</a></p>
<p>[3].softmax函数的介绍</p>
<p><a href="https://www.cnblogs.com/alexanderkun/p/8098781.html" target="_blank" rel="noopener">https://www.cnblogs.com/alexanderkun/p/8098781.html</a></p>
<p>[4].<a href="http://liweithu.com/word2vec" target="_blank" rel="noopener">http://liweithu.com/word2vec</a></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>linux环境变量</title>
    <url>/2020/06/09/linux/linux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%9A%84%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h3 id="export命令"><a href="#export命令" class="headerlink" title="export命令"></a>export命令</h3><p>linux的export命令：设置或显示环境变量，在程序中先执行export，告诉系统某某某程序在对应路径下。 在linux里设置环境变量的方法：要么直接在命令行中执行（只对当前有效），要么在profile，.bashrc中设置（重启系统后生效）。</p>
<p> 使用模板：export PATH=”$PATH:/要添加的路径”</p>
<p>$是调用变量的意思，$PATH是调用该环境变量的值。其中${}里面放的是变量，用来引用，$()里面放的是命令，执行这个命令。</p>
<h3 id="etc-environment和-etc-profile的区别"><a href="#etc-environment和-etc-profile的区别" class="headerlink" title="/etc/environment和/etc/profile的区别"></a>/etc/environment和/etc/profile的区别</h3><p>/environment是给系统配置变量，而/profile是给用户配置变量，都是在系统运行时读取，一个先读一个后读。 若是要修改bash的，需要在vi ~/.bashrc中修改，这样重启后就会生效。</p>
<p>参考：<a href="https://blog.csdn.net/teamlet/article/details/8257853" target="_blank" rel="noopener">https://blog.csdn.net/teamlet/article/details/8257853</a> </p>
<h3 id="source-filename"><a href="#source-filename" class="headerlink" title="source filename"></a>source filename</h3><p>这个命令其实只是简单地读取脚本里面的语句依次在当前shell里面执行，没有建立新的子shell。那么脚本里面所有新建、改变变量的语句都会保存在当前shell里面。</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>linux的tar命令的使用</title>
    <url>/2020/04/23/linux/linux%E7%9A%84tar%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h3 id="一-命令概述"><a href="#一-命令概述" class="headerlink" title="一.命令概述"></a>一.命令概述</h3><p>​    <strong>1. 作用</strong>： tar命令是Unix/Linux系统中备份文件（<strong>打包/解压</strong>）的可靠方法，几乎可以工作于任何环境中，它的使用权限是所有用户。</p>
<p>​    <strong>2. 格式</strong>： <strong>tar [命令] [参数] 文件或目录</strong> </p>
<p>　　　　示例： </p>
<p>　　　　　　①  <strong>tar -czvf test.tgz test</strong>；  将当前目录下的test文件夹打包为test.tgz</p>
<p>　　　　　　② <strong>tar -xzvf test.tgz</strong>；  将test.tgz解压到当前目录，如果要解压到指定目录</p>
<p>　　　　　　③ <strong>tar -xzvf test.tgz -C /usr</strong> ;解压到指定目录 解压到/usr,可以用其中C必须大写</p>
<p>​    <strong>3.主要参数：</strong>使用该命令时，必须选择一个命令（仅选一个，如-x），参数是辅助选项，可以根据需要选择（-f必选）</p>
<h3 id="二-命令"><a href="#二-命令" class="headerlink" title="二.命令"></a>二.命令</h3><p>​        -c: 建立压缩档案<br>　　-x：解压<br>　　-t：查看内容<br>　　-r：向压缩归档文件末尾追加文件<br>　　-u：更新原压缩包中的文件</p>
<blockquote id="fn_注意">
<sup>注意</sup>. 这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。<a href="#reffn_注意" title="Jump back to footnote [注意] in the text."> &#8617;</a>
</blockquote>
<h3 id="三-参数"><a href="#三-参数" class="headerlink" title="三.参数"></a>三.参数</h3><p>​       -z：有gzip属性的<br>　　-j：有bz2属性的<br>　　-Z：有compress属性的<br>　　-v：显示所有过程<br>　　-O：将文件解开到标准输出<br>​        -f :   使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。(-f为必选)</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>linux编程环境</title>
    <url>/2020/04/18/linux/linux%E7%BC%96%E7%A8%8B%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h3 id="1-一些问题辨析"><a href="#1-一些问题辨析" class="headerlink" title="1.一些问题辨析"></a>1.一些问题辨析</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>介绍</th>
</tr>
</thead>
<tbody>
<tr>
<td>在windows上启动wsl的方法</td>
<td>当前定位的是虚拟的/home/wgl的路径，通过cd  /mnt进入到该虚拟文件夹中，然后C盘，D盘都是以文件夹的形式附缀在其内部的。</td>
</tr>
<tr>
<td>ls a.txt b.txt 1&gt;file.out 2&gt;&amp;1</td>
<td>这代表把标准输出和标准错误重定向合并到文件file.out</td>
</tr>
<tr>
<td></td>
<td>0表示stdin标准输入<br />1表示stdout标准输出<br />2表示stderr标准错误</td>
</tr>
<tr>
<td>./a.sh与.a.sh</td>
<td>./a.sh 将创建子进程，在子shell中执行当前目录下的a.sh脚本里的程序，而.a.sh 将在当前的shell中执行a.sh脚本。</td>
</tr>
<tr>
<td>编译并运行.c文件的方法</td>
<td>：编译：gcc -o 文件名  文件名.c  或者gcc 文件名.c -o 文件名或者make 文件名运行：./文件名其中：gcc将编译链接过程产生的错误信息输出到标准错误文件stderr中，要将stderr输出到标准输出中，则有 2&gt;&amp;1</td>
</tr>
<tr>
<td>代码段与栈</td>
<td>代码段：存放着程序的指令数据段.data 存放着已经初始化的全局变量和静态变量(包括局部），字符串数据（用双引号包起来的数据），声明为static的变量也在数据段BSS段：Unix链接器产生的未初始化数据段。程序中没有初始化的全局变量堆：存放进程运行中被动态分配的内存段，栈：用户函数内部定义的局部变量，都是在堆栈段</td>
</tr>
<tr>
<td>bash中的()与{}</td>
<td>()和{}都是执行一段程序。两者的区别:()命令组，括号中的命令新开一个子shell 程序，括号中的变量为本地变量，不能够在脚本其他部分使用。括号中多个命令之间用分号隔开。   {}命令组，大括号的命令在当前shell运行，不会重新开子shell。括号内的命令必须用分隔符隔开，最后一个命令后面必须跟上分号。{}的第一个命令和左括号之间必须有空格</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-命令集"><a href="#2-命令集" class="headerlink" title="2.命令集"></a>2.命令集</h3><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>cat</td>
<td>1.一次显示整个文件：cat filename<br />2.从键盘创建一个文件：cat&gt;filename ，<br />3.将几个文件合并为一个文件：cat file1 file2 &gt;file</td>
</tr>
<tr>
<td>cc</td>
<td>1.编译文件2.比如说：cc file.c3.cc -o fot foobar.c  其中会生成fot.o</td>
</tr>
<tr>
<td>chomd</td>
<td><a href="https://blog.csdn.net/weixin_43190941/article/details/83281132" target="_blank" rel="noopener">https://blog.csdn.net/weixin_43190941/article/details/83281132</a></td>
</tr>
<tr>
<td>close</td>
<td>作用是关闭进程的文件描述符，即一个进程的文件描述符被close后，就不会指向内核的资源了</td>
</tr>
<tr>
<td>diff</td>
<td>1. 逐行比较两个文本文件，列出其不同之处。显示出两个文件中所有不同的行。diff a.c b.c<br />2.diff -c&lt;行数&gt;  a.c b.c  比较前多少行</td>
</tr>
<tr>
<td>echo</td>
<td>echo -e 能够识别以\开头的一些特殊字符,比如echo -e \\101</td>
</tr>
<tr>
<td>find</td>
<td><a href="https://www.cnblogs.com/weijiangbao/p/7653588.html" target="_blank" rel="noopener">https://www.cnblogs.com/weijiangbao/p/7653588.html</a></td>
</tr>
<tr>
<td>grep</td>
<td>1.用于查找文件里符合条件的字符串，把含有范式样本的那一列显示出来。<br />2.常用格式：grep [选项] “模式“ [文件]<a href="https://www.runoob.com/linux/linux-comm-grep.html" target="_blank" rel="noopener">https://www.runoob.com/linux/linux-comm-grep.html</a><br />3.去掉所有空行：grep -v “^ *$” 文件名</td>
</tr>
<tr>
<td>man</td>
<td>使用man可以在线查阅命令的使用手册</td>
</tr>
<tr>
<td>ls</td>
<td>ls -l 是列出当前目录下的所有文件和目录，而ls -l *则是列出当前目录下所有文件，和当前目录下所有目录中的内容。</td>
</tr>
<tr>
<td>pwd</td>
<td>查看当前工作目录的完整路径</td>
</tr>
<tr>
<td>pipe()</td>
<td>1.把两个进程之间的标准输入和标准输出连接起来的，提供两个文件描述符来操作管道，其中一个对管道写，另一个对管道读2.必须在fork()中调用pipe(),否则子进程不会继承文件描述符，两个进程不共享祖先进程，3.<a href="http://www.cnblogs.com/kunhu/p/3608109.html4.父子进程管道的关闭问题https://blog.csdn.net/rl529014/article/details/51464363" target="_blank" rel="noopener">http://www.cnblogs.com/kunhu/p/3608109.html4.父子进程管道的关闭问题https://blog.csdn.net/rl529014/article/details/51464363</a></td>
</tr>
<tr>
<td>ps</td>
<td>ps -l的选项，可以打印出进程当前的SZ属性，即进程的虚拟内存空间的大小2.ps -e 显示所有程序3.ps -f 用ASCII字符显示树状结构，表达程序间的相互关系</td>
</tr>
<tr>
<td>rm</td>
<td>1.删除文件命令，rm— -f，表示显示结束选项参数。<br />2.递归地删除一个子目录：rm -r 目录名</td>
</tr>
<tr>
<td>test</td>
<td><a href="https://www.cnblogs.com/tankblog/p/6160808.html" target="_blank" rel="noopener">https://www.cnblogs.com/tankblog/p/6160808.html</a></td>
</tr>
<tr>
<td>wc</td>
<td>1.wc [选项]文件 统计指定文件中的字节数、字数、行数，并将统计结果显示输出。该命令统计指定文件中的字节数、字数、行数。<br />2.<a href="https://www.cnblogs.com/newcaoguo/p/5896491.html" target="_blank" rel="noopener">https://www.cnblogs.com/newcaoguo/p/5896491.html</a><br />3.统计行数  。  -l统计字节数  -c统计字节数-w</td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-Vim编辑器的使用"><a href="#3-Vim编辑器的使用" class="headerlink" title="3.Vim编辑器的使用"></a>3.Vim编辑器的使用</h3><ul>
<li><p>先按ESC进入Command模式，然后输入下面对应的命令执行相应的command操作</p>
<p>| 操作                               | 命令       |<br>| ————————————————— | ————— |<br>| 回车保存并退出                     | :wq        |<br>| 文件另存为                         | :w newname |<br>| 保存并强制退出                     | :wq!       |<br>| 强制退出                           | :q!        |<br>| 保存并退出（仅当文件有变化时保存） | :x         |</p>
</li>
</ul>
<h3 id="4-参考"><a href="#4-参考" class="headerlink" title="4.参考"></a>4.参考</h3><p>$的用法<a href="https://www.cnblogs.com/chjbbs/p/6393935.html" target="_blank" rel="noopener">https://www.cnblogs.com/chjbbs/p/6393935.html</a></p>
<p>文件通配符<a href="https://www.cnblogs.com/0zcl/p/6821213.html" target="_blank" rel="noopener">https://www.cnblogs.com/0zcl/p/6821213.html</a></p>
<p>linux的正则表达式<a href="https://www.cnblogs.com/fox-zhang/p/8066719.html" target="_blank" rel="noopener">https://www.cnblogs.com/fox-zhang/p/8066719.html</a></p>
<p>vi的一些使用命令：<a href="https://blog.csdn.net/williamfan21c/article/details/56495261" target="_blank" rel="noopener">https://blog.csdn.net/williamfan21c/article/details/56495261</a></p>
<p>Linux的i结点<a href="https://www.cnblogs.com/hnrainll/archive/2012/08/25/2237877.html" target="_blank" rel="noopener">https://www.cnblogs.com/hnrainll/archive/2012/08/25/2237877.html</a></p>
<p>Linux中cat,more，less,tail,head命令的区别<a href="https://www.cnblogs.com/losbyday/p/5856106.html" target="_blank" rel="noopener">https://www.cnblogs.com/losbyday/p/5856106.html</a></p>
<p>sed的使用<a href="https://blog.csdn.net/wangcg123/article/details/50667883" target="_blank" rel="noopener">https://blog.csdn.net/wangcg123/article/details/50667883</a></p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>(DeepWalk)online Learning of Social Representation</title>
    <url>/2020/08/02/papers/(DeepWalk)online%20Learning%20of%20Social%20Representation/</url>
    <content><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>构建分层softmax有什么用？？</p>
<p>独立性假设？？？</p>
<p>标签应该用什么向量来表示？？？？？？</p>
<p>这里为什么可以用独立性假设</p>
<p>这里的J是不是有问题？不应该是连乘式嘛？</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/clipboard.png" alt="img"></p>
<h1 id="0-简介"><a href="#0-简介" class="headerlink" title="0 简介"></a>0 简介</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">论文英文：online Learning of Social Representation.</span><br><span class="line">论文中文：社交表征的在线学习</span><br><span class="line">发表期刊：2014的KDD会议上</span><br><span class="line">作者：</span><br><span class="line">Bryan Perozzi, Stony Brook University, Stony Brook, NY, USA</span><br><span class="line">Rami Al-Rfou, Stony Brook University, Stony Brook, NY, USA</span><br><span class="line">Steven Skiena, Stony Brook University, Stony Brook, NY, USA</span><br></pre></td></tr></table></figure>
<p><strong>嵌入、词嵌入、网络嵌入</strong></p>
<p><strong>DeepWalk：</strong>DeepWalk把一个图或网络作为输入，输出为网络中顶点的向量表示。通过截断随机游走（truncated random walk）学习出一个网络的社会表示（social representation）(中心思想)，所谓的社会表示就是原来图中邻居的相似性、社区关系等特征表示。对这种关系编码得到低维的、有丰富含义的顶点向量表示。</p>
<p>deepwalk是将截断随机游走和神经语言模型结合形成的网络表示。</p>
<p><strong>映射函数$\Phi$：</strong>实现将网络中的节点映射成向量，便于计算。</p>
<h1 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1 背景介绍"></a>1 背景介绍</h1><pre><code>  1.使用机器学习的算法解决问题需要大量的信息，而现实生活中的网络信息较少。为了将机器学习的算法应用在现实网络中，要对信息较少的网络（稀疏性网络，社交网络）进行处理。
</code></pre><p><strong>DeepWalk</strong>通过构建的short random walk流学习Graph中顶点的social representation。Social representations是关于顶点的邻居相似性、社区关系的一种隐含的特征表示，通过对上述关系的编码得到一种低维的、具有丰富含义的向量表示，也即embedding vector。</p>
<h1 id="2-问题描述-相关概念"><a href="#2-问题描述-相关概念" class="headerlink" title="2 问题描述+相关概念"></a>2 问题描述+相关概念</h1><p><strong>普通图的表示：</strong></p>
<p>令G =(V,E)，其中V表示网络的节点，E是网络中的连接，$E\subseteq(V\times V)$。</p>
<p><strong>标注图的表示（labeled social network）:</strong></p>
<p>G的基础上加上所有顶点的向量表示的矩阵X和所有顶点所属的标签构成的矩阵Y</p>
<blockquote>
<p>网络节点分类问题中每个顶点都有一个类别，所属的类别即为该顶点的标注</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online.png" alt="DW-online" style="zoom:50%;" /></p>
<p>​       X是将每个顶点的向量结合在一起形成的矩阵</p>
<p>​        Y是每个顶点的标签构成的集合</p>
<p><strong>学习网络表示注意的几个性质：</strong></p>
<p>适用性（Adaptability）:网络要适应网络的变化，对于新的节点和边添加可以处理，正常演化</p>
<p>同节点类似表示性(Community aware):网络中结构相似的点表示成的向量也相似</p>
<p>低维性(Low dimensional): 代表每个顶点的向量维数不能过高，过高会过拟合。</p>
<p>连续性(Continuous):低维的向量应当连续。</p>
<p><strong>网络嵌入和词嵌入：(word embedding and network embedding)</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>网络嵌入</th>
<th>词嵌入</th>
</tr>
</thead>
<tbody>
<tr>
<td>可用向量表示单元&amp;&amp;基本处理单元</td>
<td>网络节点</td>
<td>单词</td>
</tr>
<tr>
<td>分析</td>
<td>对节点的表示中节点构成的随机游走序列进行分析</td>
<td>对构成一个句子的单词序列进行分析</td>
</tr>
</tbody>
</table>
</div>
<p><strong>嵌入的理解：（Embedding）</strong></p>
<p>词嵌入，网络嵌入中的嵌入是<font color='blue'>学习这些内容的本质特征和内在含义的意思</font></p>
<p>网络嵌入：将节点转化为向量，挖掘节点的本质特征（语义，属性等性质上的相似性转化为向量空间上的相似性）</p>
<p>网络嵌入是将节点表示成低微向量，用向量的余弦距离表示节点的相连关系，余弦距离越近，表示有相连关系。</p>
<p><strong>随机游走（random walk）:</strong></p>
<p>网络上不断重复地随机选择游走路径，最终形成一条贯穿网络的路径；</p>
<p>从某个特定的端点开始，游走的每一步都从与当前节点相连的边中随机选择一条，沿着选定的边移动到下一个顶点，不断重复这个过程。</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online3.png" alt="DW-online3" style="zoom:50%;" /></p>
<p>截断随机游走==长度固定的随机游走。</p>
<p><strong>随机游走的两个好处：</strong></p>
<ul>
<li>并行性：随机游走是局部的，可以多个顶点同时开始一定长度的随机游走。减少采样的时间。</li>
<li>适应性：适应网络局部的变化，网络演化是局部的点和边的变化，这样的变化只对部分随机游走路径产生影响。</li>
</ul>
<h1 id="3-语言建模扩展到网络节点表示"><a href="#3-语言建模扩展到网络节点表示" class="headerlink" title="3 语言建模扩展到网络节点表示"></a>3 语言建模扩展到网络节点表示</h1><p><a href="https://zhuanlan.zhihu.com/p/45167021（推理部分）" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/45167021（推理部分）</a></p>
<p><strong>类比过程：</strong></p>
<p>语言建模的目标是估计出现在语料库中的特定序列的可能性。即，给定$W_n=(w_0,w_1,…,w_n)$的序列，其中$w_i\in V$（V是词汇表），我们想最大化$P_r(w_n|w_0,w_1,..w_{n-1})$。在最近的工作中，语言建模扩展到使用概率神经网络来构建词语的一般表示。</p>
<p>随机游走得到的序列可以被认为是一种特殊语言的短句，类比语言建模可以得到：在随机游走中给定迄今为止访问的所有先前顶点$(v_1,v_2,…,v_{i-1})$的情况下，下一个顶点是$v_i$的可能性可以表示为：</p>
<script type="math/tex; mode=display">
P_r(v_i|(v_1,v_2,...,v_{i-1}))\tag{1}</script><p><strong>引入”节点—向量的映射“：</strong></p>
<p>对于(1)而言，顶点是没办法计算的，因此要引入<font color='red'>映射函数</font>$\Phi:v\in V \rarr R^{|V|\times d}$。将网络中的每一个节点映射成d维向量，得到一个矩阵，共有|V|xd个参数，这些参数需要学习。</p>
<p>则原先(1)的<font color='red'>优化目标</font>就可以写成：</p>
<script type="math/tex; mode=display">
P_r(v_i|(\Phi(v_0),\Phi(v_1),...,\Phi(v_{i-1})))\tag{2}</script><p><strong>引入”松弛（relaxation）假设“：</strong></p>
<p>​    但是随着walk的增长，$(\Phi(v_0),\Phi(v_1),…,\Phi(v_{i-1}))$这一部分太难计算。因此，借用词向量中的skip-gram模型，引入松弛假设：</p>
<ul>
<li><p>不是通过上下文预测缺失词(missing word)，而是使用缺失词来预测上下文。因此，只需要计算一个$\Phi(v_k)$就可以，其中$v_k$是缺失词。</p>
</li>
<li><p>同时考虑左边窗口和右边窗口。如下图橘黄色部分，$v_4$同时考虑左边和右边的2个窗口内的节点：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/deepwalk-窗口.jpg" alt="deepwalk-窗口" style="zoom:40%;" /></p>
</li>
<li><p>不考虑顺序，只要是窗口中出现的词都算进来，而不管它具体出现在窗口的哪个位置。即无序性。</p>
</li>
</ul>
<p><strong>得到：最终优化目标函数：</strong></p>
<script type="math/tex; mode=display">
\underset{\Phi}{minimize}~-log[P_r(\{v_{i-w},...,v_{i-1},v_{i+1},...,v_{i+w}\}|\Phi(v_i))]</script><blockquote>
<p>这里概率部分的意思是：在一个随机游走中，当给定一个顶点$v_i$时，出现在它的w窗口范围内顶点的概率。</p>
<p>忽视顶点的顺序更好地体现了在随机游走中顶点的邻近关系，真正需要计算的是一个顶点$v_i$的向量</p>
</blockquote>
<h1 id="4-算法"><a href="#4-算法" class="headerlink" title="4 算法"></a>4 算法</h1><p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online8.png" alt="DW-online8"></p>
<p><em>图3.DeepWalk算法框架</em></p>
<p>DeepWalk的算法包含两个部分，一个部分是随机游走的生成，另一部分是参数的更新</p>
<p><strong>1.主体部分：</strong></p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online9.png" alt="DW-online9"></p>
<p>其中第2步是构建Hierarchical Softmax，第3步对每个节点做γ次随机游走，第4步打乱网络中的节点，第5步以每个节点为根节点生成长度为t的随机游走，第7步根据生成的随机游走使用skip-gram模型利用梯度的方法对参数进行更新。</p>
<p><strong>2.参数更新部分：</strong></p>
<p>skip-gram是一个语言模型，用于最大化句子中出现在窗口w内的单词之间的共现概率。用独立性假设，将等式3中的条件概率近似为</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online10.png" alt="DW-online10"></p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online11.png" alt="DW-online11"></p>
<p>对随机游走序列中的每个顶点，先把它映射到它的当前表示向量Φ(vj)（参见图3(b)）；然后通过随机梯度下降算法，最大化出现在上下文中的所有单词的概率，以此更新向量表示。</p>
<p><strong>3.Hierarchical Softmax</strong></p>
<p>给定uk∈V，直接计算第3行的Pr(uk|Φ(vj))是不可行的，我们将使用Hierarchical Softmax来分解条件概率。</p>
<p>我们将网络中的顶点分配为二叉树的叶子节点，将问题转化为最大化层级中特定路径的概率（参见图3(c)）。如果顶点uk的路径由一系列树节点(b0，b1，…，b[log |V|])来标识，其中，b0=vj，b[log |V|]= uk，那么</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online12.png" alt="DW-online12"></p>
<p>Pr(bl|Φ(vj))可以通过对bl的父节点建模一个二元分类器实现，计算公式为：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online13.png" alt="DW-online13"></p>
<p>(这里的公式二元分类器)</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/DW-online14.png" alt="DW-online14"></p>
<h1 id="八-实验"><a href="#八-实验" class="headerlink" title="八.实验"></a>八.实验</h1><p><a href="https://www.jianshu.com/p/5adcc3d94159" target="_blank" rel="noopener">https://www.jianshu.com/p/5adcc3d94159</a>  参照实验部分</p>
<p><strong>1.数据集：</strong></p>
<ul>
<li>BlogCatalog是博客作者的社交关系网络。标签代表作者提供的主题类别。</li>
<li>Flickr是照片分享网站用户之间的联系网络。标签代表用户的兴趣组。</li>
<li>YouTube是流行的视频分享网站用户之间的社交网络。标签代表喜欢不同类视频的观众群体。</li>
</ul>
<p><strong>2.对比算法</strong></p>
<ul>
<li>SpectralClustering</li>
<li>Modularity</li>
<li>EdgeCluster</li>
<li>wvRN</li>
<li>Majority</li>
</ul>
<p><strong>3.实验设计</strong></p>
<h1 id="九-总结"><a href="#九-总结" class="headerlink" title="九.总结"></a>九.总结</h1><p>学习顶点潜在表示的新方法，对语言建模算法的一般化。DeepWalk可扩展，可为大规模、稀疏的图创建有意义的表示。</p>
<h1 id="十-参考文献"><a href="#十-参考文献" class="headerlink" title="十.参考文献"></a>十.参考文献</h1><p>[1].deepwalk理解：<a href="https://zhuanlan.zhihu.com/p/45167021" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/45167021</a></p>
<p>[2].论文参考翻译：<a href="https://www.jianshu.com/p/5adcc3d94159" target="_blank" rel="noopener">https://www.jianshu.com/p/5adcc3d94159</a></p>
<p>[3].工具：<a href="https://github.com/phanein/deepwalk" target="_blank" rel="noopener">https://github.com/phanein/deepwalk</a></p>
]]></content>
      <categories>
        <category>papers</category>
      </categories>
      <tags>
        <tag>deepwalk</tag>
      </tags>
  </entry>
  <entry>
    <title>(node2vec)Scalable Feature Learning for Networks</title>
    <url>/2020/08/02/papers/(node2vec)Scalable%20Feature%20Learning%20for%20Networks/</url>
    <content><![CDATA[<h3 id="1-问题"><a href="#1-问题" class="headerlink" title="-1 问题"></a>-1 问题</h3><p>本文最终的输出是什么？和目标函数有什么关系？</p>
<h3 id="0-简介"><a href="#0-简介" class="headerlink" title="0 简介"></a>0 简介</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">论文英文：Scalable Feature Learning for Networks</span><br><span class="line">论文中文：面向网络的可扩展特征学习</span><br><span class="line">发表期刊：KDD 2016</span><br></pre></td></tr></table></figure>
<p><strong>node2vec主要思想：</strong>生成随机游走采样得到（节点，上下文）的组合，然后用处理词向量的方法对这样的组合建模得到网络节点的表示。</p>
<p><strong>论文的创新点：</strong>在生成随机游走的过程中做了一些创新。</p>
<p>思想和DeepWalk是一样的，但是改进了DeepWalk中随机游走的生成方式，使得生成的随机游走可以反映深度游走和广度游走的特性。</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p><strong>复杂网络面对的几种任务：</strong></p>
<ul>
<li>网络节点的分类（网络中的节点进行聚类，哪些节点有类似的属性，就将其分到同一个类别中）</li>
<li>链接预测（预测网络中哪些顶点有潜在的关联）</li>
</ul>
<p><strong>本文的工作：</strong></p>
<p>设计出既能保持节点邻居信息又容易训练的模型</p>
<p><strong>网络中的结构特征（社区）：</strong></p>
<p>社区：很多节点会聚集在一起，内部的连接远比外部的连接多。</p>
<blockquote>
<p>相当于一个集群的概念</p>
</blockquote>
<p>网络中两个可能相聚很远的节点，在边的连接上有着类似的特征。</p>
<p>如下面的$u,S_1,S_2,S_3,S_4$就是一个社区，u和$S_6$在结构上有着相似的特征</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/node2vec-社区.png" alt="node2vec-社区" style="zoom:50%;" /></p>
<p><strong>网络表示学习算法要满足：</strong></p>
<ul>
<li>同一个社区内的节点表示相似</li>
<li>拥有类似结构的节点表示相似</li>
</ul>
<h1 id="2-Related-Works"><a href="#2-Related-Works" class="headerlink" title="2 Related Works"></a>2 Related Works</h1><p>之前的工作存在着的一些问题：</p>
<ul>
<li>特征需要依赖人手工定义，本身就不准确</li>
<li>一些非监督学习中的降维方法被拿来使用，但效率低，准确度不够，不能反应出网络的结构特征</li>
</ul>
<h1 id="3-模型介绍"><a href="#3-模型介绍" class="headerlink" title="3 模型介绍"></a>3 模型介绍</h1><h4 id="3-1-模型目标函数及推导："><a href="#3-1-模型目标函数及推导：" class="headerlink" title="3.1 模型目标函数及推导："></a>3.1 模型目标函数及推导：</h4><p><strong>初始目标函数（objective function）：</strong></p>
<script type="math/tex; mode=display">
\underset{f}{max}\sum_{u\in V}logPr(N_s(u)|f(u)) \tag{1}</script><p>$f(u)$是当前节点，$N_s(u)$是邻居节点。</p>
<p><font color='red'>优化目标是给定每个顶点条件下，令其邻近顶点出现的概率最大。</font>，因此是对数和的形式。</p>
<p><strong>引入的两个假设：</strong></p>
<ul>
<li><strong>条件独立性（Conditional independence）：</strong>也即采样的每个邻居是相互独立的，若要计算采样所有邻居的概率只需要将采样每个邻居的概率相乘即可，公式如下：</li>
</ul>
<script type="math/tex; mode=display">
P_r(N_s(u)|f(u))=\prod_{n_i\in N_s(u)}P_r(n_i|f(u))\tag{2}</script><ul>
<li><strong>特征空间的对称性（Symmetry in feature space）：</strong>一条边连接了a和b，则映射到特征空间时，a对b的影响和b对a的影响是一样的。一个顶点作为源顶点和作为近邻顶点时共享一套embedding向量。由一个模型表示一个（节点，邻居）对：</li>
</ul>
<script type="math/tex; mode=display">
P_r(n_i|f(u))=\frac{exp(f(n_i)\cdot f(u))}{\sum_{v\in V }exp(f(v)\cdot f(u))}\tag{3}</script><p><strong>最终的优化目标函数：</strong></p>
<p>将(1)、(2)、(3) 三个公式结合起来推导得到最终的优化结果：</p>
<script type="math/tex; mode=display">
\underset{f}{max}\sum_{u\in V}[-logZ_u+\sum_{n_i\in N_s(u)}f(n_i)\cdot f(u)]</script><p>其推导过程如下：</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/node2vec的公式推导.jpg" alt="node2vec的公式推导" style="zoom:40%;" /></p>
<p>推导完后，应该有一个$|N_s(u)|$的系数，但这一部分并不出现在最终的损失函数中，是因为整个这一项$|N_s(u)|logZ_u$都是常数的原因。</p>
<p>这里注意两点：</p>
<p>​        1). $Z_u$直接计算特别费时，本文是Negative Sampling方式解决。</p>
<p>​        2).$N_s(u)$未必是u的直接邻居，只是用s方法采样得到的邻居，和具体的采样方式有关。</p>
<h4 id="3-2-随机游走采样-创新的部分"><a href="#3-2-随机游走采样-创新的部分" class="headerlink" title="3.2 随机游走采样(创新的部分)"></a>3.2 随机游走采样(创新的部分)</h4><p><strong>两种图的游走方式：</strong></p>
<p>​        深度优先游走(Depth-first Sampling,DFS)，广度优先游走(BFS)</p>
<p>​        BFS倾向于在初始节点的周围游走，反映处一个节点的邻居的微观特性；</p>
<p>​        DFS则会跑的离初始节点越来越远，反映出一个节点邻居的宏观特性。</p>
<p><strong>本文工作：改进DeepWalk中随机游走的方式，综合DFS和BFS的特性。</strong></p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/node2vec-随机游走.png" alt="node2vec-随机游走" style="zoom:40%;" /></p>
<p>对于这个随机游走，若已经采样了(t,v)，现在停留在节点v上，则下一个要采样的节点x遵循以下的概率分布：(一个节点到它不同邻居的转移概率：)</p>
<script type="math/tex; mode=display">
\alpha_{pq}(t,x)=\begin{cases}
\frac{1}{p} &if~d_{tx}=0\\
1 & if~d_{tx}=1\\
\frac{1}{q} &if~d_{tx}=2
\end{cases}</script><blockquote>
<p>若t与x相等，则采样x的概率为$\frac{1}{p}$，即往回采样，采样已经访问过的节点t</p>
<p>若t与x相连，则采样x的概率为1，这是一定采样相邻的节点$x_1$；</p>
<p>若t与x不相连，则采样x的概率为$\frac{1}{q}$，这是采样不相邻的节点$x_2,x_3$。</p>
</blockquote>
<p><strong>超参数p、q的意义：</strong></p>
<p>​    返回参数p：</p>
<p>​        若$p&gt;max(q,1)$，则采样会尽量不往回走，不太可能是上一个访问的节点t</p>
<p>​        若$p&lt;min(q,1)$，则采样更倾向于返回上一个节点，则会一直在起始点周围的某些节点来回转。</p>
<p>​    出入参数q：</p>
<p>​        q控制着游走是向外还是向内，若q&gt;1，随机游走倾向于访问和t接近的顶点（偏向于BFS）。若q&lt;1，倾向于访问远离t的顶点（偏向于DFS）</p>
<p>这里当p=1，q=1时，游走方式就等同于DeepWalk中的随机游走。</p>
<h1 id="六-算法部分"><a href="#六-算法部分" class="headerlink" title="六.算法部分"></a>六.算法部分</h1><p>按概率抽取，采用了Alias算法进行顶点采样</p>
<p><img src="D:\有道云存储\qq4EC68D37BEC205269D5190F466ABEE14\9908a908f1cf4930976bd7d526e99348\clipboard.png" alt="img"></p>
<p>算法的参数+部分：</p>
<p>图G，表示向量维度d，每个节点生成的游走个数r，游走长度I，上下文的窗口长度k，还有p,q参数。</p>
<p>1.根据p,q和之前的公式计算一个节点到它的邻居的转移概率。</p>
<p>2.将这个转移概率加到图G中形成G’。</p>
<p>3.walks用来存储随机游走，初始化为空。</p>
<p>4.外循环r次表示每个节点作为初始节点要生成r个随机游走。</p>
<p>5.对于图中的各个节点。</p>
<p>6.生成一条随机游走walk。</p>
<p>7.将walk添加到walks中保存。</p>
<p>8.用SGD的方法对walks进行训练。</p>
<p>1.将初始节点u添加进去。</p>
<p>2.walk的长度为I，由此还要再循环添加I-1个节点。</p>
<p>3.当前节点设为walk最后添加的节点。</p>
<p>4.找出当前节点的所有邻居节点。</p>
<p>5.根据转移概率采样选择某个邻居s</p>
<p>6.将该邻居添加到walk中。</p>
<p><strong>此处有不懂的地方？？？？？</strong></p>
<h1 id="七-Node2vec核心代码"><a href="#七-Node2vec核心代码" class="headerlink" title="七.Node2vec核心代码"></a>七.Node2vec核心代码</h1><p><a href="https://blog.csdn.net/u012151283/article/details/87081272" target="_blank" rel="noopener">https://blog.csdn.net/u012151283/article/details/87081272</a></p>
<h1 id="八-实验部分"><a href="#八-实验部分" class="headerlink" title="八.实验部分"></a>八.实验部分</h1><p><strong>实验部分？？？？？？？？？？</strong></p>
<p><img src="D:\有道云存储\qq4EC68D37BEC205269D5190F466ABEE14\447b2a1282f14e2eaef542a225ccc8a2\clipboard.png" alt="img"></p>
<p><img src="D:\有道云存储\qq4EC68D37BEC205269D5190F466ABEE14\15b2e0dbe7074368a67182f0103f3e5b\clipboard.png" alt="img"></p>
<h1 id="十-参考论文"><a href="#十-参考论文" class="headerlink" title="十.参考论文"></a>十.参考论文</h1><p>[1].论文翻译<a href="https://zhuanlan.zhihu.com/p/46344860" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46344860</a></p>
<p>[2].代码参考<a href="https://blog.csdn.net/u012151283/article/details/87081272" target="_blank" rel="noopener">https://blog.csdn.net/u012151283/article/details/87081272</a></p>
<p>[3].模型实现<a href="https://github.com/shenweichen/GraphEmbedding" target="_blank" rel="noopener">https://github.com/shenweichen/GraphEmbedding</a></p>
]]></content>
      <categories>
        <category>papers</category>
      </categories>
      <tags>
        <tag>node2vec</tag>
      </tags>
  </entry>
  <entry>
    <title>(Trans系列)</title>
    <url>/2020/08/02/papers/(Trans%E7%B3%BB%E5%88%97)/</url>
    <content><![CDATA[<p><strong>论文情况</strong></p>
<p>目前基于翻译模型（Trans系列）的知识表示学习的研究情况</p>
<p>TransE, NIPS2013, Translating embeddings for modeling multi-relational data</p>
<p>TransH, AAAI2014, Knowledge graph embedding by translating on hyperplanes</p>
<p>TransR, AAAI2015, Learning Entity and Relation Embeddings for Knowledge Graph Completion</p>
<p>TransD, ACL2015, Knowledge graph embedding via dynamic mapping matrix</p>
<p>TransA, arXiv2015, An adaptive approach for knowledge graph embedding</p>
<p>TranSparse, AAAI2016, Knowledge graph completion with adaptive sparse transfer matrix</p>
<p>TransG, arXiv2015, A Generative Mixture Model for Knowledge Graph Embedding</p>
<p>KG2E, CIKM2015, Learning to represent knowledge graphs with gaussian embedding</p>
<hr>
<h1 id="Mean-rank，Hit-10的理解"><a href="#Mean-rank，Hit-10的理解" class="headerlink" title="Mean rank，Hit@10的理解"></a>Mean rank，Hit@10的理解</h1><h3 id="1-Mean-rank"><a href="#1-Mean-rank" class="headerlink" title="1.Mean rank:"></a>1.Mean rank:</h3><p>对于每个testing triple，以预测tail entity为例，将(h,r,t)中的t用知识图谱中的每个实体代替，通过fr(h,t)函数计算分数，得到的一系列分数升序排列，f函数值越小越好-排的越靠前越好。然后去看每个testing triple中正确答案也即真实的t在序列中排多少位，比如t1排100位，t2排200，t3排60，然后对这些排名求平均,Mean rank即可以得到。</p>
<h3 id="2-Hit10"><a href="#2-Hit10" class="headerlink" title="2.Hit10:"></a>2.Hit10:</h3><p>按照上述进行f函数值排列，然后去看每个testing triple的正确答案是否排在序列的前十，如果在的话就计数+1,然后，最终排在前十的个数/总个数 ，就是Hit@10.</p>
<h1 id="参考的"><a href="#参考的" class="headerlink" title="参考的"></a>参考的</h1><p><a href="https://blog.csdn.net/wp_csdn/article/details/79607727" target="_blank" rel="noopener">https://blog.csdn.net/wp_csdn/article/details/79607727</a></p>
<p><a href="https://www.jianshu.com/p/f1ba68064343" target="_blank" rel="noopener">https://www.jianshu.com/p/f1ba68064343</a></p>
<p>书籍-《知识图谱》 -第九章的第四节</p>
]]></content>
      <categories>
        <category>papers</category>
      </categories>
  </entry>
  <entry>
    <title>Ajax+Django框架介绍</title>
    <url>/2020/05/16/python/Django%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h3 id="Django前后端交互"><a href="#Django前后端交互" class="headerlink" title="Django前后端交互"></a>Django前后端交互</h3><p>实现数据交互的两种方法：form表单和ajax数据交互。</p>
<h3 id="form表单-Django中自带的模板"><a href="#form表单-Django中自带的模板" class="headerlink" title="form表单(Django中自带的模板)"></a>form表单(Django中自带的模板)</h3><h4 id="i-1-前端表单部分"><a href="#i-1-前端表单部分" class="headerlink" title="i-1 前端表单部分"></a>i-1 前端表单部分</h4><p>通过form表单向后端提交数据</p>
<p>这个中的action路径的填写：参考”html的form表单”</p>
<h4 id="i-2-urls-py部分-绑定响应函数"><a href="#i-2-urls-py部分-绑定响应函数" class="headerlink" title="i-2 urls.py部分(绑定响应函数)"></a>i-2 urls.py部分(绑定响应函数)</h4><p>url(r’^type_add/$’, views.type_add, name=’type_add’),</p>
<p>这里的r’^type_add/‘中，r是匹配的意思，单引号的中间是具体要匹配的，^是匹配要检索的文本的开头，还有一般是有在最后面加上$，这个$匹配文本的结束，不加也可以。上述的访问链接是 <a href="http://127.0.0.1:port/type_add/">http://127.0.0.1:port/type_add/</a></p>
<p>path(‘在html绑定的url网页名\\’,调用的views中的视图函数)</p>
<h4 id="i-3-views-py部分"><a href="#i-3-views-py部分" class="headerlink" title="i-3 views.py部分"></a>i-3 views.py部分</h4><p>具体构建响应函数的内容，并将处理后的结果连同html页面返回给前端用户。</p>
<h4 id="i-4-url传输的具体的实例"><a href="#i-4-url传输的具体的实例" class="headerlink" title="i-4 url传输的具体的实例"></a>i-4 url传输的具体的实例</h4><p>在 user\templates\user 目录下新建 login.html 文件，&lt; form action=”/user/login/“ method=”post”<strong>&gt;</strong></p>
<p>在 user\views.py 中编写视图层用户登录逻辑代码，login_view()</p>
<p>在路由配置部分 path(‘login/‘,views.login_view)</p>
<h3 id="后端的数据传给前端的两种方式"><a href="#后端的数据传给前端的两种方式" class="headerlink" title="后端的数据传给前端的两种方式"></a>后端的数据传给前端的两种方式</h3><p>把数据发送到html中的话，后端 return render(request,’index.html’,{‘data’:data}) ,前端：获取数据</p>
<p>若是要在js中处理的话，后端 return render(request ,’index.html’,{‘data’: json.dumps(list),})       ,前端js拿取数据：var List=;</p>
<p>注意在用指令python manage.py startapp app01后，要在setting.py中的INSTALLED_APPS={} 中加入’app01’合法注册</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1].Djano基础教程+实例(重要)<a href="http://c.biancheng.net/django/" target="_blank" rel="noopener">http://c.biancheng.net/django/</a></p>
<p>[2].Django框架的文件结构<a href="https://blog.csdn.net/xzy5210123/article/details/80178128" target="_blank" rel="noopener">https://blog.csdn.net/xzy5210123/article/details/80178128</a></p>
<h3 id="给用户返回服务端的html静态文件的一个实例"><a href="#给用户返回服务端的html静态文件的一个实例" class="headerlink" title="给用户返回服务端的html静态文件的一个实例"></a>给用户返回服务端的html静态文件的一个实例</h3><p>1.准备前端的HTML文件</p>
<p>2.在Views中处理HTML文件的返回</p>
<p>3.在URL中实现路由</p>
<h4 id="templates文件夹的设定："><a href="#templates文件夹的设定：" class="headerlink" title="templates文件夹的设定："></a>templates文件夹的设定：</h4><p>在非templates文件夹中，要返回html文件的话</p>
<p>​    1.把文件夹设置成templates folder</p>
<p>​    2.在setting.py文件夹中，找到TEMPLATES= 的DIRS，模仿templates ,加入</p>
<h3 id="MVC"><a href="#MVC" class="headerlink" title="MVC:"></a>MVC:</h3><p>M:model -数据</p>
<p>V：views- 视图</p>
<p>C：control</p>
<h3 id="MVT"><a href="#MVT" class="headerlink" title="MVT"></a>MVT</h3><p>M : model -数据  数据库的访问部分</p>
<p>V ：view- 视图     核心部分，实现逻辑处理</p>
<p>T: templates           模板        存放静态html文件</p>
<p>整个过程：用户发送url请求，在urls.py中匹配，调用对应的views方法，然后views中调用model的数据库处理部分得到值，填充到templates中，将填充好的html文件返回给用户。</p>
<h3 id="在Django中配置html的静态文件"><a href="#在Django中配置html的静态文件" class="headerlink" title="在Django中配置html的静态文件"></a>在Django中配置html的静态文件</h3><p>在Django中，html页面中所依赖的css，js，images，等都阻止分享</p>
<p>1.建立静态文件的文件夹 （在根目录下建立static文件夹，然后在这个文件夹下可以建立分类js文件夹，css文件夹，font文件夹，image文件夹等）</p>
<p>2.配置文件夹为项目的合法静态文件夹       </p>
<p>​    在setting.py中配置 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">STATICFILES_DIRS &#x3D;(os.path.join(BASE_DIR, &#39;static&#39;),)</span><br></pre></td></tr></table></figure>
<p>然后可以在浏览器中直接<a href="http://127.0.0.1:8000/static/image/11.png访问文件，然后就可以直接在html文件中引用了" target="_blank" rel="noopener">http://127.0.0.1:8000/static/image/11.png访问文件，然后就可以直接在html文件中引用了</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>Numpy包</title>
    <url>/2020/04/18/python/Numpy%E5%8C%85/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>开源的数值计算</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h3 id="2-array数据类型-数组"><a href="#2-array数据类型-数组" class="headerlink" title="2 array数据类型-数组"></a>2 array数据类型-数组</h3><h4 id="2-1-产生数组"><a href="#2-1-产生数组" class="headerlink" title="2.1 产生数组"></a>2.1 产生数组</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#从列表中产生的</span></span><br><span class="line">L=[<span class="number">0</span>,<span class="number">1</span>] a=np.array(L) a=np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>]) a=np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],dtype=float)</span><br><span class="line"></span><br><span class="line"><span class="comment">#特殊的数组</span></span><br><span class="line">np.zeros(<span class="number">0</span>的个数,dtype=<span class="string">'int'</span>)	<span class="comment">#生成全0的数组</span></span><br><span class="line">np.ones(<span class="number">1</span>的个数,dtype=<span class="string">'bool'</span>)	<span class="comment">#生成全1的数组</span></span><br><span class="line">a=np.arange(<span class="number">1</span>,<span class="number">10</span>,<span class="number">2</span>)		<span class="comment">#生成整数序列,生成1~9的整数序列，以2为步长（1,10）左闭右开生成等差数列</span></span><br><span class="line">a=np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">10</span>)        <span class="comment">#生成1~10，的10个等差数列</span></span><br><span class="line">np.random.rand(<span class="number">10</span>)     <span class="comment">#生成随机数</span></span><br><span class="line">np.random.randint(<span class="number">1</span>,<span class="number">10</span>,(<span class="number">5</span>,<span class="number">5</span>))	<span class="comment">#创建一个5x5的随机二维数组</span></span><br><span class="line">np.random.random((<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>))	<span class="comment">#创建3x3x3的随机数组</span></span><br><span class="line">np.random.randint(<span class="number">1</span>,<span class="number">10</span>,<span class="number">5</span>)   <span class="comment">#生成1~10里面5个随机整数</span></span><br><span class="line">np.random.randn(<span class="number">10</span>)   <span class="comment">#生成10个随机数 范围在0~1不包括1</span></span><br></pre></td></tr></table></figure>
<h4 id="2-2-查看"><a href="#2-2-查看" class="headerlink" title="2.2 查看"></a>2.2 查看</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a.dtype		<span class="comment">#查看数组中的数据类型</span></span><br><span class="line">a.shape		<span class="comment">#查看形状，会返回一个元组，每个元素代表着一维的元素数目</span></span><br><span class="line">a.size		<span class="comment">#查看数组里面元素的个数</span></span><br><span class="line">a.ndim   	<span class="comment">#查看数组的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#一维数组</span></span><br><span class="line">a[<span class="number">0</span>]		<span class="comment">#查看下标为0的数据</span></span><br><span class="line">a[<span class="number">1</span>:<span class="number">3</span>]		<span class="comment">#切片操作，查看下标为1~2的数据</span></span><br><span class="line">y=a[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">-3</span>]]		<span class="comment">#这个操作会把a数组中的a[1],a[2],a[-3]的值放到y中</span></span><br><span class="line">mask=np.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],dtype=bool) </span><br><span class="line"></span><br><span class="line"><span class="comment">#多维数组</span></span><br><span class="line">np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>]])</span><br><span class="line">a[<span class="number">1</span>,<span class="number">3</span>]		<span class="comment">#索引第2行第4列</span></span><br><span class="line">a[<span class="number">1</span>]  		<span class="comment">#索引第二行的所有元素</span></span><br><span class="line">a[:,<span class="number">1</span>] 		<span class="comment">#所有第二列的所有元素</span></span><br><span class="line">a[<span class="number">0</span>,<span class="number">3</span>:<span class="number">5</span>]  	<span class="comment">#第一行的第4个和第5个元素,左闭右开</span></span><br></pre></td></tr></table></figure>
<h4 id="2-3-修改"><a href="#2-3-修改" class="headerlink" title="2.3 修改"></a>2.3 修改</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=a[[<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]	<span class="comment">#交换二维数组中的两行</span></span><br></pre></td></tr></table></figure>
<h3 id="3-参考"><a href="#3-参考" class="headerlink" title="3 参考"></a>3 参考</h3><p><a href="https://www.w3school.com.cn/python/python_arrays.asp" target="_blank" rel="noopener">https://www.w3school.com.cn/python/python_arrays.asp</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>pandas包</title>
    <url>/2020/04/18/python/Pandas%E5%8C%85/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h3><p>导入数据包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<p>基本的数据类型：</p>
<p>Series:一维数组</p>
<p>DataFrame:二维表格型的数据结构</p>
<h3 id="2-Series数据结构"><a href="#2-Series数据结构" class="headerlink" title="2.Series数据结构"></a>2.Series数据结构</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s=pd.Series([<span class="number">1</span>,np.nan,<span class="number">2</span>,<span class="number">3</span>]) <span class="comment">#初始化</span></span><br><span class="line">s=pd.Series([<span class="number">1</span>,np.nan,<span class="number">2</span>,<span class="number">3</span>],index=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>,<span class="string">'f'</span>]) <span class="comment">#索引初始化</span></span><br><span class="line"></span><br><span class="line">s.index <span class="comment">#查看索引的行标签</span></span><br><span class="line">s.values <span class="comment">#查看所有值</span></span><br><span class="line">s[<span class="number">0</span>] <span class="comment">#查看某一个值</span></span><br><span class="line">s[<span class="string">'a'</span>:<span class="string">'c'</span>] <span class="comment">#取出s['a']~s['c']的片</span></span><br><span class="line"></span><br><span class="line">s.index.name=<span class="string">'索引'</span>	<span class="comment">#索引赋值</span></span><br><span class="line">s.index=list(<span class="string">'abcde'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-DataFrame数据类型"><a href="#3-DataFrame数据类型" class="headerlink" title="3.DataFrame数据类型"></a>3.DataFrame数据类型</h3><h3 id="4-Pandas相关操作"><a href="#4-Pandas相关操作" class="headerlink" title="4.Pandas相关操作"></a>4.Pandas相关操作</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Want to do</th>
<th>How to do</th>
</tr>
</thead>
<tbody>
<tr>
<td>读取xlsx文件的数据</td>
<td>midf=pd.read_excel(‘香港酒店数据.xlsx’)      <br />df.read_文件类型(r’绝对路径名\文件名.后缀’) ，<br />比如read_excel(r’C:\Users\豆瓣电影数据.xlsx‘)，<br />如果文件和执行.nb在一个路径下，则不需要加路径。</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>Spacy库-英文文本分词库</title>
    <url>/2020/06/09/python/Spacy%E5%BA%93/</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>是预先读入一个已经训练好的词向量模型，在海量语料上训练的结果。</p>
<p>使用举例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">doc&#x3D;nlp(要分析的text)</span><br><span class="line">list(doc.sents)  #打印所有的句子</span><br><span class="line">list(doc.sents)[0].text  #取出某一句话</span><br></pre></td></tr></table></figure>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>用spacy库构建知识图谱 <a href="https://www.jianshu.com/p/df18cde76cda" target="_blank" rel="noopener">https://www.jianshu.com/p/df18cde76cda</a></p>
<p>用spacy库进行分词的例子<a href="https://github.com/ZhangRaymond/Learning-Note/blob/master/demo-spacy-text-processing.ipynb" target="_blank" rel="noopener">https://github.com/ZhangRaymond/Learning-Note/blob/master/demo-spacy-text-processing.ipynb</a></p>
<p>分词的例子2<a href="https://blog.csdn.net/weixin_40056628/article/details/89361587" target="_blank" rel="noopener">https://blog.csdn.net/weixin_40056628/article/details/89361587</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>invalid syntax问题</title>
    <url>/2020/05/11/python/invalid%20syntax%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="一-问题"><a href="#一-问题" class="headerlink" title="一.问题"></a>一.问题</h3><p>学习python时，明明代码没有一点问题，但是每次运行时都会显示<strong>”SyntaxError: invalid syntax”</strong>。</p>
<h3 id="二-原因"><a href="#二-原因" class="headerlink" title="二.原因"></a>二.原因</h3><p><strong>”SyntaxError: invalid syntax”</strong>。意思是<strong>语法错误</strong></p>
<p>有一下几种解决办法：</p>
<h4 id="1-版本问题："><a href="#1-版本问题：" class="headerlink" title="1.版本问题："></a>1.版本问题：</h4><p>因为python2和python3是不兼容的，所以一些可以在python2上运行的代码不一定可以在python3上运行；可以尝试更换版本；</p>
<h4 id="2-路径问题："><a href="#2-路径问题：" class="headerlink" title="2.路径问题："></a>2.路径问题：</h4><p>记得仔细查看自己的路径是否正确；</p>
<h4 id="3-安装第三方模块时："><a href="#3-安装第三方模块时：" class="headerlink" title="3.安装第三方模块时："></a>3.安装第三方模块时：</h4><p>在安装第三方模块时也有可能出现“SyntaxError: invalid syntax”这个问题，这时需要检查一些是否是在cmd窗口下安装，同时，要到python的安装目录里面，找到pip所在的目录里面进行安装；</p>
<h4 id="4-编写问题："><a href="#4-编写问题：" class="headerlink" title="4.编写问题："></a>4.编写问题：</h4><p>忘记在 if , elif , else , for , while , class ,def 声明末尾添加 冒号( : )；<br>误将 = 当成 == 使用；</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>endswitch()函数</title>
    <url>/2020/05/06/python/endswitch()%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h3 id="一-功能："><a href="#一-功能：" class="headerlink" title="一.功能："></a>一.功能：</h3><p>判断字符串是否以指定字符或者字符串结尾。</p>
<h3 id="二-函数原型："><a href="#二-函数原型：" class="headerlink" title="二.函数原型："></a>二.函数原型：</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">str.endswith(&quot;suffix&quot;,    	&#x3D;&gt; 后缀，可以是单个字符，也可以是字符串，还可以是元组;</span><br><span class="line">	      start &#x3D; 0,  	&#x3D;&gt; 索引字符串的起始位置;</span><br><span class="line">	      end &#x3D; len(str))	&#x3D;&gt; 索引字符串的结束位置。</span><br><span class="line">返回值：布尔类型（True,False）</span><br></pre></td></tr></table></figure>
<h3 id="三-例子"><a href="#三-例子" class="headerlink" title="三.例子"></a>三.例子</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">str=<span class="string">"Hello World"</span></span><br><span class="line">str.endswitch(<span class="string">"d"</span>)  <span class="comment">#判断是否以d结尾</span></span><br><span class="line">str.endswitch(<span class="string">"d"</span>,<span class="number">0</span>,<span class="number">6</span>) <span class="comment">#索引"Hello W"是否以d结尾</span></span><br><span class="line">str[<span class="number">0</span>:<span class="number">6</span>].endswitch(<span class="string">"d"</span>) <span class="comment">#只索引str[0:6]的</span></span><br><span class="line">str.endswitch((<span class="string">"e"</span>,<span class="string">"o"</span>)) <span class="comment">#遍历元组中的元素，存在则返回True</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>Iterable(可迭代对象)</title>
    <url>/2020/05/08/python/iterable%E5%AF%B9%E8%B1%A1/</url>
    <content><![CDATA[<h3 id="一-定义"><a href="#一-定义" class="headerlink" title="一.定义"></a>一.定义</h3><p>可以对list、tuple、dict、set、str等类型的数据使用for…in…的循环语法，会从其中依次拿到数据元素进行使用，把这样的过程称为<strong>遍历</strong>，也叫<strong>迭代</strong>。把可以通过for…in…这类语句迭代读取一条数据元素供我们使用的这个对象就称之为<strong>可迭代对象(Iterable)</strong></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>jieba库的介绍</title>
    <url>/2020/05/24/python/jieba%E5%BA%93/</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/dongzixian/article/details/103240861" target="_blank" rel="noopener">https://blog.csdn.net/dongzixian/article/details/103240861</a></p>
<p><a href="https://www.cnblogs.com/han20180705/p/9470622.html" target="_blank" rel="noopener">https://www.cnblogs.com/han20180705/p/9470622.html</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>networkx库-绘图</title>
    <url>/2020/05/08/python/networkx%E5%BA%93-%E7%BB%98%E5%9B%BE/</url>
    <content><![CDATA[<h3 id="一-创建图"><a href="#一-创建图" class="headerlink" title="一.创建图"></a>一.创建图</h3><h4 id="1-图的声明："><a href="#1-图的声明：" class="headerlink" title="1.图的声明："></a>1.图的声明：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx </span><br><span class="line"></span><br><span class="line">G = nyix.Graph()	<span class="comment">#无多重边无向图</span></span><br><span class="line">G = nx.DiGraph()	<span class="comment">#无多重边有向图</span></span><br><span class="line">G = nx.MultiGraph()		<span class="comment">#有多重边无向图</span></span><br><span class="line">G = nx.MultiDiGraph()	<span class="comment">#有多重边有向图</span></span><br></pre></td></tr></table></figure>
<h4 id="2-添加节点和边："><a href="#2-添加节点和边：" class="headerlink" title="2.添加节点和边："></a>2.添加节点和边：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 方法一--------------------------------------</span></span><br><span class="line">G.add_node(<span class="string">'a'</span>)  <span class="comment"># 添加点a</span></span><br><span class="line">G.add_node(<span class="number">1</span>,<span class="number">1</span>)  <span class="comment"># 用坐标来添加点</span></span><br><span class="line">G.add_edge(<span class="string">'x'</span>,<span class="string">'y'</span>)   <span class="comment"># 添加边,起点为x，终点为y</span></span><br><span class="line">G.add_weight_edges_from([(<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="number">1.0</span>)])  <span class="comment"># 第三个输入量为权值</span></span><br><span class="line"><span class="comment"># 方法二--------------------------------------</span></span><br><span class="line">list = [[(<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="number">5.0</span>),(<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="number">3.0</span>),(<span class="string">'a'</span>,<span class="string">'c'</span>,<span class="number">1.0</span>)]</span><br><span class="line">G.add_weight_edges_from([(list)])</span><br><span class="line"><span class="comment"># 方法三--------------------------------------</span></span><br><span class="line">G = nx.from_pandas_edgelist(df_table, source = <span class="string">'A'</span>, target = <span class="string">'B'</span>, edge_attr = <span class="string">'C'</span>, create_using = nx.DiGraph())</span><br></pre></td></tr></table></figure>
<h4 id="3-图的显示："><a href="#3-图的显示：" class="headerlink" title="3.图的显示："></a>3.图的显示：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">nx.draw(G,</span><br><span class="line">        pos = nx.random_layout(G), <span class="comment"># pos 指的是布局,主要有spring_layout,random_layout,circle_layout,shell_layout</span></span><br><span class="line">        node_color = <span class="string">'b'</span>,   <span class="comment"># node_color指节点颜色,有rbykw,同理edge_color </span></span><br><span class="line">        edge_color = <span class="string">'r'</span>,</span><br><span class="line">        with_labels = <span class="literal">True</span>,  <span class="comment"># with_labels指节点是否显示名字</span></span><br><span class="line">        font_size =<span class="number">18</span>,  <span class="comment"># font_size表示字体大小,font_color表示字的颜色</span></span><br><span class="line">        node_size =<span class="number">20</span>)  <span class="comment"># font_size表示字体大小,font_color表示字的颜色</span></span><br><span class="line">plt.savefig(<span class="string">"network.png"</span>)</span><br><span class="line">nx.write_gexf(G, <span class="string">'network.gexf'</span>)  <span class="comment"># gexf格式文件可以导入gephi中进行分析</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="二-from-pandas-edgelist"><a href="#二-from-pandas-edgelist" class="headerlink" title="二.from_pandas_edgelist()"></a>二.from_pandas_edgelist()</h3><h4 id="1-简介："><a href="#1-简介：" class="headerlink" title="1.简介："></a>1.简介：</h4><p>把包含边缘列表的pandas.DataFrame类型的数据转换成图</p>
<h4 id="2-参数："><a href="#2-参数：" class="headerlink" title="2.参数："></a>2.参数：</h4><p>（df，source，target，edge_attr，create_using)</p>
<details>
    <summary>具体介绍</summary>
    -df:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Pandas DataFrame)&nbsp;&nbsp;&nbsp;&nbsp;-图的边的集合<br>
    -source:&nbsp;&nbsp;&nbsp;&nbsp;(str or int)&nbsp;&nbsp;&nbsp;&nbsp;-源节点的有效的列名(有向图)<br>
    -targe:&nbsp;&nbsp;&nbsp;&nbsp;(str or int)&nbsp;&nbsp;&nbsp;&nbsp;-目标节点的有效的列名<br>
    -edge_attr:&nbsp;&nbsp;&nbsp;&nbsp;(str or int,iterable可迭代对象,True or None)&nbsp;&nbsp;&nbsp;&nbsp;边的名字=映射在df中要添加的列的名字，若=True，则除了前面已经用到的两个列以外，剩下的列都添加进去。<br>
    -create_using:&nbsp;&nbsp;&nbsp;&nbsp;(NetworkX graph constructor, optional (default=nx.Graph))&nbsp;&nbsp;&nbsp;&nbsp;-要创建的图形类型。如果是图形实例，则在填充之前清除。<br>
</details>

<h4 id="3-举例："><a href="#3-举例：" class="headerlink" title="3.举例："></a>3.举例：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">G = nx.from_pandas_edgelist(routes_us, source = <span class="string">'source'</span>, target = <span class="string">'target'</span>, edge_attr = <span class="string">'numbers'</span>, create_using = nx.DiGraph())</span><br></pre></td></tr></table></figure>
<h3 id="三-draw"><a href="#三-draw" class="headerlink" title="三.draw()"></a>三.draw()</h3><p>nx.draw()至少接受一个参数：待绘制的网络G</p>
<details>
    <summary>其他参数</summary>
    -'node_size': &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;指定节点的尺寸大小(默认是300)<br>
    -'node_color':  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;指定节点的颜色(默认是红色，可以用字符串简单标识颜色，例如'r'为红色，'b'为绿色等)<br>
    -'node_shape':  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;节点的形状(默认是圆形，用字符串'o'标识)<br>
    -'alpha': &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;透明度(默认是1.0，不透明，0为完全透明)<br>
    -'width: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;边的宽度(默认为1.0)<br>
    -'edge_color': &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;边的颜色(默认为黑色)<br>
    -'edge_cmp':&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;edge_cmap与plt.cm.parameter开成映射，在图表上表现为边的颜色。<br>
    -'style': &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;边的样式(默认是可实现，可选: solid|dashed|dotted,dashdot)<br>
    -'with_labels': &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;节点是否带标签(默认是True)<br>
    -'font_size': &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;节点标签字体大小(默认为12)<br>
    -font_color': &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;节点标签字体颜色(默认为黑色)
</details>




<h3 id="四-draw-network-edge-labels"><a href="#四-draw-network-edge-labels" class="headerlink" title="四.draw_network_edge_labels()"></a>四.draw_network_edge_labels()</h3><h4 id="1-作用："><a href="#1-作用：" class="headerlink" title="1.作用："></a>1.作用：</h4><p>绘制图中带有边的权重的图。</p>
<h4 id="2-举例："><a href="#2-举例：" class="headerlink" title="2.举例："></a>2.举例：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">G=nx.Graph(...)</span><br><span class="line">pos=nx.spring_layout(...)</span><br><span class="line">edge=dict(&#123;&#125;)</span><br><span class="line">nx.draw_network_edge_labels(G,pos,edge_labels=edge)</span><br></pre></td></tr></table></figure>
<h3 id="五-spring-layout-函数"><a href="#五-spring-layout-函数" class="headerlink" title="五.spring_layout()函数"></a>五.spring_layout()函数</h3><h4 id="1-函数作用："><a href="#1-函数作用：" class="headerlink" title="1.函数作用："></a>1.函数作用：</h4><p>用来建立布局，起到美化作用。获取node的位置，</p>
<h4 id="2-参数介绍："><a href="#2-参数介绍：" class="headerlink" title="2.参数介绍："></a>2.参数介绍：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">spring_layout(G, dim=<span class="number">2</span>, k=<span class="literal">None</span>, pos=<span class="literal">None</span>, fixed=<span class="literal">None</span>, iterations=<span class="number">50</span>, weight=<span class="string">'weight'</span>, scale=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>取值</th>
<th>介绍</th>
</tr>
</thead>
<tbody>
<tr>
<td>G</td>
<td>Networkx graph</td>
<td>传入DataFrame的值</td>
</tr>
<tr>
<td>dim</td>
<td>int</td>
<td>布局的维度</td>
</tr>
<tr>
<td>k</td>
<td>float 或者default=None</td>
<td>节点间的最佳距离。如果没有，则将距离设置为1/sqrt(n)，其中n是节点的数量。增加此值以将节点移动到更远的地方。</td>
</tr>
<tr>
<td>pos</td>
<td>dict 或者没有<br />default=None</td>
<td>节点的初始位置为字典，节点为键，值为列表或元组。如果没有，则使用随机生成图node的初始位置。</td>
</tr>
<tr>
<td>fixed</td>
<td>list or None optional (default=None)</td>
<td>节点保持固定在初始位置。</td>
</tr>
<tr>
<td>iterations</td>
<td>int optional (default=50)</td>
<td>弹簧松弛的迭代次数</td>
</tr>
<tr>
<td>weight</td>
<td>string or None optional (default=’weight’)</td>
<td>保存用于边缘权重的数值的边缘属性。如果没有，则所有边的权值都是1。</td>
</tr>
<tr>
<td>scale</td>
<td>float (default=1.0)</td>
<td>位置的比例因子。节点被放置在一个大小为[0,scale] x [0,scale]的框中。</td>
</tr>
<tr>
<td>return</td>
<td>dict</td>
<td>由节点键控的位置字典</td>
</tr>
</tbody>
</table>
</div>
<h4 id="3-举例"><a href="#3-举例" class="headerlink" title="3.举例"></a>3.举例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">G=nx.path_graph(<span class="number">4</span>)</span><br><span class="line">pos=nx.spring_layout(G)</span><br></pre></td></tr></table></figure>
<h3 id="六-参考"><a href="#六-参考" class="headerlink" title="六.参考"></a>六.参考</h3><p><a href="https://blog.csdn.net/Zhili_wang/article/details/89368177" target="_blank" rel="noopener">https://blog.csdn.net/Zhili_wang/article/details/89368177</a></p>
<p><a href="https://www.jianshu.com/p/6292e45da3d0" target="_blank" rel="noopener">https://www.jianshu.com/p/6292e45da3d0</a>   可以参考的是其中读取各种文件和绘制图形的过程</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>python-os库的介绍</title>
    <url>/2020/05/12/python/os%E5%BA%93/</url>
    <content><![CDATA[<h3 id="一-system-函数"><a href="#一-system-函数" class="headerlink" title="一.system()函数"></a>一.system()函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.system(cmd)<span class="comment"># 命令行的命令用双印号括起来</span></span><br></pre></td></tr></table></figure>
<h4 id="1-返回值："><a href="#1-返回值：" class="headerlink" title="1.返回值："></a>1.返回值：</h4><p>执行成功则返回0，若返回其他值，类型如下：</p>
<details>
    <summary>大致类型</summary>
    "OS error code   1:  Operation not permitted"<br>
 "OS error code   2:  No such file or directory"<br>
 "OS error code   3:  No such process"<br>
 "OS error code   4:  Interrupted system call"<br>
 "OS error code   5:  Input/output error"<br>
 "OS error code   6:  No such device or address"<br>
 "OS error code   7:  Argument list too long"<br>
 "OS error code   8:  Exec format error"<br>
 "OS error code   9:  Bad file descriptor"<br>
 "OS error code  10:  No child processes"<br>
 "OS error code  11:  Resource temporarily unavailable"<br>
 "OS error code  12:  Cannot allocate memory"<br>
 "OS error code  13:  Permission denied"<br>
 "OS error code  14:  Bad address"<br>
 "OS error code  15:  Block device required"<br>
 "OS error code  16:  Device or resource busy"<br>
 "OS error code  17:  File exists"<br>
 "OS error code  18:  Invalid cross-device link"<br>
 "OS error code  19:  No such device"<br>
 "OS error code  20:  Not a directory"<br>
 "OS error code  21:  Is a directory"<br>
</details>

<h3 id="二-popen-函数"><a href="#二-popen-函数" class="headerlink" title="二.popen()函数"></a>二.popen()函数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">r&#x3D;os.popen(&#39;ping www.baidu,com&#39;)</span><br></pre></td></tr></table></figure>
<h4 id="1-返回值：-1"><a href="#1-返回值：-1" class="headerlink" title="1.返回值："></a>1.返回值：</h4><p>返回脚本执行过程中的输出内容。</p>
<p>但是当return str时，调用函数无法输出str的内容，此时可以打印一下该函数执行即可： print(fun(return str))</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>python-DataFrame()函数</title>
    <url>/2020/05/07/python/pandas-DataFrame()%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h3 id="一-简介"><a href="#一-简介" class="headerlink" title="一.简介"></a>一.简介</h3><p>DataFrame是Python中Pandas库中的一种数据结构，它类似execl，是一种二维表。其单元格可以存放数值、字符串等。</p>
<h3 id="二-使用"><a href="#二-使用" class="headerlink" title="二.使用"></a>二.使用</h3><h4 id="1-引用头文件"><a href="#1-引用头文件" class="headerlink" title="1.引用头文件"></a>1.引用头文件</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h4 id="2-创建变量"><a href="#2-创建变量" class="headerlink" title="2.创建变量"></a>2.创建变量</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df1 = pd.DataFrame(np.random.randn(<span class="number">3</span>, <span class="number">3</span>), index=list(<span class="string">'abc'</span>), columns=list(<span class="string">'ABC'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#参数说明：第一个参数是要存放在DataFrame里的数据，第二个参数index就是行名，第三个参数就是列名</span></span><br><span class="line"><span class="comment">#其中，后两个参数List的长要和前面DataFrame的对应长度匹配。</span></span><br><span class="line">print(df1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#           A         B         C</span></span><br><span class="line"><span class="comment"># a -0.612978  0.237191  0.312969</span></span><br><span class="line"><span class="comment"># b -1.281485  1.135944  0.162456</span></span><br><span class="line"><span class="comment"># c  2.232905  0.200209  0.028671</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#直接创建：</span></span><br><span class="line">df4 = pd.DataFrame([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], </span><br><span class="line">					[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">                    [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]],</span><br><span class="line">                   index=list(<span class="string">'abc'</span>), columns=list(<span class="string">'ABC'</span>))</span><br><span class="line"><span class="comment">#使用字典创建：</span></span><br><span class="line">dic1 = &#123;</span><br><span class="line">    <span class="string">'name'</span>: [</span><br><span class="line">        <span class="string">'张三'</span>, <span class="string">'李四'</span>, <span class="string">'王二麻子'</span>, <span class="string">'小淘气'</span>], <span class="string">'age'</span>: [</span><br><span class="line">            <span class="number">37</span>, <span class="number">30</span>, <span class="number">50</span>, <span class="number">16</span>], <span class="string">'gender'</span>: [</span><br><span class="line">                <span class="string">'男'</span>, <span class="string">'男'</span>, <span class="string">'男'</span>, <span class="string">'女'</span>]&#125;</span><br><span class="line">df5 = pd.DataFrame(dic1)</span><br><span class="line">print(df5)</span><br><span class="line"></span><br><span class="line"><span class="comment">#    age gender  name</span></span><br><span class="line"><span class="comment"># 0   37      男    张三</span></span><br><span class="line"><span class="comment"># 1   30      男    李四</span></span><br><span class="line"><span class="comment"># 2   50      男  王二麻子</span></span><br><span class="line"><span class="comment"># 3   16      女   小淘气</span></span><br></pre></td></tr></table></figure>
<h4 id="3-查看操作"><a href="#3-查看操作" class="headerlink" title="3.查看操作"></a>3.查看操作</h4><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>df.dtypes</td>
<td>返回</td>
</tr>
<tr>
<td>df.head(6)</td>
<td>显示前6行的数据，若不带参数则会显示全部数据</td>
</tr>
<tr>
<td>df.tail(6)</td>
<td>显示后6行的数据，若不带参数也会显示全部数据</td>
</tr>
<tr>
<td>查看DataFrame的index,columns和values</td>
<td>df.index和df.columns和df.values即可</td>
</tr>
</tbody>
</table>
</div>
<h3 id="三-参考"><a href="#三-参考" class="headerlink" title="三.参考"></a>三.参考</h3><p><a href="https://www.cnblogs.com/luban/p/9117360.html" target="_blank" rel="noopener">https://www.cnblogs.com/luban/p/9117360.html</a></p>
<p><a href="https://blog.csdn.net/tefuirnever/article/details/93708964" target="_blank" rel="noopener">https://blog.csdn.net/tefuirnever/article/details/93708964</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>py2neo库的介绍</title>
    <url>/2020/05/12/python/py2neo%E5%BA%93/</url>
    <content><![CDATA[<h3 id="一-简介"><a href="#一-简介" class="headerlink" title="一.简介"></a>一.简介</h3><p>这个库是python和neo4j进行连接的库，可以用这个库的相关函数对Neo4j的数据库进行操作。</p>
<p>安装指令：pip install py2neo</p>
<h4 id="1-引用代码："><a href="#1-引用代码：" class="headerlink" title="1.引用代码："></a>1.引用代码：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> py2neo <span class="keyword">import</span> Graph,Node,Relationship</span><br></pre></td></tr></table></figure>
<h3 id="二-相关操作"><a href="#二-相关操作" class="headerlink" title="二.相关操作"></a>二.相关操作</h3><h4 id="1-连接操作："><a href="#1-连接操作：" class="headerlink" title="1.连接操作："></a>1.连接操作：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_graph = Graph(</span><br><span class="line">    <span class="string">"http://localhost:7474"</span>, </span><br><span class="line">    username=<span class="string">"neo4j"</span>, </span><br><span class="line">    password=<span class="string">"neo4j"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="2-节点的建立"><a href="#2-节点的建立" class="headerlink" title="2.节点的建立"></a>2.节点的建立</h4><p><a href="https://www.jianshu.com/p/a2497a33390f" target="_blank" rel="noopener">https://www.jianshu.com/p/a2497a33390f%20%20</a></p>
<p><a href="https://blog.csdn.net/amao1998/article/details/81041143" target="_blank" rel="noopener">https://blog.csdn.net/amao1998/article/details/81041143</a></p>
<p>这里neo4j-driver和py2neo是有区别的，</p>
<p>前者是官方支持的，后者则在用户友好度上有优势，但还是建议使用前者。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>plt-figure()函数</title>
    <url>/2020/05/07/python/plt-figure()%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h3 id="一-简介："><a href="#一-简介：" class="headerlink" title="一.简介："></a>一.简介：</h3><p>创建一个图形实例</p>
<h3 id="二-语法说明"><a href="#二-语法说明" class="headerlink" title="二.语法说明"></a>二.语法说明</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">figure(num=<span class="literal">None</span>, figsize=<span class="literal">None</span>, dpi=<span class="literal">None</span>, facecolor=<span class="literal">None</span>, edgecolor=<span class="literal">None</span>, frameon=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">      num : 图像编号或名称，数字为编号，字符串为名称</span></span><br><span class="line"><span class="string">  figsize : 指定figure的宽和高，单位为英寸</span></span><br><span class="line"><span class="string">      dpi : 指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80</span></span><br><span class="line"><span class="string">facecolor : 背景的颜色</span></span><br><span class="line"><span class="string">edgecolor : 边框颜色</span></span><br><span class="line"><span class="string">  frameon : 是否显示边框</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<h3 id="三-举例"><a href="#三-举例" class="headerlink" title="三.举例"></a>三.举例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">4</span>, <span class="number">3</span>), facecolor=<span class="string">'blue'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>pykg2vec-表示学习的库</title>
    <url>/2020/06/09/python/pykg2vec%E5%BA%93-%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BA%93/</url>
    <content><![CDATA[<h3 id="一-一些概念"><a href="#一-一些概念" class="headerlink" title="一.一些概念"></a>一.一些概念</h3><h4 id="1-pkl文件"><a href="#1-pkl文件" class="headerlink" title="1..pkl文件"></a>1..pkl文件</h4><p>python中的存储方式，将python项目过程中用到的一些暂时变量、或者需要提前、暂存的字符串、列表、字典等数据保存起来。</p>
<blockquote id="fn_参考">
<sup>参考</sup>. <a href="https://www.cnblogs.com/cainiaoxuexi2017-ZYA/p/11673982.html" target="_blank" rel="noopener">https://www.cnblogs.com/cainiaoxuexi2017-ZYA/p/11673982.html</a><a href="#reffn_参考" title="Jump back to footnote [参考] in the text."> &#8617;</a>
</blockquote>
<h4 id="2-tsv文件"><a href="#2-tsv文件" class="headerlink" title="2..tsv文件"></a>2..tsv文件</h4><p>制表符分隔符，制表符分隔数据段成列，可以用Excel进行打开。</p>
<h4 id="3-pickle文件"><a href="#3-pickle文件" class="headerlink" title="3..pickle文件"></a>3..pickle文件</h4><p>用于将python对象为一个字节表示存储在磁盘或通过网络传输的python模块创建的文件。</p>
<p>一个Python模块，允许将对象序列化到磁盘上的文件和反序列化回程序在运行时创建的文件，保存表示对象的字节流，更经常使用.P延伸，而不是“ .pickle 。</p>
<h4 id="4-数据集"><a href="#4-数据集" class="headerlink" title="4.数据集"></a>4.数据集</h4><p>以fb15k的数据为例子。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;m&#x2F;0b7x18   &#x2F;people&#x2F;person&#x2F;profession	&#x2F;m&#x2F;05sxg2</span><br></pre></td></tr></table></figure>
<p>数据格式：每一行都包含； 一个三元组和两个mid(Freebase实体的标识）和关系标识。第一个mid是关系的头实体，第三个是关系的尾实体，中间是关系。</p>
<h4 id="5-关系预测的结果解释"><a href="#5-关系预测的结果解释" class="headerlink" title="5.关系预测的结果解释"></a>5.关系预测的结果解释</h4><p>以infer_tails(1,10,topk=5)为例子</p>
<p>这里的1是ent_label里面的第二个实体的mid，10是rel_label里面的第11个关系，</p>
<p>topk=5是预测和head有关系的排名前5的tail</p>
<p>/m/03_dj 是Jonathan Swift</p>
<p>/m/0100mt是El Paso, Texas  是Texas州，El Paso县</p>
<p>/m/05m7zg是David Tennant   演员，饰演足球的演员</p>
<p>/m/05wh0sh是Vladimir Lenin</p>
<h4 id="6-模型训练和关系推理两个阶段的衔接"><a href="#6-模型训练和关系推理两个阶段的衔接" class="headerlink" title="6.模型训练和关系推理两个阶段的衔接"></a>6.模型训练和关系推理两个阶段的衔接</h4><p>第一阶段训练得到的是embedding，第二阶段的预测是利用embedding去遍历所有的，找到满足h+r=t的关系即可</p>
<h4 id="7-freebase数据集介绍"><a href="#7-freebase数据集介绍" class="headerlink" title="7.freebase数据集介绍"></a>7.freebase数据集介绍</h4><p><a href="https://developer.aliyun.com/article/717320" target="_blank" rel="noopener">https://developer.aliyun.com/article/717320</a></p>
<p>其中的关系介绍： mid1 people.person.place_of_birth mid2</p>
<h3 id="二-整个文件的架构图"><a href="#二-整个文件的架构图" class="headerlink" title="二.整个文件的架构图"></a>二.整个文件的架构图</h3><p>inference.py 文件  用来进行预测，使用此脚本检查训练的结果，并执行手动推断任务。</p>
<p>tune_model.py  是用来调节某一个单一算法的，可以用来训练某个已有的模型（利用自己的标注数据）</p>
<p>train.py  运行一个算法</p>
<p>config文件夹：文件配置模块，提供解析数据集的必要模块，基线图超参数的基准值</p>
<p>core文件夹：嵌入算法的核心代码组成，每种算法都实现为单独的python模块</p>
<p>utils文件夹：各种实用程序组成的模块：数据准备+数据可视化+算法评估+数据生成器+贝叶斯优化器</p>
<p>example文件夹：包含示例代码，可用于运行单个模块或一次运行所有模块或调整模块</p>
<h4 id="train-py中的模型参数传递过程"><a href="#train-py中的模型参数传递过程" class="headerlink" title="train.py中的模型参数传递过程"></a>train.py中的模型参数传递过程</h4><p>mian中参数的调用：=Importer().import_model_config()</p>
<p>对于import_model_config()</p>
<p>返回的参数= getattr(importlib.import_model(),….)</p>
<p>并且self.config_path=pykg2vec.config.config，model_path=pykg2vec.core</p>
<p>对于import_mode()，传入的是config_path，然后返回的是调用config.py中的所有类</p>
<p>对于getattr()：（传入的是config.py中的所有类，返回的是configMap[name]=TransE的类)</p>
<h4 id="模型训练的输入"><a href="#模型训练的输入" class="headerlink" title="模型训练的输入"></a>模型训练的输入</h4><p>1.所有三元组以文本格式存储，，每个关系一行，使用制表符\t分隔实体和关系，head  relation  tail</p>
<p>2.将文本文件根据参考名称分成三个文件：train.txt ，valid.txt ，test.txt</p>
<p>3.创建一个文件夹包含这个三个文件，</p>
<p>4.使用如下命令训练一个数据集：python <a href="http://train.py" target="_blank" rel="noopener">train.py</a> -mn TransE -ds trains.txt -dsp [文件路径存储路径]</p>
<p>1.所有三元组以文本格式存储，，每个关系一行，使用制表符\t分隔实体和关系，head  relation  tail </p>
<p>2.将文本文件根据参考名称分成三个文件：train.txt ，valid.txt ，test.txt </p>
<p>3.创建一个文件夹包含这个三个文件， </p>
<p>4.使用如下命令训练一个数据集：python train.py -mn TransE -ds trains.txt -dsp [文件路径存储路径]</p>
<h4 id="模型训练的输出"><a href="#模型训练的输出" class="headerlink" title="模型训练的输出"></a>模型训练的输出</h4><p>模型训练完后，得到的是实体和关系的向量表示，进一步可以做关系推理知识抽取的任务。</p>
<p>ent_embedding.tsv是一个神经网络的嵌入矩阵，其列=hidden_size，其行=实体个数</p>
<p>ent_labels.tsv是所有实体</p>
<p>rel_embedding.tsv也是一个神经网络的嵌入矩阵，其列=hidden_size，其行=关系个数</p>
<h4 id="config-config-py文件中"><a href="#config-config-py文件中" class="headerlink" title="/config/config.py文件中"></a>/config/config.py文件中</h4><p>KGEArgParser：类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这个类实现参数解析器，定义所有可能的参数，有全局参数，也有本地参数，也即在控制台该如何输入的参数。每个模型都有各种的参数，也有公共的参数，以及参数对应的功能。</span><br><span class="line"></span><br><span class="line">- 这其中parse的函数是什么作用？</span><br></pre></td></tr></table></figure>
<p>Import类</p>
<p>用于定义算法名称的映射，并提供用于加载配置和模型的方法</p>
<p>ArgumentParser</p>
<p>是pyhon的一个子库。用于解析命令行参数</p>
<p><a href="https://www.carymic.com/tag/argumentparser/" target="_blank" rel="noopener">https://www.carymic.com/tag/argumentparser/</a></p>
<p>对于argparse.ArgumentParser()函数的用法：<a href="https://blog.csdn.net/the_time_runner/article/details/97941409" target="_blank" rel="noopener">https://blog.csdn.net/the_time_runner/article/details/97941409</a></p>
<h4 id="utils-kgcontroller-py文件中"><a href="#utils-kgcontroller-py文件中" class="headerlink" title="/utils/kgcontroller.py文件中"></a>/utils/kgcontroller.py文件中</h4><p>进行知识图谱的构建，把读入的三元组数据按照一定规则存储起来。</p>
<p>如果不在控制台输入数据集的名称和路径，则默认名称是Freebase15k的数据集，路径无。</p>
<h4 id="main中"><a href="#main中" class="headerlink" title="/main中"></a>/main中</h4><ol>
<li>从控制台获取相关参数</li>
<li>准备输入的原始数据</li>
<li>从Importer()中获取对应模型的参数配置和定义</li>
<li>模型训练</li>
</ol>
<h3 id="三-相关参数介绍"><a href="#三-相关参数介绍" class="headerlink" title="三.相关参数介绍"></a>三.相关参数介绍</h3><div class="table-container">
<table>
<thead>
<tr>
<th>参数名</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mean Rank</td>
<td>那些预测尾实体命中了的排名的平均</td>
</tr>
<tr>
<td>Filtered Mean Rank</td>
<td>经过筛选之后的预测的尾实体的排名的平均</td>
</tr>
<tr>
<td>Mean Reciprocal Rank</td>
<td>对于一个query，若第一个正确答案排在第n位，则MRR得分就是1\n，然后取Q为样本                                        query集合，取平均</td>
</tr>
<tr>
<td>batch_size：</td>
<td>更新梯度中使用的样本数（批量梯度下降算法）</td>
</tr>
<tr>
<td>iterations：</td>
<td>迭代次数，每次迭代更新一次网络结构的参数，每一次迭代得到的结果都会被作为下一次迭代的初始值                 其中，一个迭代=一个（batch_size）数据正向通过+一个（batch_size）数据反向通过（其中：前向传播                  根据xi得到y的表达式，反向传播是基于损失函数求解参数？？？？</td>
</tr>
<tr>
<td>epochs</td>
<td>前向传播+反向传播所有批次的单次迭代训练=1个周期就是所有数据的单词前向和反向传递</td>
</tr>
<tr>
<td>loss</td>
<td>目标函数值，随着训练轮数（epoch）的增加而缓慢下降+接近最优值或找到某个局部最优值。</td>
</tr>
<tr>
<td>learning_rate</td>
<td>过大时导致模型难以收敛，过小时收敛速度过慢；在梯度下降过程中更新权重时的超参数。</td>
</tr>
<tr>
<td>margin：</td>
<td>最大分类间隔的超平面。</td>
</tr>
<tr>
<td>sampling:uniform</td>
<td>是采样，[0,1]采样</td>
</tr>
<tr>
<td>argument是实参，parameter是形参</td>
</tr>
</tbody>
</table>
</div>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>学习率：<a href="https://blog.csdn.net/u012526436/article/details/90486021" target="_blank" rel="noopener">https://blog.csdn.net/u012526436/article/details/90486021</a></p>
<p>train loss和test loss：<a href="https://www.cnblogs.com/chason95/articles/10575859.html" target="_blank" rel="noopener">https://www.cnblogs.com/chason95/articles/10575859.html</a></p>
<p>MRR简介：<a href="http://www.voidcn.com/article/p-hgmpcymt-sr.html" target="_blank" rel="noopener">http://www.voidcn.com/article/p-hgmpcymt-sr.html</a></p>
<p>深度学习中的相关参数介绍：<a href="https://blog.csdn.net/Gamer_gyt/article/details/87927075" target="_blank" rel="noopener">https://blog.csdn.net/Gamer_gyt/article/details/87927075</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>python语法小记</title>
    <url>/2020/05/13/python/python%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<h3 id="with…as…语句"><a href="#with…as…语句" class="headerlink" title="with…as…语句"></a>with…as…语句</h3><h3 id="一-with…as…语句"><a href="#一-with…as…语句" class="headerlink" title="一.with…as…语句"></a>一.with…as…语句</h3><h4 id="1-作用："><a href="#1-作用：" class="headerlink" title="1.作用："></a>1.作用：</h4><p>1.解决异常退出时资源释放的问题</p>
<p>2.解决用户忘记调用close方法而产生的资源泄露问题</p>
<p>包含一个错误处理和文件关闭功能。</p>
<h4 id="2-代码示例："><a href="#2-代码示例：" class="headerlink" title="2.代码示例："></a>2.代码示例：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(filepath,<span class="string">'wb'</span>) <span class="keyword">as</span> file:</span><br><span class="line">	file.write(<span class="string">"something"</span>)</span><br><span class="line"><span class="comment">#等价于</span></span><br><span class="line">file = open(filepath)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    file.write(<span class="string">"something"</span>,<span class="string">'wb'</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    file.close()</span><br></pre></td></tr></table></figure>
<h3 id="二-map-函数"><a href="#二-map-函数" class="headerlink" title="二.map()函数"></a>二.map()函数</h3><h4 id="1-作用：-1"><a href="#1-作用：-1" class="headerlink" title="1.作用："></a>1.作用：</h4><p>会根据提供的函数对指定序列做映射</p>
<p>参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">map(function, iterable,...)</span><br><span class="line"><span class="comment">#function --函数</span></span><br><span class="line"><span class="comment">#iterable -- 一个或多个序列</span></span><br></pre></td></tr></table></figure>
<p>第一个参数function以参数序列中的每一个元素调用function函数，返回包含每function函数返回值的新列表</p>
<h4 id="2-举例："><a href="#2-举例：" class="headerlink" title="2.举例："></a>2.举例：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">map(<span class="keyword">lambda</span> x: x**<span class="number">2</span>,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])  </span><br><span class="line"><span class="comment">#返回[1,4,9,16,25]</span></span><br><span class="line">map(<span class="keyword">lambda</span> x,y: x+y,[<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>],[<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>])</span><br><span class="line"><span class="comment">#返回[3,7,11]</span></span><br></pre></td></tr></table></figure>
<h3 id="三-list-方法"><a href="#三-list-方法" class="headerlink" title="三.list()方法"></a>三.list()方法</h3><h4 id="1-作用：-2"><a href="#1-作用：-2" class="headerlink" title="1.作用："></a>1.作用：</h4><p>把字符串、列表、元组、字典转化为列表</p>
<h4 id="2-举例：-1"><a href="#2-举例：-1" class="headerlink" title="2.举例："></a>2.举例：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1.列表转换成列表</span></span><br><span class="line">list([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.字符串转成列表</span></span><br><span class="line">list(<span class="string">'hello'</span>)</span><br><span class="line"><span class="comment">#得到['h','e','l','l','o']</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#3.元组转换成列表</span></span><br><span class="line">list((<span class="number">123</span>,<span class="string">'aaa'</span>,<span class="string">'abc'</span>))</span><br><span class="line"><span class="comment">#得到[123,'aaa','abc']</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#4.字典转换成列表</span></span><br><span class="line">list(&#123;<span class="string">'name'</span>:<span class="string">'wang'</span>,<span class="string">'age'</span>:<span class="number">18</span>&#125;)</span><br><span class="line"><span class="comment">#得到['name','age'] ,这里只打印了keys，没有values值.</span></span><br><span class="line">list(&#123;<span class="string">'name'</span>:<span class="string">'wang'</span>,<span class="string">'age'</span>:<span class="number">18</span>&#125;.values())</span><br><span class="line"><span class="comment">#得到的是['liang',18]</span></span><br></pre></td></tr></table></figure>
<h3 id="四-装饰器"><a href="#四-装饰器" class="headerlink" title="四.装饰器"></a>四.装饰器</h3><h4 id="1-作用：-3"><a href="#1-作用：-3" class="headerlink" title="1.作用："></a>1.作用：</h4><p>在一个函数内部定义另外一个函数,然后返回一个新的函数,即动态的给一个对象添加额外的职责。</p>
<p>传入的是f()</p>
<p>可以给装饰器传递参数。在原有的函数外面进行传参数的函数封装，def  fengzhuan(a,b):</p>
<p>然后在调用时，@fengzhuan(“start”,”end”)</p>
<h3 id="五-python的项目程序执行结构"><a href="#五-python的项目程序执行结构" class="headerlink" title="五.python的项目程序执行结构"></a>五.python的项目程序执行结构</h3><p>在测试模块.py文件中加入以下的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#注意，是双下划线</span></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#要执行的测试代码</span></span><br></pre></td></tr></table></figure>
<p>if <strong>name</strong> == ‘<strong>main</strong>‘的意思是：当.py文件被直接运行时，if <strong>name</strong> == ‘<strong>main</strong>‘之下的代码块将被运行；当.py文件以模块形式被导入时，if <strong>name</strong> == ‘<strong>main</strong>‘之下的代码块不被运行。</p>
<h3 id="六-python如何把汉字转成unicode编码"><a href="#六-python如何把汉字转成unicode编码" class="headerlink" title="六.python如何把汉字转成unicode编码"></a>六.python如何把汉字转成unicode编码</h3><p>字符-&gt;Unicode编码</p>
<p>Unicode编码字符串-&gt;汉字</p>
<p>str=Ustr.encode(“utf-8”).decode(“utf-8”)</p>
<p>或者 str=Ustr.decode(‘unicode_escape’)</p>
<p>其他编码到Unicode的转换  decode(str)</p>
<p>encode(str)  Unicode到其他编码的转换</p>
<h3 id="lambda表达式"><a href="#lambda表达式" class="headerlink" title="lambda表达式"></a>lambda表达式</h3><blockquote id="fn_参考">
<sup>参考</sup>. <a href="https://www.cnblogs.com/mxh1099/p/5386529.html" target="_blank" rel="noopener">https://www.cnblogs.com/mxh1099/p/5386529.html</a><a href="#reffn_参考" title="Jump back to footnote [参考] in the text."> &#8617;</a>
</blockquote>
<h3 id="python中的异常处理和try-except的用法"><a href="#python中的异常处理和try-except的用法" class="headerlink" title="python中的异常处理和try,except的用法"></a>python中的异常处理和try,except的用法</h3><p><a href="https://blog.csdn.net/u012080686/article/details/81940211" target="_blank" rel="noopener">https://blog.csdn.net/u012080686/article/details/81940211</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>requests库介绍</title>
    <url>/2020/05/11/python/requests%E5%BA%93%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h3 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h3><p>这个库是用于发送一个网络请求。</p>
<h3 id="requests-get-函数"><a href="#requests-get-函数" class="headerlink" title="requests.get()函数"></a>requests.get()函数</h3><h4 id="作用："><a href="#作用：" class="headerlink" title="作用："></a>作用：</h4><p>获取HTML网页的主要方法，对应于http的GET</p>
<blockquote id="fn_http的GET">
<sup>http的GET</sup>. 向特定的资源发出请求<a href="#reffn_http的GET" title="Jump back to footnote [http的GET] in the text."> &#8617;</a>
</blockquote>
<p><a href="https://blog.csdn.net/k_koris/article/details/82950654" target="_blank" rel="noopener">https://blog.csdn.net/k_koris/article/details/82950654</a></p>
<h3 id="requests-head-函数"><a href="#requests-head-函数" class="headerlink" title="requests.head()函数"></a>requests.head()函数</h3><h3 id="requests-post-函数"><a href="#requests-post-函数" class="headerlink" title="requests.post()函数"></a>requests.post()函数</h3><blockquote id="fn_http的POST">
<sup>http的POST</sup>. 向指定资源提交数据进行处理请求（如提交表单或者上传文件，数据被包含在请求体中。<a href="#reffn_http的POST" title="Jump back to footnote [http的POST] in the text."> &#8617;</a>
</blockquote>
<h3 id="requests-put-函数"><a href="#requests-put-函数" class="headerlink" title="requests.put()函数"></a>requests.put()函数</h3><h3 id="requests-patch-函数"><a href="#requests-patch-函数" class="headerlink" title="requests.patch()函数"></a>requests.patch()函数</h3><h3 id="requests-delete-函数"><a href="#requests-delete-函数" class="headerlink" title="requests.delete()函数"></a>requests.delete()函数</h3>]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>《如何让你爱的人爱上你》</title>
    <url>/2020/04/16/read%20note/%E3%80%8A%E5%A6%82%E4%BD%95%E8%AE%A9%E4%BD%A0%E7%88%B1%E7%9A%84%E4%BA%BA%E7%88%B1%E4%B8%8A%E4%BD%A0%E3%80%8B/</url>
    <content><![CDATA[<p>1.</p>
<p>——《从医学角度看人类性行为》先不管语义学，我们只探讨事实——任何微小的刺激都会导致爱情的发生。与意中人初次邂逅时你的一举一动都具有非常关键的作用。如果那件强力刺激事件以后你们之间发生了爱情，那么你就完全有权利把它叫做一见钟情，没有人会否定你的说法。</p>
<p>2.</p>
<p>因此，和你的意中人进行密集、强烈甚至带有威胁意味的目光接触，是让他（或她）爱上你的第一步。</p>
<p>3.</p>
<p>意中人聊天的时候，请大幅度增加你们的目光接触。寻找他（或她）的视神经，将你的视线死死锁住对方，制造那种你们已经相爱的暧昧气氛。</p>
<p>4.</p>
<p>电眼和意中人聊天的时候，凝视着他（或她）脸上最有魅力的地方，这样你的瞳孔就会自动放大，你的眼睛就变成了“电眼”。</p>
<p>5.</p>
<p>眷恋的眼神每次和意中人聊天的时候，将你的视线在他（或她）的脸上多停留一会儿——即使在谈话间的沉默时段也如此</p>
<p>6.</p>
<p>视线之旅和意中人交谈的时候，让你的视线来一场旅行——但开始的时候，仅限一些安全的区域。先用视线对他（或她）的面庞做个整体扫描，重点集中在对方的双眼。如果他（或她）看起来很享受你的视线抚摸的话，就朝下再走一小步，到达对方的脖颈、肩膀和上身。</p>
<p>7.</p>
<p>那就是让你的身体说话。首先请使用你的眼睛。看着她的双眼并延长你们之间的目光接触。她很可能会转移视线，你要对此做好心理准备。女性从小受到的教育就是，当发现男性盯着自己看时便垂下眼帘，但这并不意味着她对你不感兴趣。一个关于调情类型的科学分析告诉我们，如果一名女士在转移视线以后的45秒钟以内重新抬起眼睛的话，就说明她对你的关注持欢迎态度。</p>
<p>8.，</p>
<p>你的开场白越朴素、效果就越好，因为在恋情的初期，她最关注的并不是你的言谈。她在仔细观察你，她的大脑在高速运转，评估你的仪态举止。她明白：不管你说什么，其实都是用来接近她的借口。如果她对你有好感的话，这种行为她是可以接受的。</p>
<p>9.</p>
<p>尽管你不用背诵任何开场白，但从你双唇之间吐出来的第一句话却一定要慎之又慎。正如你对意中人最初的凝视应该取悦她的眼睛一样，你对她说的第一句话也要取悦她的耳朵。记住，你对意中人说的第一句话是迄今为止她借以评估你的最重要根据。如果你张口就是抱怨，在她的印象中，你就会成为一个牢骚满腹的人；如果你第一句就透着自负，她就会给你贴上自大狂的标签；但如果你的第一句话吸引了她，她就会觉得你是个魅力十足的人。</p>
<p>10</p>
<p>轻微的身体接触。在交谈和身体逐渐正面相对的过程中，会随之发生一种强有力的动作：轻微的身体接触。</p>
<p>11</p>
<p>遇见陌生的感兴趣的女生，就要想方设法去接触，去与其交流，经常出现在其面前，而不是扭扭捏捏的躲在一旁</p>
<p>当你倾听意中人的讲话时，要让一抹肯定而自信的微笑露出来</p>
]]></content>
      <categories>
        <category>read note</category>
      </categories>
  </entry>
  <entry>
    <title>《如何阅读一本书》</title>
    <url>/2020/04/16/read%20note/%E3%80%8A%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6%E3%80%8B/</url>
    <content><![CDATA[<ul>
<li>运用阅读以增加资讯和洞察力，和运用阅读以增加理解力是很容易区分开来的。</li>
</ul>
<p>（想想自己平时的状态，确实，无论是看csdn还是看新闻资讯，只是增加资讯，并没有真正在理解，）</p>
<ul>
<li><p>所谓吸收资讯，就只是知道某件事发生了，想要被启发，就要去理解，搞清楚这到底是怎么回事，为什么会发生，与其他的事实有什么关联，有什么类似的情况，同类的差异在哪里</p>
</li>
<li><p>除了知道作者所说的话之外，还要明白他的意思，懂得他为什么会这么说。</p>
</li>
<li><p>判断一本书是否具有可读性，（略读整本书，决定了值不值得花时间去认真读，或者将来</p>
</li>
</ul>
<p>有需要的话，应该归为哪一类）</p>
<p>读书名，读序，读目录，读摘要介绍，索引，也即把所有正文以外的部分全部阅读一遍。知道这本书大致是什么</p>
<ol>
<li>先看书名页，如果有序就先看序</li>
<li>仔细研究目录，弄清楚作者的结构思路</li>
<li>如果书中附有索引，也要看一下索引</li>
<li>若书中附有新皮，读一下出版者的介绍</li>
<li>在目录中挑几个和主题息息相关的章节读</li>
<li>最后，把书随意再翻一翻，弄个一两段读一读，有时，连续读几页，但不要太多</li>
</ol>
<ul>
<li>一般来说，就算是你想要仔细阅读的书，也要提前略读一下，这样才能从基本架构上找到一些想法</li>
<li>霍布斯认为人的生命是一种机器运动，趋利避害，自我保存一种人的本性。（如果这个作为机器学习的原动力的话，该怎么实现，用遗传算法，每次筛选出更为有力的后代，然后让其继续繁衍）</li>
<li>从书名中判断这本书是实用类的书还是理论类的书，给书籍进行分类，</li>
<li>分析阅读的第二个规则:使用一个单一的句子，或者最多几句话来叙述整本书的内容。;第三:将书中重要篇章列举出来说明如何按照顺序组成一个整体的框架。</li>
<li>两个心灵若想透过语言来进行交流，需要作者与读者都愿意才行。作者也是一样，无论他的写作技巧如何，如何读者没有呼应的技巧，则沟通不可能建立。就像在一座山的两头分头凿隧道，不论花多少力气，如果双方不是照着同样的工程原理进行计算，就永远不可能相遇。(爱情也是的，如果只是一方在努力，就永远不可能，相遇，同时，无论是身为作者还是读者，自己都得具备呼应的技巧，只能靠自己去磨练。)</li>
<li>找出重要的关键词，理解词在语境中的不同含义，与作者共通。是读一本书的需求所在。</li>
<li>真正读会一本书，要或赞同，反对的话，也要提出批评，给出反对的想法。有自己的思考。</li>
</ul>
]]></content>
      <categories>
        <category>read note</category>
      </categories>
  </entry>
  <entry>
    <title>《我们仨》</title>
    <url>/2020/04/16/read%20note/%E3%80%8A%E6%88%91%E4%BB%AC%E4%BB%A8%E3%80%8B/</url>
    <content><![CDATA[<p>1.</p>
<p>……他现在故意慢慢儿走，让我一程一程送，尽量多聚聚，把一个小梦拉成一个万里长梦</p>
<p>   这我愿意。送一程，说一声再见，又能见到一面。离别拉得越长，是增加痛苦还是减少痛苦呢？我算不清。但是我陪他走得愈远，愈怕从此不见。</p>
<p>​     至此无言，我在世上多活一天，就要多陪你一天。</p>
<p>2.</p>
<p>  我急着往上爬，想寻找河里的船。昏暗中，能看到河的对岸也是山，河里飘荡着一只小船，一会儿给山石挡住了，又看不见了。</p>
<p>读到这里我才明白，这里钱钟书先生歇息的船不是真正的船，而是一种暗示，暗示着钱先生即将离开人世，杨绛和钱瑗对先生的探望，也不是去船上，而是去医院。回过头来看前面提到的客栈，也许就是人世吧。</p>
<p>（一） 顺着驿道走，没有路的地方，别走</p>
<p>（二） 看不见的地方，别去。</p>
<p>（三） 不知道的事，别问。</p>
<p>再想想前面，杨绛想为钱钟书请假，不去船上“开会”，是希望命运能让他们一家多团圆一会。甚至杨绛想代替钱钟书去。但觉得比直接写要更触动人心，不舍与担忧全写在了字里行间。</p>
]]></content>
      <categories>
        <category>read note</category>
      </categories>
  </entry>
  <entry>
    <title>《看见》</title>
    <url>/2020/04/16/read%20note/%E3%80%8A%E7%9C%8B%E8%A7%81%E3%80%8B/</url>
    <content><![CDATA[<p>1.“保持对不同论述的警惕，才能保持自己的独立性。探寻就是要不断相信、不断怀疑、不断幻灭、不断摧毁、不断重建，为的只是避免成为偏见的附庸。或者说，煽动各种偏见的互殴，从而取得平衡，这是我所理解的‘探寻’。</p>
<p>2.但纠正偏见的最好方式就是让意见市场流通起来，让意见与意见较量，用理性去唤起理性。</p>
<p>3.，有一句“念起即觉，觉即不随”，人是不能清空自己的情绪判断的，但要有个戒备，念头起来要能觉察，觉察之后你就不会跟随它。</p>
<p>（         要学会关注自己的情绪，）</p>
<p>4.如果你用悲情贿赂过读者，你也一定用悲情取悦过自己，我猜想柴静老师做节目、写博客时，常是热泪盈眶的。得诚实地说，悲情、苦大仇深的心理基础是自我感动。自我感动取之便捷，又容易上瘾。对它的自觉抵制，便尤为可贵：每一条细微的新闻背后，都隐藏一条冗长的逻辑链，在我们这，这些逻辑链绝大多数是同一朝向，正是因为这不能言说又不言而喻的秘密，我们需要提醒自己：绝不能走到这条逻辑链的半山腰就号啕大哭。”</p>
<p>5.是的，生命往往要以其他生命为代价，但那是出于生存。只有我们人类，是出于娱乐。</p>
<p>6.每个人都有自己的文化密码，在一定年纪的时候，自然会启动。</p>
<p>7.为什么得病，就是老想不该想的事，现在为什么快乐，就是不想那些事，只想怎么把该做的事情做好，这一点可能更重要。</p>
<p>（关注当下的事情，这点很重要，不要为哪些本就虚无缥缈的东西担心，）</p>
]]></content>
      <categories>
        <category>read note</category>
      </categories>
  </entry>
  <entry>
    <title>&lt;&lt;贫穷的本质&gt;&gt;读后感</title>
    <url>/2020/06/24/read%20note/%E3%80%8A%E8%B4%AB%E7%A9%B7%E7%9A%84%E6%9C%AC%E8%B4%A8%E3%80%8B/</url>
    <content><![CDATA[<blockquote>
<p>Poor countries are poor because they are hot, infertile, malaria infested, often landlocked; this makes it hard for them to be productive without an initial large investment to help them deal with these endemic problems. But they cannot pay for the investments precisely because they are poor—they are in what economists call a“poverty trap.” Until something is done about these problems, neither free markets nor democracy will do very much for them. This is why foreign aid is key: It can kick-start a virtuous cycle by helping poor countries invest in these critical areas and make them more productive. The resulting higher incomes will generate further investments; the beneficial spiral will continue. </p>
</blockquote>
<p><strong>穷人困境：</strong>穷人只所以穷，就是因为他们所在的国家贫瘠、疾病流行，还经常闭关锁国，导致他们如果没有一笔足够大的初始投资去克服这些问题，就没办法使得自己变得有效益。但他们大多数是承担不起这个投资的，因为他们穷，这样恶性循环，积贫积弱。</p>
<p>对于这种情况，由国外援助来解决初始资金的投资问题，敲开良性循环的口子。</p>
<blockquote>
<p>The Elusive Quest for Growth</p>
</blockquote>
<p>在迷雾中挣扎成长。</p>
<blockquote>
<p>Both argue that aid does more bad than good: It prevents people from searching for their own solutions, while corrupting and undermining local institutions and creating a self-perpetuating lobby of aid agencies. The best bet for poor countries is to rely on one simple idea: When markets are free and the incentives are right, people can find ways to solve their problems. They do not need handouts, from foreigners or from their own governments.</p>
</blockquote>
<p>援助所带来的坏处要大于其好的初衷：它会阻碍穷人去寻找自己的解决方案，同时腐化当地机构，削弱当地机构的威信力和执行力，使得一些援助机构形同虚设。</p>
<p><strong>对于穷国的最好的办法是，提供自由的市场和恰当的奖励机制，让人们自己去找到解决问题的方法，避免接收外国人的援助或政府的施舍。</strong></p>
<blockquote>
<p> The point is simple: Talking about the problems of the world without talking about some accessible solutions is the way to paralysis rather than progress. </p>
</blockquote>
<p>道理很简单：只谈论问题却不谈论问题的解决办法，这是止步不前而不是进步。</p>
<blockquote>
<p>童年时期适度的营养摄入具有深远意义。营养不良的儿童的个子更有可能长不高、学习成绩更差、生下来的孩子更瘦小。</p>
<p>在菲律宾，一项研究表明，那些既要挣基本工资又要挣计件工资的，他们在挣计件工资时要多吃25%的食物。在挣计件工资时，工作能力十分重要，因为干的越多，挣得钱也就越多。</p>
</blockquote>
<p>让劳动者按照自己付出的努力和最后的结果来评估这个人的所得，才能调动其的积极性，让其自发地创造性的去完成任务，提高效率。</p>
<blockquote>
<p>实际上，存在着一种“心理沉没成本”—-人们更有可能会利用他们为之支付很多钱的东西。此外，人们可能会根据价格来判断质量，恰恰是由于某物品是廉价的，热们便有可能认为它没有价值。</p>
<p>“时间矛盾”概念，我们对当前与未来的看法是截然不同的，当前的我们是冲动的，很大程度上由感性与即时欲望支配；花一点点时间或放弃一点点舒适感都是我们当前需要经历的，较之在没有迫切感的情况下去想这些事，当前的这种感觉更令人不愉快。但当我们为将来而计划时，那种渴望的快感似乎就不那么重要了。</p>
</blockquote>
<p>终于明白为啥构思计划时感觉很简单，真正去实施时却困难重重了，原来要克服一点点的即时欲望，要有迫切感。</p>
<blockquote>
<p>诱惑是生理需求的(性、糖、脂肪类食品、烟等)的表现。在这种情况下，富人更容易满足“受到诱惑的自己”。在决定是否存钱时，他们认为，任何为将来存的钱都会用于实现长期目标。因此，如果糖和茶是一种诱惑物的原型，那么富人不太可能会有所困扰—-他们并不是不会受到诱惑，而是无须担心多喝一杯茶就会花掉自己辛苦赚来的钱。</p>
</blockquote>
<p>正如自己现在的处境，自己对于时间上想要做的事情是很渴求的，但也经不住玩游戏、看视频的诱惑，但是有钱人的家里是不会让自己的孩子去做事情，不占用孩子自己的时间，因此他们有大把的时间用来试错，即使一天中懈怠了一上午或一下午，他们仍然有剩下的时间去充足地做自己想做的事情，而我自己则不行，一旦懈怠一会儿，就会导致一天下来，什么自己的事情也做不了，毕竟一天中自己有将近五个小时是被占用帮父母做事的状态。</p>
<blockquote>
<p>一点儿希望、保障以及安慰可以成为一种强大的激励措施。我们都很容易过上一种安稳的生活，制定一些我们有信心实现的目标(一台新沙发、50英寸的平板电视、第二辆汽车等)，寻求一些机构(储蓄账户、养老金计划、住房贷款等)的帮助。然后，像维多利亚时代的人那样，依据动力与规则行事。…….当你想要的一切看上去都很遥远时，你很难感受到动力。将目标设置得更近一些，或许是穷人实现这些目标的有效方式。</p>
</blockquote>
<p>将目标设置得近一些，寻求外在力量的监督和帮助。自己的话，想要发表论文的话，最近的目标就应该是把一些外围的基础知识给弄扎实了，然后潜心看几篇论文，把论文给弄懂。</p>
<blockquote>
<p>想要摆脱贫困，就要学会对长期目标进行思考，并习惯为此做出一些短期的牺牲。</p>
</blockquote>
<p>长期目标？？？！！！！ 短期享乐！！！？？？？</p>
<blockquote>
<p>自我控制就像是一块肌肉，我们用这块肌肉时就会感到劳累。……此外，穷人还生活在巨大的压力之下，而由压力产生的皮质醇会使我们做出更冲动的举动，因此，穷人只能以更少的资源完成更艰苦的任务。</p>
</blockquote>
<p>原来如此，自己每次都在本来可以学习的时间段里，冲动性地去玩游戏或者刷视频，就是潜意识里想要去缓解这种不自觉的压力(强迫自己去学习，不学就怎么样，怎么样的压力)。</p>
<p>因此，解决办法就是不要给自己施压，放轻松地去做，简单一些，凭借着一种最为直接的想法，我就是想学习补充自己，了解自己的动力，而不是强迫自己的压力。</p>
<blockquote>
<p>这就是穷人和他们所做生意的矛盾之处，他们精力充沛，拥有丰富的资源，而且努力地做着白手起家的生意。但他们的大部分精力都花在了很小的生意上，而且他们同周围很多其他人都在做着相同的生意。结果，他们失去了过上一种富裕生活的机会。孟买那些富有创意的拾沙女们，发现了利用现成资源赚钱的机会：一些自由的时间和海滩上的沙子。但商业精英没有指出的是，尽管她们有这样的聪明才智，但这种生意几乎赚不了几个钱。</p>
</blockquote>
<p>也许，这就是菜市场有很多个卖菜的，但是很少有听说靠卖菜的起家的事迹。</p>
<blockquote>
<p>确实有超过10亿人在经营着自己的农场或公司，但他们中的大多数人这样做是因为别无选择。他们只想生存下去。因为他们没有才华、技能或是必要的风险承受能力。小额信贷及其他有助于小企业发展的方式，仍然在穷人的生活中扮演着重要角色。因为这些小企业要存活下去。或许，在可预见的未来，这是很多穷人得以生存的唯一方式。但是，如果我们认为他们能以此铺出一条逃脱贫穷的路，那么我们简直是在自欺欺人。</p>
</blockquote>
<p>如果不具有一技之长，那么做着同样的活，又凭什么你能致富脱贫，而我不能呢？</p>
]]></content>
      <categories>
        <category>read note</category>
      </categories>
  </entry>
  <entry>
    <title>电影</title>
    <url>/2020/04/16/read%20note/%E7%94%B5%E5%BD%B1/</url>
    <content><![CDATA[<h3 id="《About-time》"><a href="#《About-time》" class="headerlink" title="《About time》"></a>《About time》</h3><p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/《About Time》.png" alt=""></p>
<p>—We’re all traveling through time together every day of our lives. All we can do is do our best to relish this remarkable ride.</p>
<p>—Big lesson number one, all the time travel in the world can’t make someone love you.</p>
<p>— We are all quite similar in the end. We all get old and the same tales too many times. But try marry someone kind.</p>
<p>穿越能力，多么让人羡慕的能力。  </p>
<p>如果拥有穿越能力，很多事情就不会在第一次遇到时显得茫然无措，</p>
<p>如果拥有穿越能力，可以像Tim一样，穿越回过去，坦然向喜欢的女生表白。</p>
<p>如果拥有穿越能力，想穿越回高中，希望自己能对陪读的母亲好一些，思维开阔一些；</p>
<p>如果拥有穿越能力，想穿越回大一，劝解自己不要陷入谜一样的漩涡中，多做一些事情，努力把自身提高。</p>
<p>如果拥有穿越能力，希望像Tim一样，能在一些小问题发生时，立刻去纠正错误。</p>
<p>如果拥有穿越能力，希望回到小时候，去看望自己的爷爷奶奶。</p>
<p>可惜只是假如。</p>
<p>正因为是过去一路上的磕磕绊绊，失去时的懊悔，犯错后的反思，才有了现在的我。</p>
<h3 id="《蜘蛛侠-英雄远征》"><a href="#《蜘蛛侠-英雄远征》" class="headerlink" title="《蜘蛛侠-英雄远征》"></a>《蜘蛛侠-英雄远征》</h3><p>不知道为啥，感觉这部电影比《复联4》要更好看，更真实一些，给我的感动更多一些。</p>
<p>从剧情上说，这部电影还是很可以的，神秘客一开始出来的时候，我以为他是正义的一方，复联方又会新增一名英雄，在他和彼得合伙解决四大元素之后，我一度以为电影已经结束了，但是当彼得把托尼.史塔克的眼镜给神秘客之后，故事一下就反转了，原来神秘客（昆汀.贝克）才是反派，之前的都是全息影像。然后到彼得帕克去阻止昆汀.贝克时，有一幕是神盾局局长向昆汀.贝克开枪，阻止了昆汀.贝克对蜘蛛侠的攻击，我也一度以为这结束了，可没想到这还是贝克耍的全息影像的把戏。不得不说，还是挺精彩的。加入了全息影像这个新点，我有时都难以判断此刻所看到的究竟是不是真的，会不会突然反转，这个算是这部电影比较新颖的地方。</p>
<p>与其他超级英雄相比，蜘蛛侠给我的是一种更为真实的感觉，脱去蜘蛛侠的外衣，他就是普普通通的一名中学生，有着这个阶段特有的烦恼，他所经历的，也正是我经历过的，他的困惑，也同样困惑着我，如何追到喜欢的女生，如何在现实生活与自己的世界里正确地切换自己的身份，如何在别人都怀疑自己的时候，仍旧保持着这份成为英雄的初心，默默坚守着。他也希望自己能不是超级英雄，而是一个普普通通的少年。真的很真实，不像美队那样有对正义贯彻到底并从大局出发的冷静，他只是一个少年。也有困惑和犯错的地方，也有失败和气馁，也正是如此，他的每个抉择都如此真实。</p>
<p>我觉得，托尼.史塔克是希望蜘蛛侠能成为下一个钢铁侠，替他完成未竟的事业。</p>
<h3 id="《我不是药神》"><a href="#《我不是药神》" class="headerlink" title="《我不是药神》"></a>《我不是药神》</h3><p>一开始以为是一部喜剧，可是看到后来为电影所反映的深刻的社会问题而震撼。</p>
<ul>
<li>程勇的前后转变是整部剧的关键，一开始程勇贩药救人是为生活所迫，想要挣钱，后来吕受益的死，给程勇带来了转变，贩药是为了治病救人，甚至不惜赔本卖给病友。让他赢得了所有人的尊重。</li>
<li>天价药问题揭露的很直接，把那些唯利是图，不顾病人死活的所谓正规药店的本性赤裸裸的呈现出来。</li>
<li>一样的疗效，真的药，病人吃不起，“假”的药，病人时时刻刻提防着吃。什么是真，什么又是假？在冷冰冰的法律面前，界限很明确，但是，最有发言权的，不应该是那一个个鲜活的生命吗？如果连百姓的命都保不住，那又谈什么法律是维护人民的利益了呢？</li>
<li>影片中黄毛做错了什么呢？只不过想要活命罢了，只不过想和程勇一起拯救更多的生命，只不过想回去再看看父母。但这样一个鲜活的生命，就这样在法律的强压下，悄然逝去。</li>
<li>人们所向往的美好生活总会到来的，虽然这个过程会很艰辛，会有很多的牺牲。</li>
<li>最后病友为程勇送行，行“摘罩礼”的场景很壮观。</li>
</ul>
]]></content>
      <categories>
        <category>read note</category>
      </categories>
  </entry>
  <entry>
    <title>电视剧</title>
    <url>/2020/04/16/read%20note/%E7%94%B5%E8%A7%86%E5%89%A7/</url>
    <content><![CDATA[<h3 id="《欢乐颂》"><a href="#《欢乐颂》" class="headerlink" title="《欢乐颂》"></a>《欢乐颂》</h3><p><strong>人物：</strong></p>
<p>何安迪，关雎尔，邱莹莹，樊胜美，曲绡绡，魏渭，王柏川，赵启平（赵医生），曲连杰（绡绡的哥哥），包亦凡（包总），魏国强（安迪的父亲），谭总（安迪的第一个朋友），林师兄（喜欢关雎尔），应勤（邱莹莹的老乡，喜欢邱莹莹），白主管（渣男），小明（安迪的弟弟），</p>
<p>谢童（关雎尔的男朋友）</p>
<p><strong>关键词：</strong></p>
<p>欢乐颂公寓，22楼，</p>
<p><strong>感悟：</strong></p>
<p>1%感觉前期做的还可以。到了最后，剧情上最后结尾处理的不好，让人感觉还有下一集的感觉，不像是一部正常的电视剧结尾</p>
<p>第42集结尾的剧情强行推向一个看似平和的场景，曲绡绡和赵医生之间明明很明显已经没有牵挂了，而且从赵医生对曲绡绡的回避可以看出，赵医生并不喜欢曲绡绡，但是结尾强行把他们两写和，而且赵医生都拒绝这么明显了，不知道曲绡绡有哪里来的勇气继续把赵医生的这种行为当成是羞涩。</p>
<p>安迪和魏胃的分手也有点让人摸不着头脑，都在一起经历过这么多，彼此也已经有不少默契了，结果安迪父亲的事一被点燃，两人分手后，安迪仔象征性的难过，无论魏胃再怎么说，安迪都一脸漠然的回应，有时甚至连回应都不想回应。转折太过于突然。</p>
<p>22楼的4个女生都关系好的让人无法相信。</p>
<p>2%相较而言，感觉第一部已经算是好的了。第二部各种人设都已经崩溃了，安迪之前还和魏渭说再也不会结婚，结果第二部在包亦凡的软磨硬泡下，竟然和包亦凡在一起了。</p>
<p>3%生活的很多事情，比如爱情，自己喜欢的，兴趣与爱好，不是任务，而是发自内心的想去做。</p>
]]></content>
      <categories>
        <category>read note</category>
      </categories>
  </entry>
  <entry>
    <title>番剧</title>
    <url>/2020/04/16/read%20note/%E7%95%AA%E5%89%A7/</url>
    <content><![CDATA[<h3 id="《英雄时代》"><a href="#《英雄时代》" class="headerlink" title="《英雄时代》"></a>《英雄时代》</h3><p><strong>亮点：</strong></p>
<p>第十五集   光芒下降之时  （艾吉与迪安奈拉相遇）    </p>
<p><a href="https://www.bilibili.com/bangumi/play/ep23254" target="_blank" rel="noopener">https://www.bilibili.com/bangumi/play/ep23254</a></p>
<p>第二十六集   AGE(艾吉与迪安奈拉再次相遇)</p>
<p><a href="https://www.bilibili.com/bangumi/play/ep23265?from=search&amp;seid=2747196282775458028" target="_blank" rel="noopener">https://www.bilibili.com/bangumi/play/ep23265?from=search&amp;seid=2747196282775458028</a></p>
<p>OP和ED都是准神曲</p>
<p><strong>影评：</strong></p>
<p>感觉有点冷门，不过确实觉得这部番整体还是不错的，立意很高，讨论的问题也很深刻，黄金族留给白银族，黑铁族和英雄族的契约，应该是指引他们走向自由的道路。迪安奈拉公主真的是神一样的存在，代表着黑铁一族的未来的方向，身上所肩负的重担可想而知，艾吉的存在让公主在指引他人时不再感到孤单，因为公主相信，她的道路，由艾吉所指引着，她相信艾吉，艾吉也相信她，彼此的信赖与爱，让希望的未来成为了可能。这部剧重点到是不在于主角的成长，而是各个种族之间逐渐理解的过程。还有一点，OP和ED真的很应景，很符合这部剧的剧情</p>
<h3 id="《钢之炼金术士》"><a href="#《钢之炼金术士》" class="headerlink" title="《钢之炼金术士》"></a>《钢之炼金术士》</h3><p>这部动漫应该是我看过的最好的动漫了。</p>
<p>剧情紧凑不拖拉，人物设计的很有个性，除了修·塔克这个可恨的人渣（把女儿妮娜和宠物炼成了合成兽）以外，其他角色没有绝对的坏，各自都只是按照自己的原则生活战斗。</p>
<p>片头曲和片尾曲是一大亮点，真的很好听，同时在故事里场景播放的背景音乐也很应景很煽情，尤其是最后艾德爸在艾德妈的坟前安然幸福的死去，然后温莉的奶奶遇到她时，突然想起的bgm，《rain》，差点哭了出来。</p>
<p>罗伊·马斯坦古上校在为休斯报仇时的决心，真的让我感动的哭了，最后和恩维对决，那不得不放弃复仇的心。人之所以为人，就是我们会控制自己的感情，不意气用事，也会为了自己所爱之人去放弃一些事情，人会在他人的影响下发生改变和成长，</p>
<p>期待二刷。</p>
<h3 id="《苍穹的法芙娜》"><a href="#《苍穹的法芙娜》" class="headerlink" title="《苍穹的法芙娜》"></a>《苍穹的法芙娜》</h3><p>有一定的内涵，但总感觉第二季的结尾有点强行为了伏笔而伏笔。</p>
<p>有很多的元素包含在其中，反战、沟通、文化、存在与虚无的讨论、责任与担当、友情和亲情、人性的讨论等等。</p>
<p>卡农的离开，为了龙宫岛的未来，本来最不擅长做出选择的她要在无数个可能的未来中开辟出一条能保龙宫岛安全的道路，因此，她一直在未来中战斗，即使牺牲自也在所不辞。</p>
<p>期待再次刷。</p>
]]></content>
      <categories>
        <category>read note</category>
      </categories>
  </entry>
  <entry>
    <title>AA常用的好用工具</title>
    <url>/2020/07/30/tools/AA%E5%B8%B8%E7%94%A8%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h3 id="编辑用的工具"><a href="#编辑用的工具" class="headerlink" title="编辑用的工具"></a>编辑用的工具</h3><div class="table-container">
<table>
<thead>
<tr>
<th>用途</th>
<th>工具</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>论文编辑软件</td>
<td>TexStudio</td>
<td></td>
</tr>
<tr>
<td>剪贴板500条存留</td>
<td>Ditto</td>
<td>可以保留剪贴板的500条历史记录，方便回溯查找</td>
</tr>
<tr>
<td>让界面半透明工具</td>
<td>class2k</td>
<td>在进行文档编辑时特别方便</td>
</tr>
<tr>
<td>Markdown公式识别软件</td>
<td>Mathpix</td>
<td>对于学生党一个月只有100条</td>
</tr>
<tr>
<td>画流程图</td>
<td>Processon</td>
<td></td>
</tr>
<tr>
<td>可以保存网页的内容</td>
<td>Web-clipper</td>
<td>谷歌的插件，方便写博客做笔记时参考其他人的内容，不用自己手动一个个敲。</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>网站设计和创意元素设计</td>
<td>No Design</td>
<td><a href="https://nodesign.dev/" target="_blank" rel="noopener">https://nodesign.dev/</a></td>
</tr>
<tr>
<td>简历模板软件</td>
<td>Good Resume</td>
<td><a href="https://good-resume.com/" target="_blank" rel="noopener">https://good-resume.com/</a></td>
</tr>
<tr>
<td>监视某个网站是否更新的Chrome插件</td>
<td>Page Monitor</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="其他工具"><a href="#其他工具" class="headerlink" title="其他工具"></a>其他工具</h3><div class="table-container">
<table>
<thead>
<tr>
<th>用途</th>
<th>工具</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>后端去测试前端的调试工具</td>
<td>Postman</td>
<td></td>
</tr>
<tr>
<td>刷机工具</td>
<td>奇兔刷机、小米手机助手</td>
<td>奇兔刷机每天有刷机次数限制</td>
</tr>
<tr>
<td>录像工具</td>
<td>KK录像机</td>
<td>KK录像机只能录流畅的，高清的要钱</td>
</tr>
<tr>
<td>磁盘清理工具</td>
<td>TreeSize</td>
<td>可以显示C和D盘每个文件夹的大小</td>
</tr>
<tr>
<td>视频播放下载工具</td>
<td>Zyplayer</td>
<td><a href="http://zyplayer.fun/" target="_blank" rel="noopener">http://zyplayer.fun/</a></td>
</tr>
<tr>
<td>桌面整理</td>
<td>腾讯桌面助手</td>
<td>对桌面的文件进行分区，还可以把常用的文件夹直接展示在桌面上，方便打开</td>
</tr>
<tr>
<td>多目录跳转</td>
<td>Q-dir</td>
<td>可以同时看到不同的文件夹的目录，这样方便操作</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>Anaconda一些常用操作</title>
    <url>/2020/05/11/tools/Anaconda%E6%93%8D%E4%BD%9C%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h3 id="一-Anaconda的虚拟环境操作"><a href="#一-Anaconda的虚拟环境操作" class="headerlink" title="一.Anaconda的虚拟环境操作"></a>一.Anaconda的虚拟环境操作</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>命令</th>
</tr>
</thead>
<tbody>
<tr>
<td>建立Anaconda的虚拟环境</td>
<td>1.以管理员身份运行Anaconda Prompt<br />2. conda create —name 虚拟环境名 python=x.x</td>
</tr>
<tr>
<td>激活虚拟环境</td>
<td>activate 虚拟环境名</td>
</tr>
<tr>
<td>退出虚拟环境</td>
<td>deactivate</td>
</tr>
<tr>
<td>查找虚拟环境</td>
<td>conda info -e 或conda list —env</td>
</tr>
<tr>
<td>删除虚拟环境</td>
<td>conda remove -n 环境名  -all</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>安装包</td>
<td>conda install 包名或者pip install 包名</td>
</tr>
</tbody>
</table>
</div>
<h3 id="二-Jupyter-notebook环境操作"><a href="#二-Jupyter-notebook环境操作" class="headerlink" title="二.Jupyter notebook环境操作"></a>二.Jupyter notebook环境操作</h3><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>命令</th>
</tr>
</thead>
<tbody>
<tr>
<td>选择环境</td>
<td>1.安装ipykernel： <code>conda install ipykernel</code> 如果不可行就使用<code>pip install ipykernel</code> <br /> 2.激活虚拟环境 将环境写入Notebook的kernel中： <code>python -m ipykernel install --user --name 环境名称 --display-name &quot;Python (环境名称)&quot;</code> <br />3.打开Jupyter notebook，新建Python文件，这时候你就能看见你的创建的环境</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="三-参考"><a href="#三-参考" class="headerlink" title="三.参考"></a>三.参考</h3><p><a href="https://www.cnblogs.com/xxmmqg/p/12766319.html" target="_blank" rel="noopener">https://www.cnblogs.com/xxmmqg/p/12766319.html</a></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>jupyter Notebook的使用</title>
    <url>/2020/04/18/tools/JupyterNotebook%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h3 id="一-其他"><a href="#一-其他" class="headerlink" title="一.其他"></a>一.其他</h3><p>对于一个单元格的运行，ctrl+enter，光标不下移动而出结果；而shift+enter，则光标移动到下一个新的单元格</p>
<h3 id="二-使用说明"><a href="#二-使用说明" class="headerlink" title="二.使用说明"></a>二.使用说明</h3><p>1.如何使jupyter notebook打开的目录是干净的</p>
<p>修改c\Users\28708.jupter\里的.py文件，修改保存路径</p>
<p>c.NotebookApp.notebook_dir=‘需要的路径’</p>
<p>同时，每次打开，必须从cmd中输入jupyter notebook，打开，才是运行.py配置后的结果</p>
<p>2.笔记本的基本操作</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/jupyter1.png" alt="jupyter1"></p>
<p>3.Conda类目下对conda环境和包进行一系列操作</p>
<p><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/jupyter2.png" alt="jupyter2"></p>
<h3 id="三-参考"><a href="#三-参考" class="headerlink" title="三.参考"></a>三.参考</h3><p><a href="https://blog.csdn.net/xiewenrui1996/article/details/90301335" target="_blank" rel="noopener">https://blog.csdn.net/xiewenrui1996/article/details/90301335</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/33207896" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33207896</a></p>
<p><a href="https://www.jianshu.com/p/91365f343585/" target="_blank" rel="noopener">https://www.jianshu.com/p/91365f343585/</a></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>Markdown编辑语法</title>
    <url>/2020/06/05/tools/Markdown%E7%BC%96%E8%BE%91%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<p>github上图床的图片地址：<a href="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/图片名.jpg" target="_blank" rel="noopener">https://raw.githubusercontent.com/liangwg/FigureBed/master/img/图片名.jpg</a></p>
<p>[TOC]</p>
<h3 id="Typora的快捷键"><a href="#Typora的快捷键" class="headerlink" title="Typora的快捷键"></a>Typora的快捷键</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Wanted</th>
<th>How</th>
</tr>
</thead>
<tbody>
<tr>
<td>插入数学公式</td>
<td>Ctrl + Shift + M.</td>
</tr>
<tr>
<td>插入表格</td>
<td>Ctrl+T.</td>
</tr>
</tbody>
</table>
</div>
<h3 id="一些操作"><a href="#一些操作" class="headerlink" title="一些操作"></a>一些操作</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Want to do</th>
<th>How to do</th>
</tr>
</thead>
<tbody>
<tr>
<td>想要显示上下标H<sub>2</sub>O<sup>T</sup></td>
<td>下标：H\<sub>2\</sub><br />上标：O\<sup>T\</sup></td>
</tr>
<tr>
<td>想要修改github图床上的图片的大小</td>
<td>在采用Picgo上传图片之后，得到的url地址，把其放到如下中<br />\<img src="url" width="300" height="200" align=center /></td>
</tr>
<tr>
<td>如何改变文字的颜色</td>
<td>\<font color='red'> text \</font></td>
</tr>
<tr>
<td>公式中插入分段函数</td>
<td>见下</td>
</tr>
<tr>
<td>在公式中实现换行</td>
<td>在要换行的末尾加入\\\即可</td>
</tr>
<tr>
<td>让&Sigma;的上下界放在上面和下面</td>
<td></td>
</tr>
<tr>
<td>插入空格</td>
<td>\&nbsp;</td>
</tr>
<tr>
<td>在公式中插入空格</td>
<td>用~即可，一个~就是一个空格。</td>
</tr>
<tr>
<td>在公式中插入标号</td>
<td>用\\tag{1}，表示标号1</td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="实现内容折叠"><a href="#实现内容折叠" class="headerlink" title="实现内容折叠"></a>实现内容折叠</h3><p><details>   <summary>展开查看</summary>
    你好   </br>
我很好，谢谢
   </details></p>
<h3 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h3><p><strong>普通矩阵，不带括号：</strong></p>
<p>$\begin{matrix} a&amp;b&amp;c\\d&amp;e&amp;f \end{matrix}$</p>
<h3 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h3><div class="table-container">
<table>
<thead>
<tr>
<th>要插入的符号</th>
<th>词（$A$）下面是A的值或者是&A;</th>
</tr>
</thead>
<tbody>
<tr>
<td>$\sigma$</td>
<td>\sigma</td>
</tr>
<tr>
<td>拉姆塔$\lambda$</td>
<td>\lambda</td>
</tr>
<tr>
<td>/fai/$\varphi$</td>
<td>\varphi</td>
</tr>
<tr>
<td>/mu/$\mu$</td>
<td>\mu</td>
</tr>
<tr>
<td>$\tau$</td>
<td>\tau</td>
</tr>
<tr>
<td>婆si $\psi$</td>
<td>\psi</td>
</tr>
<tr>
<td>/fai/$\phi$</td>
<td>\phi</td>
</tr>
<tr>
<td>伊普西隆$\varepsilon$</td>
<td>\varepsilon</td>
</tr>
<tr>
<td>圆周率$\pi$</td>
<td>\pi</td>
</tr>
<tr>
<td>$\Sigma$</td>
<td>\Sigma</td>
</tr>
</tbody>
</table>
</div>
<h3 id="字体转换"><a href="#字体转换" class="headerlink" title="字体转换"></a>字体转换</h3><p> 使用&A;时，这里的A只能是原始的限定词，比如A=theta可以显示&theta;，但是A=theta_t就不能显示</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>要插入的符号</th>
<th>词（$A$）下面是A的值或者是&A;</th>
</tr>
</thead>
<tbody>
<tr>
<td>美术字$\mathcal{A,D}$</td>
<td>\mathcal{A,D}</td>
</tr>
<tr>
<td>空心R$\R$</td>
<td>\R</td>
</tr>
<tr>
<td>黑板粗体$\Bbb{E}$</td>
<td>\Bbb{E}</td>
</tr>
<tr>
<td>黑体表示向量1$\boldsymbol{X}$</td>
<td>\boldsymbol{X}</td>
</tr>
<tr>
<td>黑体表示向量2$\bold{X}$</td>
<td>\bold{X}</td>
</tr>
</tbody>
</table>
</div>
<h3 id="数学运算符号"><a href="#数学运算符号" class="headerlink" title="数学运算符号"></a>数学运算符号</h3><div class="table-container">
<table>
<thead>
<tr>
<th>要插入的符号</th>
<th>词（$A$）下面是A的值或者是&A;</th>
</tr>
</thead>
<tbody>
<tr>
<td>乘积符号$\times$</td>
<td>\times</td>
</tr>
<tr>
<td>正负号$\plusmn$</td>
<td>\plusmn</td>
</tr>
<tr>
<td>圆点乘积$\cdot$</td>
<td>\cdot</td>
</tr>
<tr>
<td>$\nabla$</td>
<td>\nabla</td>
</tr>
<tr>
<td>偏微分$\part$</td>
<td>\part</td>
</tr>
<tr>
<td>求和符号$\sum_{n=1}^{N}$</td>
<td>\sum_{n=1}^{N}</td>
</tr>
<tr>
<td>累乘符号$\prod^9_{n=1}$</td>
<td>\prod^9_{n=1}</td>
</tr>
<tr>
<td>累乘符号$\displaystyle\prod^9_{n=1}$</td>
<td>\displaystyle\prod^9_{n=1}</td>
</tr>
<tr>
<td>普通矩阵不带括号$\begin{matrix} a&amp;b&amp;c\\d&amp;e&amp;f \end{matrix}$</td>
<td>\begin{matrix} a&amp;b&amp;c\\\d&amp;e&amp;f \end{matrix}</td>
</tr>
<tr>
<td>带中括号的矩阵$\left[\begin{matrix} a&amp;b&amp;c\\d&amp;e&amp;f \end{matrix}\right]$</td>
<td>\left[\begin{matrix} a&amp;b&amp;c\\\d&amp;e&amp;f \end{matrix}\right]</td>
</tr>
<tr>
<td>矩阵中间有省略号(将矩阵对应位置的元素换成相应的省略号即可)</td>
<td></td>
</tr>
<tr>
<td>无限大$\infin$</td>
<td>\infin</td>
</tr>
<tr>
<td>角度符号$\ang$</td>
<td>\ang</td>
</tr>
<tr>
<td>积分符号$\int$</td>
<td>\int</td>
</tr>
<tr>
<td>$\forall$</td>
<td>\forall</td>
</tr>
<tr>
<td>大于；大于等于；小于等于；小于；等于; 不等于</td>
<td>\gt     \ge       \le      \lt   \equiv  \ne</td>
</tr>
<tr>
<td>组合符号$\circ$</td>
<td>\circ</td>
</tr>
<tr>
<td>$\frac{1}{2}$分数</td>
<td>\frac{分子}{分母}</td>
</tr>
<tr>
<td>向量$\vec{a}$</td>
<td>\vec{a}</td>
</tr>
</tbody>
</table>
</div>
<h3 id="其他的符号"><a href="#其他的符号" class="headerlink" title="其他的符号"></a>其他的符号</h3><blockquote id="fn_！！">
<sup>！！</sup>. 使用&A;时，这里的A只能是原始的限定词，比如A=theta可以显示&theta;，但是A=theta_t就不能显示$\theta_t$<a href="#reffn_！！" title="Jump back to footnote [！！] in the text."> &#8617;</a>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>要插入的符号</th>
<th>词（$A​$）下面是A的值或者是&A;</th>
</tr>
</thead>
<tbody>
<tr>
<td>帽子$\hat{y}$</td>
<td>\hat</td>
</tr>
<tr>
<td>向右的箭头$\rarr$</td>
<td>\rarr</td>
</tr>
<tr>
<td>箭头有上标$\stackrel{F}{\rarr}$</td>
<td>\stackrel{上}{下}</td>
</tr>
<tr>
<td>波浪号$\sim$</td>
<td>\sim</td>
</tr>
<tr>
<td>花括号$\lbrace\rbrace$</td>
<td>\lbrace  和\rbrace</td>
</tr>
<tr>
<td>文本中线对齐的省略号$\cdots$</td>
<td>\cdots</td>
</tr>
<tr>
<td>竖直方向的省略号$\vdots$</td>
<td>\vdots</td>
</tr>
<tr>
<td>斜线方向的省略号$\ddots$</td>
<td>\ddots</td>
</tr>
<tr>
<td>文本底线对齐的省略号$\ldots$</td>
<td>\ldots</td>
</tr>
<tr>
<td>左右两边都有上下标$\sideset{^1_2}{^3_4}I$</td>
<td>sideset{^1_2}{^3_4}I</td>
</tr>
</tbody>
</table>
</div>
<script type="math/tex; mode=display">y = \begin{cases}  
f1 & x = 0 \\
f2 & x\lt0    \\
f3    &x\gt0
\end{cases}</script><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">y &#x3D; \begin&#123;cases&#125;  </span><br><span class="line">f1 &amp; x &#x3D; 0 \\</span><br><span class="line">f2 &amp; x\lt0	\\</span><br><span class="line">f3	&amp;x\gt0</span><br><span class="line">\end&#123;cases&#125;</span><br></pre></td></tr></table></figure>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>1.希腊字母对应表<a href="https://blog.csdn.net/leviopku/article/details/81566554" target="_blank" rel="noopener">https://blog.csdn.net/leviopku/article/details/81566554</a></p>
<p>3.常见的特殊的字符<a href="http://www.mamicode.com/info-detail-2539363.html" target="_blank" rel="noopener">http://www.mamicode.com/info-detail-2539363.html</a></p>
<p>4.数学符号<a href="https://blog.csdn.net/katherine_hsr/article/details/79179622" target="_blank" rel="noopener">https://blog.csdn.net/katherine_hsr/article/details/79179622</a></p>
<p>5.如何修改图片的大小<a href="https://blog.csdn.net/robin_23/article/details/84319593" target="_blank" rel="noopener">https://blog.csdn.net/robin_23/article/details/84319593</a></p>
<p>6.MathJax 支持的数学符号表<a href="https://mirrors.tuna.tsinghua.edu.cn/CTAN/info/symbols/math/maths-symbols.pdf" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/CTAN/info/symbols/math/maths-symbols.pdf</a></p>
<p>7.Latex特殊符号与特殊字体<a href="https://blog.csdn.net/lanchunhui/article/details/54633576" target="_blank" rel="noopener">https://blog.csdn.net/lanchunhui/article/details/54633576</a></p>
<p>8.希腊字母怎么读<a href="https://zhidao.baidu.com/question/394534378094332565.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/394534378094332565.html</a></p>
<p>9.Markdwon的字母的各种字体<a href="https://www.jianshu.com/p/db7ed194e023" target="_blank" rel="noopener">https://www.jianshu.com/p/db7ed194e023</a></p>
<p>10.Typora的一些快捷键<a href="https://www.cnblogs.com/hongdada/p/9776547.html#windows快捷键：" target="_blank" rel="noopener">https://www.cnblogs.com/hongdada/p/9776547.html#windows%E5%BF%AB%E6%8D%B7%E9%94%AE%EF%BC%9A</a></p>
<p>12.markdown公式学习使用笔记<a href="https://www.cnblogs.com/q735613050/p/7253073.html" target="_blank" rel="noopener">https://www.cnblogs.com/q735613050/p/7253073.html</a></p>
<p>13.markdown进阶学习<a href="https://ucren.com/blog/archives/747" target="_blank" rel="noopener">https://ucren.com/blog/archives/747</a></p>
<p>14.markdown常用快捷键<a href="https://www.cnblogs.com/gxh195/p/10657200.html" target="_blank" rel="noopener">https://www.cnblogs.com/gxh195/p/10657200.html</a></p>
<p>15.markdown中的矩阵表示<a href="https://www.jianshu.com/p/756bc7e0ef6d" target="_blank" rel="noopener">https://www.jianshu.com/p/756bc7e0ef6d</a></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>tools/Neo4j的相关操作</title>
    <url>/2020/05/13/tools/Neo4j%E7%9A%84%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Neo4j Desktop是安装在Windows或Mac计算机上的应用软件，它包含试用的企业版数据库引擎，可以创建本地的图数据库；它也支持到远端数据库的连接。Neo4j Desktop 还包含一个应用管理器，可以方便地下载和安装Neo4j扩展应用，例如ETL、Bloom等。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Want to do</th>
<th>How to do</th>
</tr>
</thead>
<tbody>
<tr>
<td>修改Neo4j的登陆密码</td>
<td>1.进入neo4j提供的可视化界面<br />2.输入： :server change-password<br />3.键入原密码及新密码，即可修改</td>
</tr>
<tr>
<td>把.csv数据导入到图数据库中</td>
<td>将要导入的.csv数据集放到neo4j-community-3.5.3\import目录下，然后执行load命令，就可完成关系图谱的构建。</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<h1 id="Cypher的语句示例"><a href="#Cypher的语句示例" class="headerlink" title="Cypher的语句示例"></a>Cypher的语句示例</h1><h4 id="删除所有（清库）："><a href="#删除所有（清库）：" class="headerlink" title="删除所有（清库）："></a>删除所有（清库）：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MATCH (n) DETACH DELETE n</span><br></pre></td></tr></table></figure>
<h4 id="创建节点："><a href="#创建节点：" class="headerlink" title="创建节点："></a>创建节点：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE (结点名字:结点类型&#123;结点属性1:属性1值,结点属性2:属性2值&#125;) RETURN 结点名字;</span><br></pre></td></tr></table></figure>
<p>举例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.创建一个Person名字为a，出生于1997的节点</span><br><span class="line">CREATE (a:Person &#123;name:‘a’, born:1997&#125;) return a;</span><br><span class="line">2.创建b和c</span><br><span class="line">CREATE (b:Person &#123;name:‘b’, born:1997&#125;),(c:Person &#123;name:‘c’, born:1961&#125;) Return b,c</span><br></pre></td></tr></table></figure>
<h4 id="创建节点和关系："><a href="#创建节点和关系：" class="headerlink" title="创建节点和关系："></a>创建节点和关系：</h4><p>a-gift-&gt;b</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE (m:Person&#123;name:‘a’&#125;)-[:gift]-&gt;(f:Person&#123;name:‘b’&#125;) return m,f</span><br></pre></td></tr></table></figure>
<h4 id="查看所有结点："><a href="#查看所有结点：" class="headerlink" title="查看所有结点："></a>查看所有结点：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MATCH (n) RETURN n;</span><br></pre></td></tr></table></figure>
<h4 id="根据结点姓名返回所有的关系和尾结点"><a href="#根据结点姓名返回所有的关系和尾结点" class="headerlink" title="根据结点姓名返回所有的关系和尾结点"></a>根据结点姓名返回所有的关系和尾结点</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">return (:star&#123;starname:&quot;张国荣&quot;&#125;)--&gt;();</span><br></pre></td></tr></table></figure>
<h4 id="查询给定姓名和关系的所有的节点"><a href="#查询给定姓名和关系的所有的节点" class="headerlink" title="查询给定姓名和关系的所有的节点"></a>查询给定姓名和关系的所有的节点</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">match p&#x3D;(n:star&#123;starname:&quot;张国荣&quot;&#125;)-[:rel&#123;relation:&quot;好友&quot;&#125;]-&gt;() return p;</span><br></pre></td></tr></table></figure>
<h4 id="查询给定关系的所有节点对"><a href="#查询给定关系的所有节点对" class="headerlink" title="查询给定关系的所有节点对"></a>查询给定关系的所有节点对</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">match p&#x3D;()-[:rel&#123;relation:&quot;旧爱&quot;&#125;]-&gt;() return p;</span><br></pre></td></tr></table></figure>
<h4 id="语句中的return的一些示例"><a href="#语句中的return的一些示例" class="headerlink" title="语句中的return的一些示例"></a>语句中的return的一些示例</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">return as A将结果集合取一个别名A，</span><br><span class="line"></span><br><span class="line">return id(p)  将p结点的id返回  0，1，2，3，4，5，6</span><br><span class="line"></span><br><span class="line">return labels(p)  将结点的标签返回：star，star，star</span><br><span class="line"></span><br><span class="line">return head(labels(p))  仍然是返回结点的标签：star，star，star</span><br><span class="line"></span><br><span class="line">return n.starid    返回结点的starid属性值，貌似是等于id(p)+1</span><br><span class="line"></span><br><span class="line">return n.starname   返回结点的starname属性值，</span><br><span class="line"></span><br><span class="line">return &#123;,,,&#125; as A   构造了一个dict型变量集，</span><br></pre></td></tr></table></figure>
<h4 id="修改结点间的关系"><a href="#修改结点间的关系" class="headerlink" title="修改结点间的关系"></a>修改结点间的关系</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">match (a:star&#123;starname:&quot;张国荣&quot;&#125;)-[p:rel&#123;relation:&quot;好友&quot;&#125;]-&gt;(b:star&#123;starname:&quot;张学友&quot;&#125;)</span><br><span class="line">set p.relation&#x3D;&quot;组合&quot;</span><br><span class="line">return a,p,b</span><br></pre></td></tr></table></figure>
<h4 id="删除某个节点"><a href="#删除某个节点" class="headerlink" title="删除某个节点"></a>删除某个节点</h4><p>先删除关系，再删除节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MATCH (n:Department&#123;name: &quot;心胸外科&quot;,alias: &quot;&quot;&#125;) DETACH DELETE n</span><br></pre></td></tr></table></figure>
<h4 id="新增节点间的关系"><a href="#新增节点间的关系" class="headerlink" title="新增节点间的关系"></a>新增节点间的关系</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MATCH (a:star&#123;starname:&quot;张国荣&quot;&#125;),(b:star&#123;starname:&quot;张学友&quot;&#125;) </span><br><span class="line">CREATE (a)-[p:rel&#123;relation:&quot;好友&quot;&#125;]-&gt;(b) return a,p,b</span><br></pre></td></tr></table></figure>
<h4 id="删除结点间的关系"><a href="#删除结点间的关系" class="headerlink" title="删除结点间的关系"></a>删除结点间的关系</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">match (a:star&#123;starname:&quot;张国荣&quot;&#125;)-[p:rel&#123;relation:&quot;好友&quot;&#125;]-&gt;(b:star&#123;starname:&quot;张学友&quot;&#125;)</span><br><span class="line">delete p</span><br><span class="line">return a,p,b</span><br></pre></td></tr></table></figure>
<h4 id="新增某个节点"><a href="#新增某个节点" class="headerlink" title="新增某个节点"></a>新增某个节点</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create (a:star&#123;starname:&quot;&quot;,starid:&quot;&quot;&#125;)</span><br></pre></td></tr></table></figure>
<h4 id="查询只有一个节点的语句"><a href="#查询只有一个节点的语句" class="headerlink" title="查询只有一个节点的语句"></a>查询只有一个节点的语句</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">match (n) where not (n)-[]-() return n;</span><br></pre></td></tr></table></figure>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>Cypher语句使用案例<a href="https://blog.csdn.net/u013032852/article/details/82997088?utm_source=blogxgwz7" target="_blank" rel="noopener">https://blog.csdn.net/u013032852/article/details/82997088?utm_source=blogxgwz7</a></p>
<p>用Neo4j构建明星关系图谱<a href="https://zhuanlan.zhihu.com/p/61096301" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/61096301</a></p>
<p>Neo4j的前端可视化组件<a href="https://zhuanlan.zhihu.com/p/126219777" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/126219777</a></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch的使用</title>
    <url>/2020/06/09/tools/Pytorch/</url>
    <content><![CDATA[<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>pytorch的中文社区库github上的<a href="https://github.com/xavier-zy/Awesome-pytorch-list-CNVersion" target="_blank" rel="noopener">https://github.com/xavier-zy/Awesome-pytorch-list-CNVersion</a></p>
<p>对应的英文库<a href="https://github.com/bharathgs/Awesome-pytorch-list" target="_blank" rel="noopener">https://github.com/bharathgs/Awesome-pytorch-list</a></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>Vmware使用问题</title>
    <url>/2020/04/19/tools/Vmware%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="一-问题"><a href="#一-问题" class="headerlink" title="一.问题"></a>一.问题</h3><p>在使用VM时出现了如下的问题：</p>
<h1 id=""><a href="#" class="headerlink" title=""></a><img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/VMware锁定问题问题.jpg" alt=""></h1><h3 id="二-原因："><a href="#二-原因：" class="headerlink" title="二.原因："></a>二.原因：</h3><p>虚拟机异常关闭导致的。</p>
<h3 id="三-解决办法："><a href="#三-解决办法：" class="headerlink" title="三.解决办法："></a>三.解决办法：</h3><p> 找到虚拟机所安装的位置，把所有.lck<em>文件都删除即可</em>。</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>github相关操作</title>
    <url>/2020/04/18/tools/github%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="删除GitHub仓库中的文件"><a href="#删除GitHub仓库中的文件" class="headerlink" title="删除GitHub仓库中的文件"></a>删除GitHub仓库中的文件</h3><p>GitHub本身只能删除仓库，而不能直接删除里面的文件。</p>
<p><strong>思路：</strong>克隆到本地+重新上传</p>
<p><strong>操作：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.将对应仓库克隆到本地库 git clone xxxxxx.git(GitHub网站上某个项目的.git号)</span><br><span class="line">2.在Git Bash中删除文件或文件夹  </span><br><span class="line">	git rm test.txt(删除文件)</span><br><span class="line">	git rm -r test (删除文件夹)</span><br><span class="line">3.提交修改,输入如下:</span><br><span class="line">	git commit -m &quot;Delete some files.&quot;</span><br><span class="line">4.重新上传,输入输入:</span><br><span class="line">	git push -u origin xxx</span><br></pre></td></tr></table></figure>
<p><strong>注意点：</strong></p>
<p>1.用Git Bash删除文件时，要在对应的文件夹下</p>
<p>2.若文件夹或者文件名中有空格需要先加转义符’\\’再加空格’ ‘</p>
<h3 id="1-github上找到好东西的方法："><a href="#1-github上找到好东西的方法：" class="headerlink" title="1.github上找到好东西的方法："></a>1.github上找到好东西的方法：</h3><p>Awesome+关键词</p>
<h3 id="2-git和svn的差别："><a href="#2-git和svn的差别：" class="headerlink" title="2.git和svn的差别："></a>2.git和svn的差别：</h3><p>git:分布式，本地有镜像，无网络时也可以提交到本地镜像，待到有网络时再push到服务器，svn：非分布式，无网络时不可以提交。</p>
<p><a href="http://www.danmakupi*e.com/manage#/" target="_blank" rel="noopener">http://www.danmakupi*e.com/manage#/</a></p>
<h3 id="3-git基本操作指令"><a href="#3-git基本操作指令" class="headerlink" title="3.git基本操作指令/"></a>3.git基本操作指令/</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Want to do</th>
<th>How to do</th>
</tr>
</thead>
<tbody>
<tr>
<td>创建一个初始的仓库</td>
<td>git bash目录定位到需要创建仓库的位置，然后，输入git init</td>
</tr>
<tr>
<td>把文件加入到仓库中</td>
<td>1.使用命令 git add  文件名（带后缀），这个命令可以反复多次使用2.使用git commit -m “文件信息”，完成</td>
</tr>
<tr>
<td>查看用户名，邮箱</td>
<td>git config user,namegit config user.email</td>
</tr>
<tr>
<td>修改用户名，邮箱</td>
<td>git config —global user.name “your name”git config —global user.name “your email”</td>
</tr>
<tr>
<td>掌握当前工作区的状态</td>
<td>git status</td>
</tr>
<tr>
<td>查看被修改内容的区别</td>
<td>git diff 文件名（带后缀）</td>
</tr>
<tr>
<td>显示从最近到最远的提交日志</td>
<td>git log</td>
</tr>
<tr>
<td>显示查看命令历史</td>
<td>git reflog</td>
</tr>
<tr>
<td>在版本的历史之间穿梭，回退</td>
<td>git reset —hard 命令号其中HEAD表示当前版本，HEAD^表示上一个版本</td>
</tr>
<tr>
<td>修改还只在工作区的时候，想要丢弃修改</td>
<td>git checkout —文件名</td>
</tr>
<tr>
<td>工作区也修改了，同时还添加到了暂存区，想要丢弃修改，可以退回到修改只在工作区</td>
<td>git reset HEAD 文件名</td>
</tr>
<tr>
<td>删除文件</td>
<td>1.先手动删除，然后再git rm 文件名 ，再git commit -m “ message”2.若是文件误删，则可以用git checkout  - 文件名，恢复到最新版本</td>
</tr>
<tr>
<td>把已有的一个本地仓库与空的远端仓库相关联，同时把本地仓库的内容推到远端仓库</td>
<td>git remote add origin <a href="https://github.com/liangwg/testgit.git(远端仓库名)同时把本地库的内容推送到远端，git" target="_blank" rel="noopener">https://github.com/liangwg/testgit.git(远端仓库名)同时把本地库的内容推送到远端，git</a> push -u origin master</td>
</tr>
<tr>
<td>只要本地做了提交，就可以直接修改</td>
<td>git push origin master</td>
</tr>
<tr>
<td>从远端库中拷贝下到本地</td>
<td>git clone git@github.com:liangwg/testgit.git(远端仓库名）其中Github还可以给出其他地址：<a href="https://github.com/仓库名" target="_blank" rel="noopener">https://github.com/仓库名</a></td>
</tr>
<tr>
<td>git使用分支</td>
<td>查看分支：git branch创建分支：git branch 分支名切换分支：git checkout 分支名或者git switch 分支名创建+切换分支：git check -b 分支名或者git switch -c 分支名合并某分支到当前分支：git merge 分支删除分支：git branch -d 分支</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>jupyter Notebook使用其他环境</title>
    <url>/2020/05/11/tools/jupyterNotebook%E4%BD%BF%E7%94%A8%E5%85%B6%E4%BB%96%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h3 id="1-问题："><a href="#1-问题：" class="headerlink" title="1.问题："></a>1.问题：</h3><p>在Andaconda中已经配置了某个虚拟环境：UseTensor，在这个环境中安装了pykg2vec库，但是在jupyternotebook中并没法使用这个环境。</p>
<h3 id="2-解决办法"><a href="#2-解决办法" class="headerlink" title="2.解决办法"></a>2.解决办法</h3><p>以管理员方式打开Anaconda Promt，</p>
<p>在Anaconda Promt中进入所创建的虚拟环境，然后执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conda install ipykernel</span><br><span class="line">#或者 pip install ipkernel</span><br></pre></td></tr></table></figure>
<p>然后将自己的环境添加到ipython的kernel里，输入一下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(你创建的虚拟环境名)&gt;python -m ipykernel install --user --name (你创建的环境名) --display-name &quot;任意的名字，在jupyternotebook中展示的&quot;</span><br></pre></td></tr></table></figure>
<p>然后再刷新一下jupyternotebook的网页即可。</p>
<h3 id="3-其他操作"><a href="#3-其他操作" class="headerlink" title="3.其他操作"></a>3.其他操作</h3><h4 id="3-1-查看已经安装的kernelspec的命令如下："><a href="#3-1-查看已经安装的kernelspec的命令如下：" class="headerlink" title="3.1 查看已经安装的kernelspec的命令如下："></a>3.1 查看已经安装的kernelspec的命令如下：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jupyter kernelspec list</span><br></pre></td></tr></table></figure>
<h4 id="3-2-删除某个kernel环境"><a href="#3-2-删除某个kernel环境" class="headerlink" title="3.2 删除某个kernel环境"></a>3.2 删除某个kernel环境</h4><p>输入jupyter kernelspec list 查看安装的kernel和位置，根据显示的路径进入，其中把对应文件夹删除即可。</p>
<p>或者，直接输入以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jupyter kernelspec remove 环境名称</span><br></pre></td></tr></table></figure>
<h3 id="4-可能遇到的问题"><a href="#4-可能遇到的问题" class="headerlink" title="4.可能遇到的问题"></a>4.可能遇到的问题</h3><p>4.1 在按照上述步骤添加完虚拟环境后，在jupyternotebook中切换到刚创建的环境一直显示“服务正在启动”和“服务重连失败”，然后在Anaconda Promt的虚拟环境中尝试执行jupyter notebook命令，直接报下面的错误:<img src="https://raw.githubusercontent.com/liangwg/FigureBed/master/img/问题.png" alt="问题"></p>
<p>解决办法：</p>
<p>在电脑的系统变量中的PATH添加下面两个路径</p>
<p>D:\appIItemp\Anaconda\Library\bin</p>
<p>D:\appIItemp\Anaconda</p>
<p>然后重新运行一下。</p>
<p>4.2 在上面的问题解决之后，又遇到这个问题：在jupyter notebook使用新建的虚拟环境时，会显示是“挂掉的服务”。</p>
<p>在后台中出现如此的问题：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ModuleNotFoundError: No module named &#39;win32api&#39;</span><br></pre></td></tr></table></figure>
<p>解决办法：</p>
<p>输入pip install pypiwin32</p>
<p>4.3 又遇到的问题</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ERROR: Could not find a version that satisfies the requirement pypiwin32 (from versions: none)</span><br></pre></td></tr></table></figure>
<p>解决办法：</p>
<p>网络不好，重新运行一下就行了。</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>ppt的一些操作</title>
    <url>/2020/05/30/tools/ppt%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="ppt如何使得某一部分内容先展示，某一部分内容后展示"><a href="#ppt如何使得某一部分内容先展示，某一部分内容后展示" class="headerlink" title="ppt如何使得某一部分内容先展示，某一部分内容后展示"></a>ppt如何使得某一部分内容先展示，某一部分内容后展示</h3><p>分成两个文本框，给文本框设计出动作，</p>
<p>单击要编辑的文本框或图片，选中，然后右键，选择自定义动画就好了。可以选择点击出现，也可以选择设计多少时间后出现。</p>
<h3 id="如何设计动画同时出现"><a href="#如何设计动画同时出现" class="headerlink" title="如何设计动画同时出现"></a>如何设计动画同时出现</h3><p><a href="https://zhidao.baidu.com/question/445588972.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/445588972.html</a></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>psql关系数据库操作</title>
    <url>/2020/06/09/tools/psql%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<h3 id="一-简介"><a href="#一-简介" class="headerlink" title="一.简介"></a>一.简介</h3><h4 id="数据库和数据库表的关系"><a href="#数据库和数据库表的关系" class="headerlink" title="数据库和数据库表的关系"></a>数据库和数据库表的关系</h4><p>角色和用户的role和user关系：create role xxx password ‘mm’  LOGIN等同于create user xxx password ‘mmm’ ，也即role + login = user;</p>
<h3 id="二-操作"><a href="#二-操作" class="headerlink" title="二.操作"></a>二.操作</h3><h4 id="创建数据库："><a href="#创建数据库：" class="headerlink" title="创建数据库："></a>创建数据库：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create database 数据库名字 owner 用户名；</span><br></pre></td></tr></table></figure>
<h4 id="将某个数据库的所有权限赋值给某个用户"><a href="#将某个数据库的所有权限赋值给某个用户" class="headerlink" title="将某个数据库的所有权限赋值给某个用户"></a>将某个数据库的所有权限赋值给某个用户</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant all privileges on database xxx to xxx;</span><br></pre></td></tr></table></figure>
<h4 id="赋予部分权限"><a href="#赋予部分权限" class="headerlink" title="赋予部分权限"></a>赋予部分权限</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter user xxx 权限1 权限2 权限3;</span><br></pre></td></tr></table></figure>
<h4 id="登陆指定数据库"><a href="#登陆指定数据库" class="headerlink" title="登陆指定数据库"></a>登陆指定数据库</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">psql -h server -p port -u username 数据库名</span><br></pre></td></tr></table></figure>
<h4 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drop database 数据库名;</span><br></pre></td></tr></table></figure>
<h4 id="删除用户角色"><a href="#删除用户角色" class="headerlink" title="删除用户角色"></a>删除用户角色</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drop role xxx;</span><br></pre></td></tr></table></figure>
<p>若遇到权限依赖的问题，前面把数据库db的权限给了xxx，则需要事先收回xxx的所有权限。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">revoke all on database db from xxx;</span><br></pre></td></tr></table></figure>
<h4 id="查看某个数据库中存储的内容"><a href="#查看某个数据库中存储的内容" class="headerlink" title="查看某个数据库中存储的内容"></a>查看某个数据库中存储的内容</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\c 数据库名  #进入到某个数据库中</span><br><span class="line">\dt   #查看该个数据库中的所有表</span><br><span class="line">\c interface  #切换数据库</span><br><span class="line">\d 表名 	#查看某个数据库的某个表结构</span><br><span class="line">select* from apps limit 1; #查看某个库中某个表的记录</span><br><span class="line">\q  #退出psql</span><br></pre></td></tr></table></figure>
<h3 id="三-参考"><a href="#三-参考" class="headerlink" title="三.参考"></a>三.参考</h3><p><a href="https://blog.csdn.net/londa/article/details/94327596" target="_blank" rel="noopener">https://blog.csdn.net/londa/article/details/94327596</a>    psql常用命令</p>
<p><a href="https://blog.csdn.net/londa/article/details/94327596" target="_blank" rel="noopener">https://blog.csdn.net/londa/article/details/94327596</a>    创建用户后，登陆用户并创建数据库</p>
<p><a href="https://jingyan.baidu.com/article/39810a23af6cc9b636fda6da.html" target="_blank" rel="noopener">https://jingyan.baidu.com/article/39810a23af6cc9b636fda6da.html</a>   pgAdmin连接psql数据库</p>
<p><a href="https://jingyan.baidu.com/article/f3ad7d0fafd8c549c2345b53.html" target="_blank" rel="noopener">https://jingyan.baidu.com/article/f3ad7d0fafd8c549c2345b53.html</a>    pgAdmin打开表</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>texlive下载+Latex</title>
    <url>/2020/06/02/tools/texlive%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85+Latex/</url>
    <content><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>在即将步入研究生阶段+本科论文撰写时，深感自己对于论文格式的缺少，因此打算安装使用Latex。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>参考这篇博客<a href="https://www.jianshu.com/p/5a42c5dea05c" target="_blank" rel="noopener">https://www.jianshu.com/p/5a42c5dea05c</a></p>
<p>大致过程是</p>
<p>1.下载安装texlive.iso</p>
<p>2.下载安装texStudio</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>visio画图心得</title>
    <url>/2020/06/22/tools/visio%E7%94%BB%E5%9B%BE/</url>
    <content><![CDATA[<p>画图的关键：图标+基本图形的组合</p>
<p>对于一些比较难画的图，比如沙漏结构，可以先在网上找一张模型结构图，然后在这个图的基础上再添加一些线条和文字。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Want to do</th>
<th>How to do</th>
</tr>
</thead>
<tbody>
<tr>
<td>画出虚线矩形</td>
<td>先用基本矩形，然后对基本矩形进行样式设置。</td>
</tr>
<tr>
<td>让交叉的线不弯曲</td>
<td>“设计”-&gt;右上角”选择连接线”-&gt;”显示跨线”前面的勾去掉</td>
</tr>
<tr>
<td>让画布扩大时的分隔线去掉</td>
<td>“视图”-&gt;取消勾选”分页符”</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>word和pdf的一些基本操作</title>
    <url>/2020/06/01/tools/word%E8%AE%BE%E7%BD%AE%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th>Want to do</th>
<th>How to do</th>
</tr>
</thead>
<tbody>
<tr>
<td>设置字符的下标的下标</td>
<td>套用下标公式，然后在下标处再套用下标公式</td>
</tr>
<tr>
<td>插入分数的形式</td>
<td>“插入”-&gt;”公式”-&gt;”其他公式”-&gt;”插入新公式”-&gt;选项栏中的”结构”选择分数的形式</td>
</tr>
<tr>
<td>插入&pi;</td>
<td>“插入”-&gt;”字体”-&gt;”Symbol”中可以找到</td>
</tr>
<tr>
<td>在表格的文字段落中实现段落操作</td>
<td>由于在表格中的文字内容比较特殊，所以要在表格中设置段落的首行缩进的话，先选中所有内容，然后在“开始”菜单栏中，找到“段落”即可设置。</td>
</tr>
<tr>
<td>如何设置页码在某一页开始不再显示</td>
<td><a href="http://www.51sjk.com/b1b107081/" target="_blank" rel="noopener">http://www.51sjk.com/b1b107081/</a><br />“布局”-&gt;”分隔符”-&gt;插入到不想显示页码的那页，然后开始设置删除页码</td>
</tr>
<tr>
<td>如何只在一部分页中加入页眉</td>
<td>分隔符的应用</td>
</tr>
<tr>
<td>如何设置目录的格式</td>
<td></td>
</tr>
<tr>
<td>如何只设置一段话中的中文字体而不改变英文和数字</td>
<td>选中后，在”字体”中找。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="打开文件遇到错误提示”word在试图打开文件时遇到错误”"><a href="#打开文件遇到错误提示”word在试图打开文件时遇到错误”" class="headerlink" title="打开文件遇到错误提示”word在试图打开文件时遇到错误”"></a>打开文件遇到错误提示”word在试图打开文件时遇到错误”</h3><p>关闭提示窗口-&gt;打开”文件”-&gt;最下面的”选项”-&gt;最下面的”信任中心”-&gt;”信任中心设置”-&gt;”受保护的视图”-&gt;取消勾选“为来自Internet的文件启用受保护的视图”</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>如何写出合适的参考文献</title>
    <url>/2020/05/28/tools/%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E5%90%88%E9%80%82%E7%9A%84%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/</url>
    <content><![CDATA[<h3 id="目标："><a href="#目标：" class="headerlink" title="目标："></a>目标：</h3><p>在写论文时知道怎么引用参考文献</p>
<h3 id="论文下载与找寻"><a href="#论文下载与找寻" class="headerlink" title="论文下载与找寻"></a>论文下载与找寻</h3><p>从浏览器中的Blog中找话</p>
<p>将看似是一段论文的话复制黏贴进搜索，找到类似的论文，再</p>
<p>通过北邮图书管理系统的资源</p>
<p>知网万方Springer，去使用参考文献。</p>
<h3 id="个例"><a href="#个例" class="headerlink" title="个例"></a>个例</h3><p><strong>引用arXiv的文献：</strong></p>
<p>[预印本]    作者姓名 年份 arXiv: 号 [科学领域]</p>
<p>举例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[8] Latham T, Gershon T 2008 arXiv: 0809.0872v1 [hep-ph]</span><br><span class="line">[9] Shih Yuan Yu,Sujit Rokka Chhetri,Palash Goyal,etc 2019 arXiv: 1906.04239v1 [cs.AI]</span><br></pre></td></tr></table></figure>
<p><strong>电子文献：</strong></p>
<p>[电子文献]    作者姓名  网址  [引用日期]</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://wenku.baidu.com/view/0d9a3c4da4e9856a561252d380eb6294dc88225e.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/0d9a3c4da4e9856a561252d380eb6294dc88225e.html</a></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
  </entry>
  <entry>
    <title>小米2手机刷机</title>
    <url>/2020/06/03/%E5%85%B6%E4%BB%96/%E5%B0%8F%E7%B1%B32s%E5%8D%A1%E5%88%B7%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="一-问题描述"><a href="#一-问题描述" class="headerlink" title="一.问题描述"></a>一.问题描述</h3><p>一部小米2手机，如何把系统刷机到MIUI5或者其他版本？</p>
<h3 id="二-方式"><a href="#二-方式" class="headerlink" title="二.方式"></a>二.方式</h3><h4 id="卡刷1："><a href="#卡刷1：" class="headerlink" title="卡刷1："></a>卡刷1：</h4><p>1.到官网论坛，选择下载需要的卡刷包。</p>
<p>2.将下载好的ROM重新命名为update.zip</p>
<p>3.将小米2连接上电脑，通常情况下会产生一个可移动磁盘（XIAOMI）和一个小米2的手机图标（MI2），如果没有小米2的图标(MI2)，请安装产生的可移动磁盘（XIAOMI）里的可执行文件Setup.exe，安装驱动，成功后继续第4步。如果产生了小米2的图标，请直接第4步。</p>
<p>4.打开小米2图标，打开我的电脑里小米2的手机图标（MI2），里面有个内存设备，打开。将下载好的并且重命名后的文件update.zip拷贝到内存设备磁盘中（必须是根目录）。拷贝完后关闭手机。</p>
<p>5.先关机，按住开机键+音量上 屏幕亮后立即松开电源键 音量上一直按住 进入recovery 。选择简体中文 然后选择 清除数据 确认 里面三个选项都清除 。（音量键上下选择，电源键确定）。然后选择将update.zip安装至第一系统。等待刷机成功重启。</p>
<p>6.刷机成功后返回主菜单，选择重启系统，选择（最近）这个系统，因为进错了会无限重启。 </p>
<h4 id="卡刷2："><a href="#卡刷2：" class="headerlink" title="卡刷2："></a>卡刷2：</h4><p>下载奇兔刷机，然后按照操作一键刷机。</p>
<p>或者下载小米手机助手</p>
<h4 id="如何识别线刷包和卡刷包："><a href="#如何识别线刷包和卡刷包：" class="headerlink" title="如何识别线刷包和卡刷包："></a>如何识别线刷包和卡刷包：</h4><p><a href="http://rom.7to.cn/jiaochengdetail/17162" target="_blank" rel="noopener">http://rom.7to.cn/jiaochengdetail/17162</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>如何写出合适的参考文献</title>
    <url>/2020/05/31/%E5%85%B6%E4%BB%96/%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E5%90%88%E9%80%82%E7%9A%84%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/</url>
    <content><![CDATA[<h3 id="一-论文下载与找寻"><a href="#一-论文下载与找寻" class="headerlink" title="一.论文下载与找寻"></a>一.论文下载与找寻</h3><p>从浏览器中的Blog中找话</p>
<p>将看似是一段论文的话复制黏贴进搜索，找到类似的论文，再</p>
<p>通过北邮图书管理系统的资源</p>
<p>知网万方Springer，去使用参考文献。</p>
<h3 id="二-论文查重"><a href="#二-论文查重" class="headerlink" title="二.论文查重"></a>二.论文查重</h3><p>PaperPass </p>
<p>知网</p>
<h3 id="三-个例"><a href="#三-个例" class="headerlink" title="三.个例"></a>三.个例</h3><h4 id="1-引用arXiv的文献"><a href="#1-引用arXiv的文献" class="headerlink" title="1.引用arXiv的文献"></a>1.引用arXiv的文献</h4><p>[预印本]    作者姓名 年份 arXiv: 号 [科学领域]</p>
<p>举例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[8] Latham T, Gershon T 2008 arXiv: 0809.0872v1 [hep-ph]</span><br><span class="line">[9] Shih Yuan Yu,Sujit Rokka Chhetri,Palash Goyal,etc 2019 arXiv: 1906.04239v1 [cs.AI]</span><br></pre></td></tr></table></figure>
<h4 id="2-电子文献："><a href="#2-电子文献：" class="headerlink" title="2.电子文献："></a>2.电子文献：</h4><p>[电子文献]    作者姓名  网址  [引用日期]</p>
<h4 id="3-引用书籍："><a href="#3-引用书籍：" class="headerlink" title="3.引用书籍："></a>3.引用书籍：</h4><p>[1] 著者. 书名[M].版本(第一版不标注).出版地.出版者.出版年.引文所在的起始或起止页码</p>
<p>如</p>
<p>[1] 翟姚明. 车辆-轨道耦合动力学[M].北京:中国铁道出版社,1997,74-80.</p>
<p>[1] 邱锡鹏. 神经网络与深度学习[M].北京: 机械工业出版社,2020,7.</p>
<h3 id="四-参考"><a href="#四-参考" class="headerlink" title="四.参考"></a>四.参考</h3><p><a href="https://wenku.baidu.com/view/0d9a3c4da4e9856a561252d380eb6294dc88225e.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/0d9a3c4da4e9856a561252d380eb6294dc88225e.html</a></p>
<p><a href="https://jingyan.baidu.com/article/fd8044faa77d7c1031137ab8.html" target="_blank" rel="noopener">https://jingyan.baidu.com/article/fd8044faa77d7c1031137ab8.html</a></p>
<p>参考文献中显示符合重复是啥意思：</p>
<p><a href="http://www.nxhh.net/lunwen/95159.html" target="_blank" rel="noopener">http://www.nxhh.net/lunwen/95159.html</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>翻墙须知</title>
    <url>/2020/06/20/%E5%85%B6%E4%BB%96/%E7%BF%BB%E5%A2%99%E9%A1%BB%E7%9F%A5/</url>
    <content><![CDATA[<h3 id="0-一些问题"><a href="#0-一些问题" class="headerlink" title="0 一些问题"></a>0 一些问题</h3><p>系统http代理是主机通过访问代理服务器的地址，端口来获得相应的网络资源。</p>
<h3 id="1-系统代理模式"><a href="#1-系统代理模式" class="headerlink" title="1 系统代理模式"></a>1 系统代理模式</h3><h4 id="1-1-PAC模式："><a href="#1-1-PAC模式：" class="headerlink" title="1.1 PAC模式："></a>1.1 PAC模式：</h4><p>智能分流模式，根据规则匹配访问的网站，仅仅加速国外网站，国内网站不受影响。PAC文件为SSR根目录下的pac.txt。</p>
<p><strong>优点</strong>：国内网站依旧走本地网络，国外网站走代理，速度快，省流。</p>
<p><strong>缺点</strong>：少部分国外网站不走代理，没法加速，甚至无法访问(解决方案：自己编辑PAC规则列表，将不走代理的国外网址加入进去，或者直接选择全局模式)</p>
<h4 id="1-2-全局模式"><a href="#1-2-全局模式" class="headerlink" title="1.2 全局模式"></a>1.2 全局模式</h4><p>国内、国外所有网站都走代理。</p>
<p><strong>优点</strong>：可访问全球所有的网站</p>
<p><strong>缺点</strong>：所有网站都走代理，造成访问国内的网站速度变慢，耗流。</p>
<h4 id="1-3-直连模式"><a href="#1-3-直连模式" class="headerlink" title="1.3 直连模式"></a>1.3 直连模式</h4><p>关闭系统HTTP代理，所有HTTP上网流量都不会通过SSR代理，此模式下只能使用Socks5代理方式连接SSR代理。</p>
<h4 id="1-4保持当前状态不修改"><a href="#1-4保持当前状态不修改" class="headerlink" title="1.4保持当前状态不修改"></a>1.4保持当前状态不修改</h4><p>不会对目前的系统HTTP代理状态进行任何的修改。当退出SSR后，系统HTTP代理会自动被恢复至原有状态;开启SSR后，系统HTTP代理会被设置成所设定的系统代理模式状态。</p>
<h3 id="2-SSR的配置"><a href="#2-SSR的配置" class="headerlink" title="2 SSR的配置"></a>2 SSR的配置</h3><ol>
<li><strong>系统代理模式选择</strong>：PAC模式（PAC模式就是有选择的使用专线，国内不代理）</li>
<li><strong>代理规则模式选择</strong>：绕过局域网和大陆</li>
<li><strong>PAC选择</strong>：更新PAC为绕过大陆IP（即所有的大陆IP网址不需要使用专线网络）</li>
</ol>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>解决国内网址跳转亚马逊下载时网速慢的问题</title>
    <url>/2020/04/17/%E5%85%B6%E4%BB%96/%E8%A7%A3%E5%86%B3%E5%9B%BD%E5%86%85%E7%BD%91%E5%9D%80%E8%B7%B3%E8%BD%AC%E4%BA%9A%E9%A9%AC%E9%80%8A%E4%B8%8B%E8%BD%BD%E6%97%B6%E7%BD%91%E9%80%9F%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="一-问题"><a href="#一-问题" class="headerlink" title="一.问题"></a>一.问题</h3><p>“<a href="https://s3.ap-northeast-2.amazonaws.com/”开头类似于这种的带有[amazonaws](https://s3.ap-northeast-2.amazonaws.com/)字眼的地址，下载起来很慢，有时候连不上。" target="_blank" rel="noopener">https://s3.ap-northeast-2.amazonaws.com/”开头类似于这种的带有[amazonaws](https://s3.ap-northeast-2.amazonaws.com/)字眼的地址，下载起来很慢，有时候连不上。</a></p>
<h3 id="二-解决办法："><a href="#二-解决办法：" class="headerlink" title="二.解决办法："></a>二.解决办法：</h3><p>可以通过设置<code>host</code>,强制把访问节点从美国定向到香港的办法来解决这个问题。<code>Windows</code>下，编辑<code>C:\Windows\System32\drivers\etc\hosts</code>然后增加如下解析即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">219.76.4.4 s3.amazonaws.com</span><br><span class="line">219.76.4.4 github-cloud.s3.amazonaws.com</span><br></pre></td></tr></table></figure>
<h5 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h5><p>host立即生效：</p>
<p>windows下修改hosts文件不需重启后直接生效：</p>
<p>在cmd中输入ipconfig /displaydns 回车和ipconfig /flushdns回车即可</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>解决在hexo提交博客到github时，登不上去的问题</title>
    <url>/2020/06/09/%E5%85%B6%E4%BB%96/%E8%A7%A3%E5%86%B3%E8%BE%93%E5%85%A5hexo%E5%91%BD%E4%BB%A4%E6%97%B6github%E7%99%BB%E4%B8%8D%E4%B8%8A%E5%8E%BB/</url>
    <content><![CDATA[<h3 id="一-问题"><a href="#一-问题" class="headerlink" title="一.问题"></a>一.问题</h3><p>在提交自己的博客到github Page，在cmd中输入命令“hexo d”时，爆出如下的错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fatal: unable to access &#39;[https:&#x2F;&#x2F;liangwg:mlma3d4f@github.com&#x2F;liangwg&#x2F;liangwg.github.io.git&#x2F;](https:&#x2F;&#x2F;liangwg:mlma3d4f@github.com&#x2F;liangwg&#x2F;liangwg.github.io.git&#x2F;)&#39;: Failed to connect to [github.com](http:&#x2F;&#x2F;github.com&#x2F;) port 443: Timed out</span><br></pre></td></tr></table></figure>
<p>但是自己在搭建完梯子之后明明能够登上github的官网，也能正常打开自己的网页。</p>
<h3 id="二-解决办法"><a href="#二-解决办法" class="headerlink" title="二.解决办法"></a>二.解决办法</h3><p>是由于自己在c:\windows\system32\drivers\etc\的目录下的host文件出了问题，之前在host文件中添加了几个github的域名，现在这些域名没法使用了，导致hexo d时，跳转不过去。</p>
<p>因此，把之前添加的有关github的域名解析的行都删除即可。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>通过关闭Windows update更新解决服务主机CPU率高的问题</title>
    <url>/2020/04/23/%E5%85%B6%E4%BB%96/%E9%80%9A%E8%BF%87%E5%85%B3%E9%97%ADWindows%20update%E6%9B%B4%E6%96%B0%E8%A7%A3%E5%86%B3%E6%9C%8D%E5%8A%A1%E4%B8%BB%E6%9C%BACPU%E7%8E%87%E9%AB%98%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="一-问题"><a href="#一-问题" class="headerlink" title="一.问题"></a>一.问题</h3><p>windows10系统卡顿，并且笔记本风扇声音特别响，通过任务管理器查看得到Windows Update 所占的内存较大。</p>
<h3 id="二-解决办法"><a href="#二-解决办法" class="headerlink" title="二.解决办法"></a>二.解决办法</h3><p>1.找到任务管理器中的“ 服务主机：本地系统”-&gt;“Windows Update”，右键，进入“服务”</p>
<p>2.在服务列表中找到“Windows Update”，右键，停止</p>
<p>3.在服务列表中找到“Windows Update”，右键，属性，启动类型选择“禁用”</p>
<p>4.打开C:\Windows\SoftwareDistribution，删除里面所有文件，如果可以删除所有文件，那么CPU应该已经恢复正常了，如果有些文件不能删除，则可能是“Windows Update”没有完全关闭，继续下面步骤</p>
<p>5.按Win键+R键调出运行，输入“gpedit.msc”点击“确定”，调出“本地组策略编辑器”。<br>（注：自己的电脑似乎没打显示gpedit.msc，不知道是什么原因。）</p>
<p>6.依次展开”计算机配置”，”管理模板” ，”windows组件” ，”windows更新 “，在右面找到“配置自动更新”，并双击</p>
<p>7.在配置窗口上按1-3的顺序选择“已禁用”，点击“应用”，“确定”，重启电脑</p>
<p>8.打开C:\Windows\SoftwareDistribution，删除里面所有文件</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>面经</title>
    <url>/2020/04/22/%E5%85%B6%E4%BB%96/%E9%9D%A2%E7%BB%8F/</url>
    <content><![CDATA[<h1 id="快手"><a href="#快手" class="headerlink" title="快手"></a>快手</h1><h3 id="一-快手"><a href="#一-快手" class="headerlink" title="一.快手"></a>一.快手</h3><p><strong>1.C++方面</strong></p>
<ul>
<li>字符定义占几位</li>
<li>多态的概念</li>
</ul>
<p><strong>2.linux编程开发</strong></p>
<ul>
<li>把一个文件的内容经过筛选输出到另一个文件中</li>
</ul>
<h3 id="二-百度（C-岗位）"><a href="#二-百度（C-岗位）" class="headerlink" title="二.百度（C++岗位）"></a>二.百度（C++岗位）</h3><p><strong>1.最重要的一条</strong></p>
<p>​    在反问环节一定要问和技术有关的问题，要知道自己能为公司做什么，怎么做。</p>
<p><strong>2.基础知识这一方面</strong></p>
<p>要有自己的理解，不能像背书一样</p>
<p><strong>3.Linux编程环境</strong></p>
<ul>
<li>fork()函数的作用（COW）：</li>
<li><p>一些常用指令必须熟记于心：</p>
</li>
<li><p>打印一个文档的内容：</p>
</li>
</ul>
<p><strong>4.数据结构</strong></p>
<ul>
<li>链表反转算法</li>
<li>所学过的数据结构</li>
<li>对于一个二叉树，寻找一个特定节点所需的时间复杂度。</li>
<li>所学过的其他算法</li>
</ul>
<p><strong>5.计算机网络</strong></p>
<ul>
<li>TCP和UDP的区别</li>
<li>TCP的三次握手四次挥手</li>
<li>TCP为什么要三次握手来建立通信</li>
</ul>
<p><strong>6.操作系统</strong></p>
<ul>
<li>线程的锁有哪几种</li>
</ul>
<p><strong>7.C++方面</strong></p>
<ul>
<li>C++虚函数的作用</li>
<li>多态的概念</li>
<li><p>C++的STL的使用</p>
</li>
<li><p>堆栈，局部变量区，全局变量区。</p>
</li>
</ul>
<p><strong>8.数据库</strong></p>
<ul>
<li>Redis的使用</li>
<li>修改数据时是先修改Redis的值还是先修改数据库磁盘的值</li>
<li>关系数据库的性能优化</li>
</ul>
<p><strong>9.与人交往方面</strong></p>
<ul>
<li>永远不要相信面试官表面所显露的样子，以及他所说的每一句客套话，没人会因为你是本科生，他们需要的是能为他们解决问题的人，不会就是不会，不要拿本科没学过搪瓷。</li>
<li>表面客气的人，其实和内心是不同的。自己要有心机。</li>
</ul>
<h3 id="三-字节跳动（后端开发岗）"><a href="#三-字节跳动（后端开发岗）" class="headerlink" title="三.字节跳动（后端开发岗）"></a>三.字节跳动（后端开发岗）</h3><p><strong>算法题方面</strong></p>
<ul>
<li>已知一个文件日志（用户名，登陆时间，登出时间），求出在线的人数情况</li>
<li>已知一个二叉树，求出根结点到其他结点的值等于一个定值的所有路径。</li>
</ul>
<p><strong>计网基础知识</strong></p>
<ul>
<li>TCP的拥塞控制是如何实现的</li>
<li>在前端与后端的交互上，是如何实现的（http如何发到后端上来）</li>
</ul>
<p><strong>字节跳动面经</strong></p>
<p><a href="https://mp.weixin.qq.com/s/A5bSc7jcUhfhcDLu9bdC6w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/A5bSc7jcUhfhcDLu9bdC6w</a></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>谷歌面试<a href="https://mp.weixin.qq.com/s/plxO4mCuAPFzLCt6AYd8GA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/plxO4mCuAPFzLCt6AYd8GA</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
</search>
